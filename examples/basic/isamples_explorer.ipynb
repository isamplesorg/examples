{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# iSamples Interactive Explorer\n\nAn interactive interface for exploring iSamples data across all sources.\n\n**Features:**\n- Map view with 6M+ samples (lonboard WebGL)\n- Interactive table with filtering (ipydatagrid)\n- Sample cards on selection\n- **Faceted filtering**: Filter by source, material type, and time period\n  - Hierarchical material types with rollup\n  - **Decade quick-select** for time filtering\n- **Fulltext search**: Search label, description, place name with ranked results\n- **Bidirectional selection sync**: Click map → highlights table row; click table → recenters map\n- **Viewport Mode**: Dynamic loading based on pan/zoom (with loading indicator)\n- **Adaptive sampling**: More points when zoomed in, fewer when zoomed out\n\n**Data:** Zenodo wide parquet (~282 MB, 20M rows)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "import threading\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Visualization\n",
    "from lonboard import Map, ScatterplotLayer\n",
    "from lonboard.colormap import apply_continuous_cmap\n",
    "from ipydatagrid import DataGrid\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "LOCAL_WIDE = os.path.expanduser(\"~/Data/iSample/pqg_refining/zenodo_wide_2026-01-09.parquet\")\n",
    "REMOTE_WIDE = \"https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202601_wide.parquet\"\n",
    "\n",
    "# Use local if available\n",
    "PARQUET_PATH = LOCAL_WIDE if os.path.exists(LOCAL_WIDE) else REMOTE_WIDE\n",
    "print(f\"Using: {PARQUET_PATH}\")\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source color scheme (consistent across iSamples)\n",
    "SOURCE_COLORS = {\n",
    "    'SESAR': [51, 102, 204, 200],       # Blue\n",
    "    'OPENCONTEXT': [220, 57, 18, 200],  # Red\n",
    "    'GEOME': [16, 150, 24, 200],        # Green\n",
    "    'SMITHSONIAN': [255, 153, 0, 200],  # Orange\n",
    "}\n",
    "\n",
    "DEFAULT_COLOR = [128, 128, 128, 200]  # Gray for unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Data\n",
    "\n",
    "We start with a sample of 50K records across all sources for responsive interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_samples(max_per_source=12500, source_filter=None, bbox=None, search_term=None,\n                 source_filters=None, material_filters=None, year_range=None):\n    \"\"\"\n    Load samples with coordinates from the wide parquet.\n\n    Args:\n        max_per_source: Maximum samples per source (for balanced representation)\n        source_filter: Optional single source name to filter (e.g., 'OPENCONTEXT') - DEPRECATED\n        bbox: Optional bounding box dict with min_lat, max_lat, min_lon, max_lon\n        search_term: Optional search string to filter and rank results\n        source_filters: Set of source names to include (empty = all)\n        material_filters: Set of material labels to include (empty = all)\n        year_range: Tuple of (min_year, max_year) or None for no filter\n\n    Returns:\n        GeoDataFrame with sample data (includes search_score if search_term provided)\n    \"\"\"\n    # Build WHERE clause with optional table prefix for material filter queries\n    def build_where_clause(prefix=\"\"):\n        p = f\"{prefix}.\" if prefix else \"\"\n        clause = f\"WHERE {p}otype = 'MaterialSampleRecord' AND {p}latitude IS NOT NULL\"\n\n        # Handle source filtering (new multi-select takes precedence)\n        if source_filters:\n            sources_sql = \", \".join(f\"'{s}'\" for s in source_filters)\n            clause += f\" AND {p}n IN ({sources_sql})\"\n        elif source_filter:\n            clause += f\" AND {p}n = '{source_filter}'\"\n\n        if bbox:\n            clause += f\" AND {p}latitude BETWEEN {bbox['min_lat']} AND {bbox['max_lat']}\"\n            clause += f\" AND {p}longitude BETWEEN {bbox['min_lon']} AND {bbox['max_lon']}\"\n\n        # Year range filter - cast result_time to TIMESTAMP first\n        if year_range and (year_range[0] is not None or year_range[1] is not None):\n            if year_range[0] is not None and year_range[1] is not None:\n                clause += f\" AND EXTRACT(YEAR FROM TRY_CAST({p}result_time AS TIMESTAMP)) BETWEEN {year_range[0]} AND {year_range[1]}\"\n            elif year_range[0] is not None:\n                clause += f\" AND EXTRACT(YEAR FROM TRY_CAST({p}result_time AS TIMESTAMP)) >= {year_range[0]}\"\n            elif year_range[1] is not None:\n                clause += f\" AND EXTRACT(YEAR FROM TRY_CAST({p}result_time AS TIMESTAMP)) <= {year_range[1]}\"\n\n        return clause\n\n    # Search filtering and scoring\n    def build_search_expr(prefix=\"\"):\n        p = f\"{prefix}.\" if prefix else \"\"\n        if not search_term or not search_term.strip():\n            return \"0 AS search_score\", \"\", \"ORDER BY RANDOM()\"\n\n        # Escape single quotes in search term\n        term = search_term.strip().replace(\"'\", \"''\")\n\n        # Weighted scoring: label (10) > description (5) > place_name (3)\n        score_expr = f\"\"\"\n            (CASE WHEN {p}label ILIKE '%{term}%' THEN 10 ELSE 0 END +\n             CASE WHEN {p}description ILIKE '%{term}%' THEN 5 ELSE 0 END +\n             CASE WHEN CAST({p}place_name AS VARCHAR) ILIKE '%{term}%' THEN 3 ELSE 0 END) AS search_score\n        \"\"\"\n\n        # Filter to only matching records\n        search_filter = f\"\"\"\n            AND ({p}label ILIKE '%{term}%' \n                 OR {p}description ILIKE '%{term}%' \n                 OR CAST({p}place_name AS VARCHAR) ILIKE '%{term}%')\n        \"\"\"\n\n        # Sort by score (highest first), then random within same score\n        order_by = \"ORDER BY search_score DESC, RANDOM()\"\n\n        return score_expr, search_filter, order_by\n\n    # Query with balanced sampling across sources\n    if material_filters:\n        # Material filter requires a CTE with join\n        material_labels_sql = \", \".join(f\"'{m}'\" for m in material_filters)\n        where_clause = build_where_clause(\"base\")\n        search_score_expr, search_filter, order_by = build_search_expr(\"base\")\n\n        query = f\"\"\"\n            WITH material_matches AS (\n                SELECT DISTINCT msr.row_id\n                FROM read_parquet('{PARQUET_PATH}') msr\n                CROSS JOIN UNNEST(msr.p__has_material_category) AS t(mat_id)\n                JOIN read_parquet('{PARQUET_PATH}') ic ON ic.row_id = mat_id\n                WHERE msr.otype = 'MaterialSampleRecord'\n                  AND ic.label IN ({material_labels_sql})\n            ),\n            scored AS (\n                SELECT \n                    base.row_id, base.pid, base.label, base.description, \n                    base.latitude, base.longitude, base.n as source,\n                    base.place_name, base.result_time,\n                    {search_score_expr}\n                FROM read_parquet('{PARQUET_PATH}') base\n                {where_clause}\n                {search_filter}\n                AND base.row_id IN (SELECT row_id FROM material_matches)\n            ),\n            ranked AS (\n                SELECT *,\n                    ROW_NUMBER() OVER (PARTITION BY source {order_by.replace('ORDER BY', 'ORDER BY')}) as rn\n                FROM scored\n            )\n            SELECT row_id, pid, label, description, latitude, longitude, source, place_name, result_time, search_score\n            FROM ranked\n            WHERE rn <= {max_per_source}\n            {order_by}\n        \"\"\"\n    else:\n        where_clause = build_where_clause()\n        search_score_expr, search_filter, order_by = build_search_expr()\n\n        query = f\"\"\"\n            WITH scored AS (\n                SELECT \n                    row_id, pid, label, description, latitude, longitude, n as source,\n                    place_name, result_time,\n                    {search_score_expr}\n                FROM read_parquet('{PARQUET_PATH}')\n                {where_clause}\n                {search_filter}\n            ),\n            ranked AS (\n                SELECT *,\n                    ROW_NUMBER() OVER (PARTITION BY source {order_by.replace('ORDER BY', 'ORDER BY')}) as rn\n                FROM scored\n            )\n            SELECT row_id, pid, label, description, latitude, longitude, source, place_name, result_time, search_score\n            FROM ranked\n            WHERE rn <= {max_per_source}\n            {order_by}\n        \"\"\"\n\n    df = con.sql(query).df()\n\n    # Convert to GeoDataFrame\n    geometry = [Point(lon, lat) for lon, lat in zip(df['longitude'], df['latitude'])]\n    gdf = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n\n    return gdf\n\n\ndef view_state_to_bbox(view_state, buffer_factor=1.5, aspect_ratio=1.5):\n    \"\"\"\n    Calculate bounding box from lonboard view_state.\n\n    The view_state contains latitude, longitude, and zoom level.\n    We calculate the visible extent using Web Mercator projection math.\n\n    Args:\n        view_state: lonboard MapViewState with latitude, longitude, zoom\n        buffer_factor: Multiply bbox by this to load slightly more data (default 1.5)\n        aspect_ratio: Width/height ratio of map container (default 1.5 for wider maps)\n\n    Returns:\n        dict with min_lat, max_lat, min_lon, max_lon\n    \"\"\"\n    lat = view_state.latitude\n    lon = view_state.longitude\n    zoom = view_state.zoom\n\n    # At zoom 0, entire world visible (~360 degrees longitude)\n    # Each zoom level halves the visible area\n    # Approximate degrees visible at zoom level\n    degrees_visible = 360 / (2 ** zoom)\n\n    # Latitude visible area - apply buffer\n    lat_degrees = degrees_visible * buffer_factor / 2\n\n    # Longitude visible area - wider due to aspect ratio and Mercator at higher latitudes\n    # Mercator stretches longitude at higher latitudes, so we need more buffer\n    lat_rad = math.radians(abs(lat))\n    mercator_stretch = 1 / max(math.cos(lat_rad), 0.1)  # Avoid division by zero near poles\n    lon_degrees = degrees_visible * buffer_factor * aspect_ratio * mercator_stretch / 2\n\n    # Clamp latitude to valid range\n    min_lat = max(-90, lat - lat_degrees)\n    max_lat = min(90, lat + lat_degrees)\n    min_lon = max(-180, lon - lon_degrees)\n    max_lon = min(180, lon + lon_degrees)\n\n    return {\n        'min_lat': min_lat,\n        'max_lat': max_lat,\n        'min_lon': min_lon,\n        'max_lon': max_lon\n    }\n\n\ndef adaptive_sample_size(zoom, base_size=50000):\n    \"\"\"\n    Calculate sample size based on zoom level.\n\n    At low zoom (world view), sample aggressively to avoid overwhelming.\n    At high zoom (local view), show all available points.\n\n    Args:\n        zoom: Current zoom level (0-20)\n        base_size: Base sample size per source\n\n    Returns:\n        Sample size to use per source\n    \"\"\"\n    if zoom < 2:\n        return min(base_size, 10000)  # World view: max 10K per source\n    elif zoom < 5:\n        return min(base_size, 25000)  # Continent view: max 25K\n    elif zoom < 8:\n        return min(base_size, 50000)  # Country view: max 50K\n    elif zoom < 12:\n        return min(base_size, 100000)  # Region view: max 100K\n    else:\n        return base_size  # Local view: use full base_size\n\n\n# Load initial data\nprint(\"Loading samples...\")\nsamples_gdf = load_samples(max_per_source=12500)\nprint(f\"Loaded {len(samples_gdf):,} samples\")\nprint(f\"\\nBy source:\")\nprint(samples_gdf['source'].value_counts())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Card Renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_sample_card(row):\n",
    "    \"\"\"\n",
    "    Render a sample as an HTML card.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row or Series with sample data\n",
    "    \n",
    "    Returns:\n",
    "        HTML string\n",
    "    \"\"\"\n",
    "    if row is None:\n",
    "        return \"<div style='padding: 10px; color: #666;'>Click a point to see details</div>\"\n",
    "    \n",
    "    source = row.get('source', 'Unknown')\n",
    "    source_color = {\n",
    "        'SESAR': '#3366CC',\n",
    "        'OPENCONTEXT': '#DC3912',\n",
    "        'GEOME': '#109618',\n",
    "        'SMITHSONIAN': '#FF9900'\n",
    "    }.get(source, '#808080')\n",
    "    \n",
    "    label = row.get('label', 'No label')\n",
    "    if pd.isna(label):\n",
    "        label = 'No label'\n",
    "    \n",
    "    description = row.get('description', '')\n",
    "    if pd.isna(description):\n",
    "        description = ''\n",
    "    elif len(str(description)) > 200:\n",
    "        description = str(description)[:200] + '...'\n",
    "    \n",
    "    lat = row.get('latitude', 0)\n",
    "    lon = row.get('longitude', 0)\n",
    "    if pd.isna(lat):\n",
    "        lat = 0\n",
    "    if pd.isna(lon):\n",
    "        lon = 0\n",
    "        \n",
    "    pid = row.get('pid', '')\n",
    "    if pd.isna(pid):\n",
    "        pid = ''\n",
    "    \n",
    "    place = row.get('place_name', '')\n",
    "    if pd.isna(place):\n",
    "        place = ''\n",
    "    elif isinstance(place, list):\n",
    "        place = ' > '.join(str(p) for p in place if p and not pd.isna(p))\n",
    "    else:\n",
    "        place = str(place)\n",
    "    \n",
    "    # Build place HTML only if place has content\n",
    "    place_html = ''\n",
    "    if place and len(place) > 0:\n",
    "        place_html = f'<div style=\"margin-bottom: 4px;\"><strong>Place:</strong> {place[:100]}</div>'\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "                border: 1px solid #ddd; border-radius: 8px; padding: 16px; \n",
    "                max-width: 400px; background: white; box-shadow: 0 2px 4px rgba(0,0,0,0.1);\">\n",
    "        <div style=\"display: flex; align-items: center; margin-bottom: 12px;\">\n",
    "            <span style=\"background: {source_color}; color: white; padding: 4px 8px; \n",
    "                        border-radius: 4px; font-size: 12px; font-weight: 600;\">{source}</span>\n",
    "        </div>\n",
    "        <h3 style=\"margin: 0 0 8px 0; font-size: 16px; color: #333;\">{label}</h3>\n",
    "        <p style=\"margin: 0 0 12px 0; font-size: 13px; color: #666; line-height: 1.4;\">\n",
    "            {description if description else '<em>No description</em>'}\n",
    "        </p>\n",
    "        <div style=\"font-size: 12px; color: #888;\">\n",
    "            <div style=\"margin-bottom: 4px;\"><strong>Location:</strong> {lat:.4f}, {lon:.4f}</div>\n",
    "            {place_html}\n",
    "            <div><strong>ID:</strong> <code style=\"background: #f5f5f5; padding: 2px 4px; border-radius: 3px;\">{str(pid)[:50]}{'...' if len(str(pid)) > 50 else ''}</code></div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "# Test the card\n",
    "display(HTML(render_sample_card(samples_gdf.iloc[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_for_sources(sources):\n",
    "    \"\"\"\n",
    "    Get color array for a list of sources.\n",
    "    \n",
    "    Args:\n",
    "        sources: pandas Series or list of source names\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of RGBA colors\n",
    "    \"\"\"\n",
    "    colors = np.array([\n",
    "        SOURCE_COLORS.get(s, DEFAULT_COLOR) for s in sources\n",
    "    ], dtype=np.uint8)\n",
    "    return colors\n",
    "\n",
    "def create_map_layer(gdf):\n",
    "    \"\"\"\n",
    "    Create a lonboard ScatterplotLayer from a GeoDataFrame.\n",
    "    \"\"\"\n",
    "    colors = get_colors_for_sources(gdf['source'])\n",
    "    \n",
    "    layer = ScatterplotLayer.from_geopandas(\n",
    "        gdf,\n",
    "        get_fill_color=colors,\n",
    "        get_radius=1000,\n",
    "        radius_units='meters',\n",
    "        radius_min_pixels=2,\n",
    "        radius_max_pixels=10,\n",
    "        pickable=True,\n",
    "        auto_highlight=True,\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "# Basemap options - uncomment your preference\n",
    "from lonboard.basemap import CartoStyle, MaplibreBasemap\n",
    "\n",
    "BASEMAP_VOYAGER = MaplibreBasemap(style=CartoStyle.Voyager)      # Light with labels (default)\n",
    "BASEMAP_POSITRON = MaplibreBasemap(style=CartoStyle.Positron)  # Light, minimal\n",
    "BASEMAP_DARK = MaplibreBasemap(style=CartoStyle.DarkMatter)    # Dark theme\n",
    "\n",
    "# Create initial map\n",
    "layer = create_map_layer(samples_gdf)\n",
    "sample_map = Map(layers=[layer], basemap=BASEMAP_VOYAGER)\n",
    "print(\"Map created with\", len(samples_gdf), \"points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(gdf):\n",
    "    \"\"\"\n",
    "    Create an ipydatagrid table from sample data.\n",
    "    \"\"\"\n",
    "    # Select columns for display\n",
    "    display_cols = ['source', 'label', 'latitude', 'longitude']\n",
    "    df_display = gdf[display_cols].copy()\n",
    "    df_display['latitude'] = df_display['latitude'].round(4)\n",
    "    df_display['longitude'] = df_display['longitude'].round(4)\n",
    "    \n",
    "    grid = DataGrid(\n",
    "        df_display,\n",
    "        base_row_size=32,\n",
    "        base_column_size=120,\n",
    "        selection_mode='row',\n",
    "        editable=False,\n",
    "        layout=widgets.Layout(height='300px', width='100%')\n",
    "    )\n",
    "    return grid\n",
    "\n",
    "# Create table\n",
    "sample_table = create_table(samples_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# State management\nclass ExplorerState:\n    def __init__(self):\n        self.selected_index = None\n        self.selected_row = None\n        self.current_gdf = None\n        self.viewport_mode = False\n        self.debounce_timer = None\n        self.loading = False\n        self.syncing_selection = False  # Prevent infinite loops\n        self.current_search = \"\"  # Current search term\n        # Facet filter state\n        self.source_filters = set()      # Selected sources (empty = all)\n        self.material_filters = set()    # Selected material URIs (full URIs for filtering)\n        self.year_range = (None, None)   # (min_year, max_year) or None for no filter\n        self.selected_decades = set()    # Selected decades for quick filter\n        self.material_rollup = True      # Whether to include children when parent selected\n        # Facet counts cache\n        self.facet_counts_cache = {}\n        self.facet_cache_time = 0\n\nstate = ExplorerState()\nstate.current_gdf = samples_gdf\n\n\n# =============================================================================\n# Material Hierarchy Definition\n# =============================================================================\n\n# iSamples material vocabulary hierarchy (3 levels)\n# Structure: (display_name, uri_suffix, children_list)\n# uri_suffix maps to actual URIs in the data\n\nMATERIAL_HIERARCHY = [\n    (\"Material\", \"material\", [\n        (\"Natural Solid Material\", \"naturalsolidmaterial\", [\n            (\"Earth Material\", \"earthmaterial\", [\n                (\"Rock\", \"rock\", []),\n                (\"Sediment\", \"sediment\", []),\n                (\"Soil\", \"soil\", []),\n                (\"Mineral\", \"mineral\", []),\n                (\"Mixed Soil/Sediment/Rock\", \"mixedsoilsedimentrock\", []),\n            ]),\n            (\"Biogenic Non-organic\", \"biogenicnonorganicmaterial\", []),\n        ]),\n        (\"Organic Material\", \"organicmaterial\", [\n            (\"Plant Material\", \"plantmaterial\", []),\n            (\"Animal Product\", \"organicanimalproduct\", []),\n        ]),\n        (\"Anthropogenic Material\", \"anyanthropogenicmaterial\", [\n            (\"Anthropogenic Metal\", \"anthropogenicmetal\", []),\n            (\"Ceramic Clay\", \"ceramicclay\", []),\n        ]),\n        (\"Fluid Material\", \"fluidmaterial\", [\n            (\"Liquid Water\", \"liquidwater\", []),\n            (\"Gas\", \"gas\", []),\n            (\"Non-aqueous Liquid\", \"nonaqueousliquid\", []),\n        ]),\n        (\"Dispersed Media\", \"dispersedmedia\", [\n            (\"Particulate\", \"particulate\", []),\n        ]),\n        (\"Any Ice\", \"anyice\", []),\n    ])\n]\n\n\ndef build_hierarchy_mappings():\n    \"\"\"\n    Build mappings for the material hierarchy.\n\n    Returns:\n        - suffix_to_children: dict mapping uri_suffix -> list of all descendant suffixes\n        - display_order: list of (display_label, uri_suffix, indent_level) in tree order\n    \"\"\"\n    suffix_to_children = {}\n    display_order = []\n\n    def collect_descendants(nodes):\n        \"\"\"Get all descendant suffixes from a list of hierarchy nodes.\"\"\"\n        descendants = []\n        for name, suffix, children in nodes:\n            descendants.append(suffix)\n            descendants.extend(collect_descendants(children))\n        return descendants\n\n    def walk(nodes, level=0):\n        \"\"\"Walk hierarchy building mappings.\"\"\"\n        for name, suffix, children in nodes:\n            # All descendants (not including self)\n            suffix_to_children[suffix] = collect_descendants(children)\n\n            # Add to display order with indentation\n            display_order.append((name, suffix, level))\n\n            # Recurse into children\n            walk(children, level + 1)\n\n    walk(MATERIAL_HIERARCHY)\n    return suffix_to_children, display_order\n\n\n# Build hierarchy mappings at module load\nSUFFIX_TO_CHILDREN, HIERARCHY_DISPLAY_ORDER = build_hierarchy_mappings()\n\n\n# =============================================================================\n# Facet Query Functions\n# =============================================================================\n\nimport re\nimport time as time_module\n\ndef uri_to_display_name(uri):\n    \"\"\"\n    Convert a vocabulary URI to a human-readable display name.\n\n    Examples:\n        https://w3id.org/isample/vocabulary/material/1.0/rock -> Rock\n        https://w3id.org/isample/opencontext/material/0.1/ceramicclay -> Ceramic Clay\n    \"\"\"\n    if not uri or not isinstance(uri, str):\n        return str(uri)\n\n    # Extract last path segment\n    name = uri.rstrip('/').split('/')[-1]\n\n    # Insert spaces before uppercase letters (camelCase -> Camel Case)\n    name = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', name)\n\n    # Capitalize first letter of each word\n    name = name.title()\n\n    return name\n\n\ndef uri_to_suffix(uri):\n    \"\"\"Extract the suffix (last path segment) from a URI, lowercased.\"\"\"\n    if not uri or not isinstance(uri, str):\n        return \"\"\n    return uri.rstrip('/').split('/')[-1].lower()\n\n\ndef get_source_counts(additional_filters=None):\n    \"\"\"\n    Get counts of samples by source.\n\n    Args:\n        additional_filters: Dict with material_filters, year_range keys\n\n    Returns:\n        Dict of {source_name: count}\n    \"\"\"\n    where_clause = \"WHERE otype = 'MaterialSampleRecord' AND latitude IS NOT NULL\"\n\n    # Apply year filter if present (cast result_time to TIMESTAMP)\n    if additional_filters and additional_filters.get('year_range'):\n        yr = additional_filters['year_range']\n        if yr[0] is not None and yr[1] is not None:\n            where_clause += f\" AND EXTRACT(YEAR FROM TRY_CAST(result_time AS TIMESTAMP)) BETWEEN {yr[0]} AND {yr[1]}\"\n        elif yr[0] is not None:\n            where_clause += f\" AND EXTRACT(YEAR FROM TRY_CAST(result_time AS TIMESTAMP)) >= {yr[0]}\"\n        elif yr[1] is not None:\n            where_clause += f\" AND EXTRACT(YEAR FROM TRY_CAST(result_time AS TIMESTAMP)) <= {yr[1]}\"\n\n    # Note: We don't filter by material here to show all source options\n    query = f\"\"\"\n        SELECT n as source, COUNT(*) as count\n        FROM read_parquet('{PARQUET_PATH}')\n        {where_clause}\n        GROUP BY n ORDER BY count DESC\n    \"\"\"\n\n    result = con.sql(query).df()\n    return dict(zip(result['source'], result['count']))\n\n\ndef get_all_material_counts():\n    \"\"\"\n    Get counts for ALL materials in the hierarchy (not just top N).\n    Used for building the hierarchical display.\n\n    Returns:\n        Dict of {uri_suffix: {'uri': full_uri, 'count': count}}\n    \"\"\"\n    query = f\"\"\"\n        WITH samples AS (\n            SELECT msr.row_id, UNNEST(msr.p__has_material_category) as material_id\n            FROM read_parquet('{PARQUET_PATH}') msr\n            WHERE msr.otype = 'MaterialSampleRecord' AND msr.latitude IS NOT NULL\n        )\n        SELECT ic.label as material_uri, COUNT(*) as count\n        FROM samples s\n        JOIN read_parquet('{PARQUET_PATH}') ic ON ic.row_id = s.material_id\n        WHERE ic.label IS NOT NULL\n        GROUP BY ic.label\n        ORDER BY count DESC\n    \"\"\"\n\n    try:\n        result = con.sql(query).df()\n        # Build dict keyed by suffix\n        materials = {}\n        for _, row in result.iterrows():\n            uri = row['material_uri']\n            suffix = uri_to_suffix(uri)\n            if suffix:\n                materials[suffix] = {\n                    'uri': uri,\n                    'count': row['count']\n                }\n        return materials\n    except Exception as e:\n        print(f\"Material count error: {e}\")\n        return {}\n\n\n# =============================================================================\n# Accurate Rollup Counts (with caching)\n# =============================================================================\n\n# Cache for accurate rollup counts\n_rollup_cache = {\n    'direct_counts': {},      # suffix -> direct count\n    'rollup_counts': {},      # suffix -> accurate distinct rollup count\n    'computed_at': None,      # timestamp\n    'existing_suffixes': set()  # suffixes that exist in data\n}\n\n\ndef compute_accurate_rollup_counts(force_refresh=False):\n    \"\"\"\n    Compute accurate rollup counts using DISTINCT sample counting.\n    \n    This avoids double-counting samples tagged at multiple hierarchy levels.\n    Results are cached for performance.\n    \n    Args:\n        force_refresh: If True, recompute even if cache exists\n        \n    Returns:\n        Tuple of (direct_counts, rollup_counts, elapsed_time)\n        - direct_counts: Dict of {suffix: count} for samples tagged exactly at that level\n        - rollup_counts: Dict of {suffix: count} for samples tagged at that level OR any descendant\n    \"\"\"\n    global _rollup_cache\n    \n    # Return cached results if available and not forcing refresh\n    if not force_refresh and _rollup_cache['computed_at'] is not None:\n        return (_rollup_cache['direct_counts'], \n                _rollup_cache['rollup_counts'], \n                0.0)\n    \n    print(\"Computing accurate rollup counts (this takes ~3 seconds)...\")\n    t0 = time_module.time()\n    \n    # Build temp table with sample-material pairs\n    build_query = f\"\"\"\n        CREATE OR REPLACE TEMP TABLE sample_materials AS\n        SELECT DISTINCT \n            msr.row_id as sample_id,\n            LOWER(SPLIT_PART(ic.label, '/', -1)) as suffix,\n            ic.label as uri\n        FROM read_parquet('{PARQUET_PATH}') msr\n        CROSS JOIN UNNEST(msr.p__has_material_category) AS t(mat_id)\n        JOIN read_parquet('{PARQUET_PATH}') ic ON ic.row_id = mat_id\n        WHERE msr.otype = 'MaterialSampleRecord' \n          AND msr.latitude IS NOT NULL\n          AND ic.label IS NOT NULL\n    \"\"\"\n    con.sql(build_query)\n    \n    # Get existing suffixes\n    suffix_df = con.sql(\"SELECT DISTINCT suffix FROM sample_materials\").df()\n    existing_suffixes = set(suffix_df['suffix'].tolist())\n    \n    # Get direct counts\n    direct_df = con.sql(\"\"\"\n        SELECT suffix, COUNT(*) as direct_count\n        FROM sample_materials\n        GROUP BY suffix\n    \"\"\").df()\n    direct_counts = dict(zip(direct_df['suffix'], direct_df['direct_count']))\n    \n    # Compute accurate rollup for each suffix\n    rollup_counts = {}\n    for suffix in existing_suffixes:\n        if suffix not in SUFFIX_TO_CHILDREN:\n            # Unknown suffix (not in our hierarchy), just use direct count\n            rollup_counts[suffix] = direct_counts.get(suffix, 0)\n        else:\n            # Include self + all descendants that exist in data\n            all_suffixes = [suffix] + [s for s in SUFFIX_TO_CHILDREN[suffix] if s in existing_suffixes]\n            suffixes_sql = \", \".join(f\"'{s}'\" for s in all_suffixes)\n            count_query = f\"SELECT COUNT(DISTINCT sample_id) FROM sample_materials WHERE suffix IN ({suffixes_sql})\"\n            count = con.sql(count_query).fetchone()[0]\n            rollup_counts[suffix] = count\n    \n    elapsed = time_module.time() - t0\n    \n    # Update cache\n    _rollup_cache['direct_counts'] = direct_counts\n    _rollup_cache['rollup_counts'] = rollup_counts\n    _rollup_cache['computed_at'] = time_module.time()\n    _rollup_cache['existing_suffixes'] = existing_suffixes\n    \n    print(f\"  Computed {len(rollup_counts)} rollup counts in {elapsed:.2f}s\")\n    \n    return direct_counts, rollup_counts, elapsed\n\n\ndef get_cached_rollup_counts():\n    \"\"\"Get cached rollup counts, computing if necessary.\"\"\"\n    if _rollup_cache['computed_at'] is None:\n        compute_accurate_rollup_counts()\n    return _rollup_cache['direct_counts'], _rollup_cache['rollup_counts']\n\n\ndef get_material_counts(additional_filters=None, limit=50):\n    \"\"\"\n    Get counts of samples by material category (requires join for labels).\n\n    Args:\n        additional_filters: Dict with source_filters, year_range keys\n        limit: Max number of materials to return\n\n    Returns:\n        Dict of {display_name: {'uri': full_uri, 'count': count}}\n    \"\"\"\n    where_clause = \"WHERE msr.otype = 'MaterialSampleRecord' AND msr.latitude IS NOT NULL\"\n\n    # Apply source filter if present\n    if additional_filters and additional_filters.get('source_filters'):\n        sources_sql = \", \".join(f\"'{s}'\" for s in additional_filters['source_filters'])\n        where_clause += f\" AND msr.n IN ({sources_sql})\"\n\n    # Apply year filter if present (cast result_time to TIMESTAMP)\n    if additional_filters and additional_filters.get('year_range'):\n        yr = additional_filters['year_range']\n        if yr[0] is not None and yr[1] is not None:\n            where_clause += f\" AND EXTRACT(YEAR FROM TRY_CAST(msr.result_time AS TIMESTAMP)) BETWEEN {yr[0]} AND {yr[1]}\"\n        elif yr[0] is not None:\n            where_clause += f\" AND EXTRACT(YEAR FROM TRY_CAST(msr.result_time AS TIMESTAMP)) >= {yr[0]}\"\n        elif yr[1] is not None:\n            where_clause += f\" AND EXTRACT(YEAR FROM TRY_CAST(msr.result_time AS TIMESTAMP)) <= {yr[1]}\"\n\n    query = f\"\"\"\n        WITH samples AS (\n            SELECT msr.row_id, UNNEST(msr.p__has_material_category) as material_id\n            FROM read_parquet('{PARQUET_PATH}') msr\n            {where_clause}\n        )\n        SELECT ic.label as material_uri, COUNT(*) as count\n        FROM samples s\n        JOIN read_parquet('{PARQUET_PATH}') ic ON ic.row_id = s.material_id\n        WHERE ic.label IS NOT NULL\n        GROUP BY ic.label\n        ORDER BY count DESC\n        LIMIT {limit}\n    \"\"\"\n\n    try:\n        result = con.sql(query).df()\n        # Return dict with display name as key, containing uri and count\n        materials = {}\n        for _, row in result.iterrows():\n            uri = row['material_uri']\n            display_name = uri_to_display_name(uri)\n            materials[display_name] = {\n                'uri': uri,\n                'count': row['count']\n            }\n        return materials\n    except Exception as e:\n        print(f\"Material count error: {e}\")\n        return {}\n\n\ndef get_year_range_stats():\n    \"\"\"\n    Get min/max years and decade counts for time facet.\n\n    Returns:\n        Dict with 'min_year', 'max_year', 'decades' (dict of decade: count)\n    \"\"\"\n    # Cast result_time to TIMESTAMP before extracting year\n    query = f\"\"\"\n        SELECT\n            MIN(EXTRACT(YEAR FROM TRY_CAST(result_time AS TIMESTAMP)))::INT as min_year,\n            MAX(EXTRACT(YEAR FROM TRY_CAST(result_time AS TIMESTAMP)))::INT as max_year\n        FROM read_parquet('{PARQUET_PATH}')\n        WHERE otype = 'MaterialSampleRecord'\n          AND latitude IS NOT NULL\n          AND result_time IS NOT NULL\n          AND TRY_CAST(result_time AS TIMESTAMP) IS NOT NULL\n    \"\"\"\n\n    stats = con.sql(query).df().iloc[0]\n\n    # Get decade counts\n    decade_query = f\"\"\"\n        SELECT\n            (EXTRACT(YEAR FROM TRY_CAST(result_time AS TIMESTAMP))::INT / 10) * 10 as decade,\n            COUNT(*) as count\n        FROM read_parquet('{PARQUET_PATH}')\n        WHERE otype = 'MaterialSampleRecord'\n          AND latitude IS NOT NULL\n          AND result_time IS NOT NULL\n          AND TRY_CAST(result_time AS TIMESTAMP) IS NOT NULL\n        GROUP BY decade\n        ORDER BY decade\n    \"\"\"\n\n    decades_df = con.sql(decade_query).df()\n    decades = dict(zip(decades_df['decade'].astype(int), decades_df['count']))\n\n    return {\n        'min_year': int(stats['min_year']) if pd.notna(stats['min_year']) else 1900,\n        'max_year': int(stats['max_year']) if pd.notna(stats['max_year']) else 2025,\n        'decades': decades\n    }\n\n\ndef expand_material_filters_with_rollup(selected_uris, all_material_counts):\n    \"\"\"\n    Expand selected URIs to include all descendant URIs (rollup).\n\n    Args:\n        selected_uris: Set of user-selected material URIs\n        all_material_counts: Dict from get_all_material_counts()\n\n    Returns:\n        Set of URIs including selected + all descendants\n    \"\"\"\n    expanded = set(selected_uris)\n\n    for uri in selected_uris:\n        suffix = uri_to_suffix(uri)\n        if suffix in SUFFIX_TO_CHILDREN:\n            # Add all descendant URIs\n            for child_suffix in SUFFIX_TO_CHILDREN[suffix]:\n                # Find the full URI for this suffix\n                if child_suffix in all_material_counts:\n                    expanded.add(all_material_counts[child_suffix]['uri'])\n\n    return expanded\n\n\n# =============================================================================\n# Facet Widgets\n# =============================================================================\n\n# Get initial counts for facets\nprint(\"Loading facet counts...\")\ninitial_source_counts = get_source_counts()\nall_material_counts = get_all_material_counts()  # Get all for hierarchy\ndirect_counts, rollup_counts = get_cached_rollup_counts()  # Compute accurate rollup\nyear_stats = get_year_range_stats()\n\nprint(f\"Sources: {list(initial_source_counts.keys())}\")\nprint(f\"Materials: {len(all_material_counts)} types found in data\")\nprint(f\"Years: {year_stats['min_year']} - {year_stats['max_year']}\")\nprint(f\"Decades with data: {sorted(year_stats['decades'].keys())}\")\n\n\ndef build_hierarchical_material_options(material_counts, direct_counts_dict, rollup_counts_dict, use_rollup=True):\n    \"\"\"\n    Build SelectMultiple options showing material hierarchy with indentation.\n\n    Args:\n        material_counts: Dict from get_all_material_counts() keyed by suffix (for URIs)\n        direct_counts_dict: Dict of {suffix: direct_count}\n        rollup_counts_dict: Dict of {suffix: accurate_rollup_count}\n        use_rollup: If True, show rollup totals; if False, show direct counts\n\n    Returns:\n        - options: List of option labels (with indentation and counts)\n        - uri_map: Dict mapping option label -> full URI\n    \"\"\"\n    options = []\n    uri_map = {}\n\n    # Indentation characters\n    INDENT = \"    \"  # 4 spaces per level\n\n    for display_name, suffix, level in HIERARCHY_DISPLAY_ORDER:\n        if suffix in material_counts:\n            data = material_counts[suffix]\n            uri = data['uri']\n\n            # Choose count based on rollup setting\n            if use_rollup:\n                count = rollup_counts_dict.get(suffix, direct_counts_dict.get(suffix, 0))\n            else:\n                count = direct_counts_dict.get(suffix, 0)\n\n            # Create indented label\n            indent = INDENT * level\n            label = f\"{indent}{display_name} ({count:,})\"\n\n            options.append(label)\n            uri_map[label] = uri\n\n    return options, uri_map\n\n\n# Build initial hierarchical material options (with rollup ON by default)\nmaterial_options, material_uri_map = build_hierarchical_material_options(\n    all_material_counts, direct_counts, rollup_counts, use_rollup=True\n)\nprint(f\"Hierarchy has {len(material_options)} materials with data\")\n\n\ndef create_source_checkboxes(counts):\n    \"\"\"Create checkboxes for source facet.\"\"\"\n    checkboxes = []\n    for source, count in counts.items():\n        cb = widgets.Checkbox(\n            value=False,\n            description=f\"{source} ({count:,})\",\n            indent=False,\n            layout=widgets.Layout(width='100%', margin='2px 0')\n        )\n        cb.source_name = source  # Store source name for easy access\n        checkboxes.append(cb)\n    return checkboxes\n\n\n# Create source checkboxes\nsource_checkboxes = create_source_checkboxes(initial_source_counts)\nsource_facet_box = widgets.VBox(\n    source_checkboxes,\n    layout=widgets.Layout(max_height='180px', overflow_y='auto', padding='5px')\n)\n\n# Use SelectMultiple for materials - hierarchical display with indentation\nmaterial_select = widgets.SelectMultiple(\n    options=material_options,\n    value=[],\n    rows=12,  # More rows to see hierarchy\n    description='',\n    layout=widgets.Layout(width='100%', height='280px'),\n    style={'description_width': '0px'}\n)\n\n# Rollup toggle\nrollup_toggle = widgets.Checkbox(\n    value=True,\n    description='Include subcategories',\n    indent=False,\n    layout=widgets.Layout(margin='5px 0'),\n    style={'description_width': 'initial'}\n)\n\n# Refresh counts button\nrefresh_counts_btn = widgets.Button(\n    description='',\n    button_style='',\n    icon='refresh',\n    tooltip='Recalculate material counts',\n    layout=widgets.Layout(width='32px', height='26px')\n)\n\nmaterial_header = widgets.HBox([\n    widgets.HTML(\"<small style='color:#666;'>Ctrl/Cmd+click to multi-select</small>\"),\n    refresh_counts_btn\n], layout=widgets.Layout(justify_content='space-between', align_items='center'))\n\nmaterial_facet_box = widgets.VBox([\n    material_header,\n    rollup_toggle,\n    material_select\n], layout=widgets.Layout(padding='5px'))\n\n\n# =============================================================================\n# Time Facet Widgets (with decade checkboxes)\n# =============================================================================\n\ndef create_decade_checkboxes(decade_counts):\n    \"\"\"Create checkboxes for decade quick-select.\"\"\"\n    checkboxes = []\n    # Sort decades and filter to reasonable range (1800-2030)\n    sorted_decades = sorted([d for d in decade_counts.keys() if 1800 <= d <= 2030])\n\n    for decade in sorted_decades:\n        count = decade_counts.get(decade, 0)\n        if count > 0:  # Only show decades with data\n            cb = widgets.Checkbox(\n                value=False,\n                description=f\"{decade}s ({count:,})\",\n                indent=False,\n                layout=widgets.Layout(width='100%', margin='1px 0')\n            )\n            cb.decade_value = decade  # Store decade value for easy access\n            checkboxes.append(cb)\n    return checkboxes\n\n\ndecade_checkboxes = create_decade_checkboxes(year_stats['decades'])\n\n# Container for decade checkboxes (scrollable if many decades)\ndecade_box = widgets.VBox(\n    decade_checkboxes,\n    layout=widgets.Layout(max_height='140px', overflow_y='auto', padding='2px')\n)\n\ndecade_label = widgets.HTML(\"<small style='color:#666;'>Quick select decades:</small>\")\n\nyear_slider = widgets.IntRangeSlider(\n    value=[year_stats['min_year'], year_stats['max_year']],\n    min=year_stats['min_year'],\n    max=year_stats['max_year'],\n    step=1,\n    description='Range:',\n    continuous_update=False,\n    layout=widgets.Layout(width='100%'),\n    style={'description_width': '50px'}\n)\n\n# Enable/disable time filter\ntime_filter_enabled = widgets.Checkbox(\n    value=False,\n    description='Filter by time',\n    indent=False,\n    layout=widgets.Layout(margin='5px 0')\n)\n\n# Sync mode: when True, decade checkboxes auto-update the slider\nsync_decades_to_slider = widgets.Checkbox(\n    value=True,\n    description='Sync decades to slider',\n    indent=False,\n    layout=widgets.Layout(margin='2px 0'),\n    style={'description_width': 'initial'}\n)\n\ntime_facet_box = widgets.VBox([\n    time_filter_enabled,\n    decade_label,\n    decade_box,\n    widgets.HTML(\"<small style='color:#666; margin-top:5px;'>Fine-tune range:</small>\"),\n    year_slider,\n    sync_decades_to_slider\n], layout=widgets.Layout(padding='5px'))\n\n\n# Create accordion\nfacet_accordion = widgets.Accordion(\n    children=[source_facet_box, material_facet_box, time_facet_box],\n    titles=['Sources', 'Material Type', 'Time Period'],\n    layout=widgets.Layout(width='100%')\n)\nfacet_accordion.selected_index = None  # Start collapsed\n\n# Clear all filters button\nclear_filters_btn = widgets.Button(\n    description='Clear All Filters',\n    button_style='warning',\n    icon='times-circle',\n    layout=widgets.Layout(width='100%', margin='10px 0')\n)\n\n\n# =============================================================================\n# Original Widgets (preserved)\n# =============================================================================\n\nsource_filter = widgets.Dropdown(\n    options=['All Sources', 'SESAR', 'OPENCONTEXT', 'GEOME', 'SMITHSONIAN'],\n    value='All Sources',\n    description='Source:',\n    style={'description_width': '60px'},\n    layout=widgets.Layout(display='none')  # Hidden - replaced by facet\n)\n\nsearch_input = widgets.Text(\n    value='',\n    placeholder='Search label, description, place...',\n    description='Search:',\n    style={'description_width': '60px'},\n    layout=widgets.Layout(width='280px')\n)\n\nsearch_btn = widgets.Button(\n    description='',\n    button_style='',\n    icon='search',\n    tooltip='Search (or press Enter)',\n    layout=widgets.Layout(width='40px')\n)\n\nclear_search_btn = widgets.Button(\n    description='',\n    button_style='',\n    icon='times',\n    tooltip='Clear search',\n    layout=widgets.Layout(width='40px')\n)\n\nsample_count = widgets.IntSlider(\n    value=12500,\n    min=1000,\n    max=500000,  # 500K per source - plenty for 128GB RAM\n    step=5000,\n    description='Per source:',\n    style={'description_width': '80px'}\n)\n\nviewport_toggle = widgets.ToggleButton(\n    value=False,\n    description='Viewport Mode',\n    tooltip='When enabled, automatically loads data for current map view',\n    icon='map',\n    button_style=''  # 'success' when active\n)\n\nrefresh_btn = widgets.Button(\n    description='Refresh Data',\n    button_style='primary',\n    icon='refresh'\n)\n\n# Loading indicator with spinner\nloading_indicator = widgets.HTML(value=\"\")\n\nstatus_label = widgets.HTML(value=f\"<b>Loaded:</b> {len(samples_gdf):,} samples\")\n\ncard_output = widgets.HTML(value=render_sample_card(None))\n\n# Active filters display\nactive_filters_html = widgets.HTML(value=\"\")\n\n\ndef update_active_filters_display():\n    \"\"\"Update the display of currently active filters.\"\"\"\n    filters = []\n\n    if state.source_filters:\n        filters.append(f\"<span style='background:#3366CC; color:white; padding:2px 6px; border-radius:3px; margin:2px;'>Sources: {', '.join(state.source_filters)}</span>\")\n\n    if state.material_filters:\n        # Get display names from selected options\n        mat_names = [uri_to_display_name(uri) for uri in state.material_filters]\n        mat_display = mat_names[:2]\n        if len(mat_names) > 2:\n            mat_display.append(f\"+{len(mat_names)-2} more\")\n        rollup_indicator = \" (+sub)\" if state.material_rollup else \"\"\n        filters.append(f\"<span style='background:#109618; color:white; padding:2px 6px; border-radius:3px; margin:2px;'>Materials: {', '.join(mat_display)}{rollup_indicator}</span>\")\n\n    if state.year_range[0] is not None or state.year_range[1] is not None:\n        yr_str = f\"{state.year_range[0] or 'any'} - {state.year_range[1] or 'any'}\"\n        # Show selected decades if any\n        if state.selected_decades:\n            decades_str = ', '.join(f\"{d}s\" for d in sorted(state.selected_decades))\n            filters.append(f\"<span style='background:#FF9900; color:white; padding:2px 6px; border-radius:3px; margin:2px;'>Time: {decades_str} ({yr_str})</span>\")\n        else:\n            filters.append(f\"<span style='background:#FF9900; color:white; padding:2px 6px; border-radius:3px; margin:2px;'>Years: {yr_str}</span>\")\n\n    if filters:\n        active_filters_html.value = f\"<div style='margin:5px 0;'><b>Active:</b> {''.join(filters)}</div>\"\n    else:\n        active_filters_html.value = \"\"\n\n\ndef show_loading(message=\"Loading...\"):\n    \"\"\"Show loading indicator.\"\"\"\n    state.loading = True\n    loading_indicator.value = f\"\"\"\n    <div style=\"display: inline-flex; align-items: center; color: #666;\">\n        <svg width=\"20\" height=\"20\" viewBox=\"0 0 50 50\" style=\"animation: spin 1s linear infinite; margin-right: 8px;\">\n            <circle cx=\"25\" cy=\"25\" r=\"20\" fill=\"none\" stroke=\"#3366CC\" stroke-width=\"4\" stroke-dasharray=\"80,40\"/>\n        </svg>\n        <style>@keyframes spin {{ from {{ transform: rotate(0deg); }} to {{ transform: rotate(360deg); }} }}</style>\n        <span>{message}</span>\n    </div>\n    \"\"\"\n\n\ndef hide_loading():\n    \"\"\"Hide loading indicator.\"\"\"\n    state.loading = False\n    loading_indicator.value = \"\"\n\n\ndef select_sample(idx, source='map'):\n    \"\"\"\n    Select a sample by index and sync map/table/card.\n\n    Args:\n        idx: Row index in current_gdf\n        source: 'map' or 'table' - which triggered the selection\n    \"\"\"\n    if idx is None or idx >= len(state.current_gdf):\n        return\n\n    state.selected_index = idx\n    state.selected_row = state.current_gdf.iloc[idx]\n\n    # Update sample card\n    card_output.value = render_sample_card(state.selected_row)\n\n    if source == 'map':\n        # Map click -> highlight table row\n        # Column count depends on whether we're showing search_score\n        col_count = 4 if state.current_search else 3\n        sample_table.selections = [{'r1': idx, 'c1': 0, 'r2': idx, 'c2': col_count}]\n\n    elif source == 'table':\n        # Table click -> recenter map (keep current zoom)\n        lat = state.selected_row['latitude']\n        lon = state.selected_row['longitude']\n        if not pd.isna(lat) and not pd.isna(lon):\n            sample_map.set_view_state(latitude=float(lat), longitude=float(lon))\n\n\ndef on_map_point_click(change):\n    \"\"\"Handle click on a map point - highlight corresponding table row.\"\"\"\n    if state.syncing_selection:\n        return\n\n    idx = change.get('new')\n    if idx is None:\n        return\n\n    state.syncing_selection = True\n    try:\n        select_sample(idx, source='map')\n    finally:\n        state.syncing_selection = False\n\n\ndef setup_layer_observer(layer):\n    \"\"\"Setup the selected_index observer on a layer.\"\"\"\n    layer.observe(on_map_point_click, names=['selected_index'])\n\n\ndef update_map_and_table(new_gdf, search_active=False):\n    \"\"\"Update map and table with new data.\"\"\"\n    state.current_gdf = new_gdf\n    state.current_search = search_input.value.strip() if search_active else \"\"\n\n    # Update map with new layer\n    new_layer = create_map_layer(new_gdf)\n\n    # Setup observer on new layer BEFORE adding to map\n    setup_layer_observer(new_layer)\n\n    sample_map.layers = [new_layer]\n\n    # Update table - include score column if searching\n    if search_active and 'search_score' in new_gdf.columns:\n        display_cols = ['search_score', 'source', 'label', 'latitude', 'longitude']\n        df_display = new_gdf[display_cols].copy()\n        df_display = df_display.rename(columns={'search_score': 'score'})\n    else:\n        display_cols = ['source', 'label', 'latitude', 'longitude']\n        df_display = new_gdf[display_cols].copy()\n\n    df_display['latitude'] = df_display['latitude'].round(4)\n    df_display['longitude'] = df_display['longitude'].round(4)\n    sample_table.data = df_display\n\n    # Update status\n    if search_active:\n        status_label.value = f\"<b>Found:</b> {len(new_gdf):,} matches for '{state.current_search}'\"\n    else:\n        status_label.value = f\"<b>Loaded:</b> {len(new_gdf):,} samples\"\n\n    # Update active filters display\n    update_active_filters_display()\n\n\ndef get_effective_material_filters():\n    \"\"\"\n    Get the effective set of material URIs to filter by,\n    applying rollup expansion if enabled.\n    \"\"\"\n    if not state.material_filters:\n        return None\n\n    if state.material_rollup:\n        # Expand to include descendants\n        return expand_material_filters_with_rollup(state.material_filters, all_material_counts)\n    else:\n        # Exact match only\n        return state.material_filters\n\n\ndef update_material_widget_options():\n    \"\"\"\n    Update material SelectMultiple options based on rollup toggle.\n    Preserves current selection when possible.\n    \"\"\"\n    global material_uri_map\n\n    # Remember current selection (by URI)\n    current_uris = set()\n    for option_label in material_select.value:\n        if option_label in material_uri_map:\n            current_uris.add(material_uri_map[option_label])\n\n    # Get cached counts\n    direct_cts, rollup_cts = get_cached_rollup_counts()\n\n    # Rebuild options with new rollup setting\n    new_options, new_uri_map = build_hierarchical_material_options(\n        all_material_counts, direct_cts, rollup_cts, use_rollup=rollup_toggle.value\n    )\n\n    # Update the global uri_map\n    material_uri_map = new_uri_map\n\n    # Update widget options\n    material_select.options = new_options\n\n    # Restore selection (find labels for remembered URIs)\n    new_selection = []\n    for label, uri in new_uri_map.items():\n        if uri in current_uris:\n            new_selection.append(label)\n\n    material_select.value = tuple(new_selection)\n\n\ndef do_search():\n    \"\"\"Execute search with current parameters.\"\"\"\n    show_loading(\"Searching...\")\n\n    try:\n        # Use facet filters instead of single source dropdown\n        source_filters_set = state.source_filters if state.source_filters else None\n        material_filters_set = get_effective_material_filters()  # Apply rollup if enabled\n        year_range = state.year_range if (state.year_range[0] is not None or state.year_range[1] is not None) else None\n\n        search_term = search_input.value.strip()\n\n        if state.viewport_mode:\n            # Search within current viewport\n            view_state = sample_map.view_state\n            zoom = view_state.zoom if hasattr(view_state, 'zoom') else 1\n            bbox = view_state_to_bbox(view_state)\n\n            # When searching, use slider value directly (no adaptive reduction)\n            # When browsing, use adaptive sampling based on zoom\n            if search_term:\n                max_samples = sample_count.value\n            else:\n                max_samples = adaptive_sample_size(zoom, base_size=sample_count.value)\n\n            new_gdf = load_samples(\n                max_per_source=max_samples,\n                bbox=bbox,\n                search_term=search_term if search_term else None,\n                source_filters=source_filters_set,\n                material_filters=material_filters_set,\n                year_range=year_range\n            )\n\n            zoom_info = f\" (zoom {zoom:.1f})\"\n        else:\n            # Search globally\n            new_gdf = load_samples(\n                max_per_source=sample_count.value,\n                search_term=search_term if search_term else None,\n                source_filters=source_filters_set,\n                material_filters=material_filters_set,\n                year_range=year_range\n            )\n            zoom_info = \"\"\n\n        update_map_and_table(new_gdf, search_active=bool(search_term))\n\n        if search_term:\n            status_label.value = f\"<b>Found:</b> {len(new_gdf):,} matches for '{search_term}'{zoom_info}\"\n        else:\n            status_label.value = f\"<b>Loaded:</b> {len(new_gdf):,} samples{zoom_info}\"\n\n    except Exception as e:\n        status_label.value = f\"<b>Error:</b> {str(e)[:50]}\"\n        import traceback\n        traceback.print_exc()\n    finally:\n        hide_loading()\n\n\ndef on_search_click(b):\n    \"\"\"Handle search button click.\"\"\"\n    do_search()\n\n\ndef on_search_submit(change):\n    \"\"\"Handle Enter key in search box.\"\"\"\n    do_search()\n\n\ndef on_clear_search(b):\n    \"\"\"Clear search and reload data.\"\"\"\n    search_input.value = ''\n    do_search()\n\n\nsearch_btn.on_click(on_search_click)\nsearch_input.on_submit(on_search_submit)\nclear_search_btn.on_click(on_clear_search)\n\n\ndef load_viewport_data():\n    \"\"\"Load data for current viewport with adaptive sampling.\"\"\"\n    if state.loading:\n        return\n\n    show_loading(\"Loading viewport data...\")\n\n    try:\n        # Get current view state\n        view_state = sample_map.view_state\n        zoom = view_state.zoom if hasattr(view_state, 'zoom') else 1\n\n        # Calculate bounding box\n        bbox = view_state_to_bbox(view_state)\n\n        # Get facet filters and search term\n        source_filters_set = state.source_filters if state.source_filters else None\n        material_filters_set = get_effective_material_filters()  # Apply rollup if enabled\n        year_range = state.year_range if (state.year_range[0] is not None or state.year_range[1] is not None) else None\n        search_term = search_input.value.strip() if search_input.value.strip() else None\n\n        # When searching, use slider value directly (no adaptive reduction)\n        # When browsing, use adaptive sampling based on zoom\n        if search_term:\n            max_samples = sample_count.value\n        else:\n            max_samples = adaptive_sample_size(zoom, base_size=sample_count.value)\n\n        # Load data\n        new_gdf = load_samples(\n            max_per_source=max_samples,\n            bbox=bbox,\n            search_term=search_term,\n            source_filters=source_filters_set,\n            material_filters=material_filters_set,\n            year_range=year_range\n        )\n\n        update_map_and_table(new_gdf, search_active=bool(search_term))\n\n        # Show zoom info in status\n        if search_term:\n            status_label.value = f\"<b>Found:</b> {len(new_gdf):,} matches for '{search_term}' (zoom {zoom:.1f})\"\n        else:\n            status_label.value = f\"<b>Loaded:</b> {len(new_gdf):,} samples (zoom {zoom:.1f}, {max_samples:,}/source max)\"\n\n    except Exception as e:\n        status_label.value = f\"<b>Error:</b> {str(e)[:50]}\"\n    finally:\n        hide_loading()\n\n\ndef debounced_viewport_load():\n    \"\"\"Debounced viewport loading - waits for user to stop panning/zooming.\"\"\"\n    # Cancel any existing timer\n    if state.debounce_timer is not None:\n        state.debounce_timer.cancel()\n\n    # Set new timer (500ms delay)\n    state.debounce_timer = threading.Timer(0.5, load_viewport_data)\n    state.debounce_timer.start()\n\n\ndef on_view_state_change(change):\n    \"\"\"Handle map pan/zoom changes.\"\"\"\n    if state.viewport_mode and not state.loading:\n        debounced_viewport_load()\n\n\ndef on_viewport_toggle(change):\n    \"\"\"Handle viewport mode toggle.\"\"\"\n    state.viewport_mode = change['new']\n    if change['new']:\n        viewport_toggle.button_style = 'success'\n        viewport_toggle.description = 'Viewport Mode ON'\n        # Immediately load viewport data\n        load_viewport_data()\n    else:\n        viewport_toggle.button_style = ''\n        viewport_toggle.description = 'Viewport Mode'\n\n\nviewport_toggle.observe(on_viewport_toggle, names=['value'])\n\n\n# Event handlers\ndef on_refresh_click(b):\n    do_search()  # Refresh now uses same logic as search\n\nrefresh_btn.on_click(on_refresh_click)\n\n\ndef on_table_selection(change):\n    \"\"\"Handle table row selection - recenter map on selected point.\"\"\"\n    if state.syncing_selection:\n        return\n\n    # selections is a LIST of selection dicts\n    selections = change.get('new', [])\n    if selections and len(selections) > 0:\n        # Get the first selection\n        sel = selections[0]\n        row_idx = sel.get('r1')\n        if row_idx is not None and row_idx < len(state.current_gdf):\n            state.syncing_selection = True\n            try:\n                select_sample(row_idx, source='table')\n            finally:\n                state.syncing_selection = False\n\nsample_table.observe(on_table_selection, names=['selections'])\n\n# Register view_state observer on the map\nsample_map.observe(on_view_state_change, names=['view_state'])\n\n# Setup observer on initial layer\nsetup_layer_observer(sample_map.layers[0])\n\n\n# =============================================================================\n# Facet Event Handlers\n# =============================================================================\n\ndef on_source_checkbox_change(change):\n    \"\"\"Handle source checkbox changes.\"\"\"\n    # Rebuild source_filters from all checkboxes\n    state.source_filters = set()\n    for cb in source_checkboxes:\n        if cb.value:\n            state.source_filters.add(cb.source_name)\n\n    # Trigger data reload\n    do_search()\n\n\ndef on_material_select_change(change):\n    \"\"\"Handle material selection changes.\"\"\"\n    # Convert selected option labels to URIs\n    state.material_filters = set()\n    for option_label in material_select.value:\n        if option_label in material_uri_map:\n            state.material_filters.add(material_uri_map[option_label])\n\n    # Trigger data reload\n    do_search()\n\n\ndef on_rollup_toggle_change(change):\n    \"\"\"Handle rollup toggle changes.\"\"\"\n    state.material_rollup = rollup_toggle.value\n\n    # Update the widget options to show correct counts\n    update_material_widget_options()\n\n    # If materials are selected, reload with new rollup setting\n    if state.material_filters:\n        do_search()\n\n\ndef on_refresh_counts_click(b):\n    \"\"\"Handle refresh counts button click - recalculate material counts.\"\"\"\n    global direct_counts, rollup_counts\n    \n    show_loading(\"Recalculating counts...\")\n    try:\n        # Force refresh of counts\n        direct_counts, rollup_counts, elapsed = compute_accurate_rollup_counts(force_refresh=True)\n        \n        # Update widget display\n        update_material_widget_options()\n        \n        status_label.value = f\"<b>Counts refreshed</b> in {elapsed:.1f}s\"\n    except Exception as e:\n        status_label.value = f\"<b>Error:</b> {str(e)[:50]}\"\n    finally:\n        hide_loading()\n\n\n# Flag to prevent infinite loops when syncing decades/slider\n_syncing_time_widgets = False\n\n\ndef sync_slider_from_decades():\n    \"\"\"Update year slider based on selected decades.\"\"\"\n    global _syncing_time_widgets\n    if _syncing_time_widgets:\n        return\n    \n    _syncing_time_widgets = True\n    try:\n        if state.selected_decades:\n            # Calculate min/max from selected decades\n            min_year = min(state.selected_decades)\n            max_year = max(state.selected_decades) + 9  # End of decade (e.g., 2010 -> 2019)\n            year_slider.value = [min_year, max_year]\n    finally:\n        _syncing_time_widgets = False\n\n\ndef on_decade_checkbox_change(change):\n    \"\"\"Handle decade checkbox changes.\"\"\"\n    global _syncing_time_widgets\n    if _syncing_time_widgets:\n        return\n    \n    # Rebuild selected_decades from all checkboxes\n    state.selected_decades = set()\n    for cb in decade_checkboxes:\n        if cb.value:\n            state.selected_decades.add(cb.decade_value)\n\n    # Auto-enable time filter if any decade selected\n    if state.selected_decades and not time_filter_enabled.value:\n        _syncing_time_widgets = True\n        time_filter_enabled.value = True\n        _syncing_time_widgets = False\n\n    # Sync slider if enabled\n    if sync_decades_to_slider.value:\n        sync_slider_from_decades()\n\n    # Update state year_range from slider (which may have been synced)\n    if time_filter_enabled.value:\n        state.year_range = (year_slider.value[0], year_slider.value[1])\n    else:\n        state.year_range = (None, None)\n\n    # Trigger data reload\n    do_search()\n\n\ndef on_time_filter_change(change):\n    \"\"\"Handle time filter enable/disable.\"\"\"\n    global _syncing_time_widgets\n    if _syncing_time_widgets:\n        return\n    \n    if time_filter_enabled.value:\n        state.year_range = (year_slider.value[0], year_slider.value[1])\n    else:\n        state.year_range = (None, None)\n        # Also clear decade selections when disabling time filter\n        _syncing_time_widgets = True\n        state.selected_decades = set()\n        for cb in decade_checkboxes:\n            cb.value = False\n        _syncing_time_widgets = False\n\n    do_search()\n\n\ndef on_year_slider_change(change):\n    \"\"\"Handle year slider changes.\"\"\"\n    global _syncing_time_widgets\n    if _syncing_time_widgets:\n        return\n    \n    if time_filter_enabled.value:\n        state.year_range = (year_slider.value[0], year_slider.value[1])\n        \n        # Update decade checkboxes to reflect slider range (if sync enabled)\n        if sync_decades_to_slider.value:\n            _syncing_time_widgets = True\n            min_yr, max_yr = year_slider.value\n            state.selected_decades = set()\n            for cb in decade_checkboxes:\n                decade = cb.decade_value\n                # Check if decade overlaps with slider range\n                decade_end = decade + 9\n                overlaps = (decade <= max_yr) and (decade_end >= min_yr)\n                cb.value = overlaps\n                if overlaps:\n                    state.selected_decades.add(decade)\n            _syncing_time_widgets = False\n        \n        do_search()\n\n\ndef on_clear_all_filters(b):\n    \"\"\"Clear all facet filters.\"\"\"\n    global _syncing_time_widgets\n    _syncing_time_widgets = True\n    \n    # Clear source checkboxes\n    for cb in source_checkboxes:\n        cb.value = False\n    state.source_filters = set()\n\n    # Clear material selection\n    material_select.value = []\n    state.material_filters = set()\n\n    # Reset rollup to default (on)\n    rollup_toggle.value = True\n    state.material_rollup = True\n\n    # Clear time filter\n    time_filter_enabled.value = False\n    for cb in decade_checkboxes:\n        cb.value = False\n    state.selected_decades = set()\n    year_slider.value = [year_stats['min_year'], year_stats['max_year']]\n    state.year_range = (None, None)\n\n    # Clear search\n    search_input.value = ''\n    \n    _syncing_time_widgets = False\n\n    # Reload data\n    do_search()\n\n\n# Wire up facet event handlers\nfor cb in source_checkboxes:\n    cb.observe(on_source_checkbox_change, names=['value'])\n\nmaterial_select.observe(on_material_select_change, names=['value'])\nrollup_toggle.observe(on_rollup_toggle_change, names=['value'])\nrefresh_counts_btn.on_click(on_refresh_counts_click)\n\n# Wire up decade checkboxes\nfor cb in decade_checkboxes:\n    cb.observe(on_decade_checkbox_change, names=['value'])\n\ntime_filter_enabled.observe(on_time_filter_change, names=['value'])\nyear_slider.observe(on_year_slider_change, names=['value'])\nclear_filters_btn.on_click(on_clear_all_filters)\n\nprint(\"Facet widgets ready!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorer Interface\n",
    "\n",
    "Run this cell to launch the interactive explorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Layout the interface\n\n# Search box with buttons\nsearch_box = widgets.HBox([\n    search_input,\n    search_btn,\n    clear_search_btn\n], layout=widgets.Layout(margin='0 15px 0 0'))\n\n# Row 1: Search and viewport mode\ncontrols_row1 = widgets.HBox([\n    search_box,\n    viewport_toggle,\n], layout=widgets.Layout(margin='5px 0'))\n\n# Row 2: Sample count, refresh, status\ncontrols_row2 = widgets.HBox([\n    sample_count,\n    refresh_btn,\n    loading_indicator,\n    status_label\n], layout=widgets.Layout(margin='5px 0', flex_wrap='wrap'))\n\n# Row 3: Active filters display\ncontrols_row3 = widgets.HBox([\n    active_filters_html\n], layout=widgets.Layout(margin='0'))\n\ncontrols = widgets.VBox([controls_row1, controls_row2, controls_row3])\n\n# Legend\nlegend_html = \"\"\"\n<div style=\"display: flex; gap: 15px; padding: 8px; background: #f9f9f9; border-radius: 4px; font-size: 12px;\">\n    <span><span style=\"display: inline-block; width: 12px; height: 12px; background: #3366CC; border-radius: 50%; margin-right: 4px;\"></span>SESAR</span>\n    <span><span style=\"display: inline-block; width: 12px; height: 12px; background: #DC3912; border-radius: 50%; margin-right: 4px;\"></span>OpenContext</span>\n    <span><span style=\"display: inline-block; width: 12px; height: 12px; background: #109618; border-radius: 50%; margin-right: 4px;\"></span>GEOME</span>\n    <span><span style=\"display: inline-block; width: 12px; height: 12px; background: #FF9900; border-radius: 50%; margin-right: 4px;\"></span>Smithsonian</span>\n</div>\n\"\"\"\nlegend = widgets.HTML(value=legend_html)\n\n# Facet panel header\nfacet_header = widgets.HTML(value=\"<h4 style='margin: 0 0 8px 0;'>Filters</h4>\")\n\n# Main layout with three columns: map | facets | details\nleft_panel = widgets.VBox([\n    widgets.HTML(\"<h4 style='margin: 0 0 8px 0;'>Map</h4>\"),\n    legend,\n    sample_map\n], layout=widgets.Layout(flex='2', margin='0 10px 0 0'))\n\ncenter_panel = widgets.VBox([\n    facet_header,\n    facet_accordion,\n    clear_filters_btn\n], layout=widgets.Layout(width='320px', min_width='280px', margin='0 10px 0 0'))\n\nright_panel = widgets.VBox([\n    widgets.HTML(\"<h4 style='margin: 0 0 8px 0;'>Selected Sample</h4>\"),\n    card_output,\n    widgets.HTML(\"<h4 style='margin: 16px 0 8px 0;'>Sample List</h4>\"),\n    sample_table\n], layout=widgets.Layout(flex='1', min_width='350px'))\n\nmain_layout = widgets.HBox([left_panel, center_panel, right_panel])\n\n# Display\ndisplay(widgets.VBox([\n    widgets.HTML(\"<h2 style='margin-bottom: 5px;'>iSamples Explorer</h2>\"),\n    widgets.HTML(\"<p style='color: #666; margin-top: 0;'>Interactive exploration of physical samples across scientific domains</p>\"),\n    controls,\n    main_layout\n]))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Usage\n\n### Faceted Filters (Center Panel)\n\nThe **Filters** panel provides multi-select faceted filtering:\n\n**Sources** - Filter by data source (multi-select):\n- Check one or more sources to show only samples from those sources\n- Counts show total samples per source\n- Unchecking all shows all sources\n\n**Material Type** - Hierarchical filter with rollup:\n- Shows the iSamples 3-level material vocabulary as an indented tree\n- **Indentation shows hierarchy**: Top-level (Material), mid-level (Earth Material), leaf-level (Rock)\n- **Include subcategories** (default ON): Selecting \"Earth Material\" also includes Rock, Sediment, Soil, Mineral, Mixed\n- **Without rollup**: Only samples explicitly tagged at the selected level are shown\n- Use Ctrl/Cmd+click to select multiple materials\n\n**Time Period** - Filter by collection/sampling date:\n- **Filter by time**: Check to enable time filtering\n- **Decade quick-select**: Click decade checkboxes (e.g., \"2010s\") for fast filtering\n  - Selecting multiple decades spans them (e.g., 2000s + 2010s = 2000-2019)\n  - Auto-enables time filter when any decade is selected\n- **Year range slider**: Fine-tune the exact year range\n- **Sync decades to slider** (default ON): Keeps checkboxes and slider in sync\n  - Checking \"2010s\" sets slider to 2010-2019\n  - Moving slider updates which decade checkboxes are highlighted\n\n**Clear All Filters** - Reset all facet selections and search\n\n### Material Hierarchy Example\n\nThe material vocabulary has 3 levels. With \"Include subcategories\" ON:\n\n```\nSelecting \"Earth Material\" includes:\n  → Rock (1M samples)\n  → Sediment (66K)\n  → Soil (32K)\n  → Mineral (300K)\n  → Mixed Soil/Sediment/Rock (838K)\n  = Total ~2.3M samples\n```\n\nWithout rollup, selecting \"Earth Material\" only shows the ~2.2M samples tagged directly at that level (not the children).\n\n### Time Period Examples\n\n**Quick decade selection:**\n- Click \"2010s\" → Shows samples from 2010-2019\n- Click \"2000s\" AND \"2010s\" → Shows samples from 2000-2019\n- Click \"1990s\", \"2000s\", \"2010s\" → Shows samples from 1990-2019\n\n**Fine-tune with slider:**\n- After selecting decades, adjust slider to narrow further (e.g., 2015-2018)\n- Disable \"Sync decades to slider\" to use slider independently\n\n### Search\n\nSearch filters samples by matching text in **label**, **description**, and **place name** fields:\n\n- **Enter a term**: Type \"pottery\", \"basalt\", \"Cyprus\", etc. and press Enter\n- **Results are ranked**: Label matches (10 pts) > Description (5 pts) > Place name (3 pts)\n- **Score column**: When searching, a \"score\" column appears in the table showing match quality\n- **Combines with facets**: Search works together with facet filters (AND logic)\n- **Viewport aware**: With Viewport Mode ON, search is limited to the current map view\n\n### Selection Sync (Bidirectional)\n\nMap and table selections are synchronized:\n\n- **Click a dot on the map** → The corresponding row is highlighted in the table, and the sample card updates\n- **Click a row in the table** → The map recenters on that point (zoom level is preserved), and the sample card updates\n\nThis makes it easy to explore samples visually on the map and then find them in the table, or vice versa.\n\n### Viewport Mode (Dynamic Loading)\n\nEnable **Viewport Mode** to automatically reload data as you pan and zoom:\n\n- **Toggle ON**: Click the \"Viewport Mode\" button (turns green when active)\n- **Pan/zoom**: Data reloads automatically after you stop moving (500ms debounce)\n- **Loading indicator**: Spinner shows while data is being fetched\n- **Adaptive sampling**: \n  - World view (zoom < 2): max 10K samples per source\n  - Continent (zoom 2-5): max 25K per source\n  - Country (zoom 5-8): max 50K per source\n  - Region (zoom 8-12): max 100K per source\n  - Local (zoom > 12): uses your slider value\n\n### Active Filters Display\n\nWhen filters are active, colored tags appear below the controls showing:\n- **Blue tag**: Active source filters\n- **Green tag**: Active material filters (shows \"+sub\" when rollup is enabled)\n- **Orange tag**: Active time range (shows selected decades if any)\n\n### Filter Combinations\n\nAll filters work together with AND logic:\n- Source + Material: Show pottery samples from OpenContext only\n- Material + Time: Show rock samples collected in the 2010s\n- Source + Time + Search: Find \"Cyprus\" in SESAR samples from 2000-2020\n\n### Color Legend\n- **Blue**: SESAR (geological samples, IGSNs)\n- **Red**: OpenContext (archaeological samples)\n- **Green**: GEOME (genomic/biological samples)\n- **Orange**: Smithsonian (museum collections)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug: Raw Data Access\n",
    "\n",
    "Use these cells to explore the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current selection\n",
    "if state.selected_row is not None:\n",
    "    print(\"Selected sample:\")\n",
    "    print(state.selected_row)\n",
    "else:\n",
    "    print(\"No sample selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the full dataset\n",
    "con.sql(f\"\"\"\n",
    "    SELECT n as source, COUNT(*) as total_samples\n",
    "    FROM read_parquet('{PARQUET_PATH}')\n",
    "    WHERE otype = 'MaterialSampleRecord' AND latitude IS NOT NULL\n",
    "    GROUP BY n\n",
    "    ORDER BY total_samples DESC\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Material Type Hierarchy Analysis\n\nThe iSamples material vocabulary is a SKOS hierarchy with **3 levels**. Samples are tagged inconsistently at different levels, and rollup does not happen automatically in the raw data.\n\n### Implementation Status\n\n**Hierarchical Material Facet**: Now implemented in the explorer interface above:\n- **Tree display**: Materials shown with indentation reflecting hierarchy\n- **Rollup toggle**: \"Include subcategories\" checkbox (default ON)\n- **Rollup behavior**: Selecting a parent material includes all descendants in the filter\n\n### Key Findings (from data analysis)\n\n1. **No automatic rollup in data** - \"Earth Material\" (2.2M samples) does NOT include Rock (1M), Sediment (66K), etc. They're tagged separately at different hierarchy levels.\n\n2. **Inconsistent tagging depth** - Some samples tagged at root \"Material\" (664K), some at mid-level \"Earth Material\" (2.2M), some at leaf \"Rock\" (1M).\n\n3. **Intermediate nodes often empty** - \"Natural Solid Material\", \"Fluid Material\", \"Dispersed Media\" have 0 direct tags.\n\n### Pre-computed Hierarchy (January 2026)\n\n```\n- Material: 664,199\n  - Natural Solid Material: 0 (not used directly)\n    - Earth Material: 2,251,086\n      - Rock: 1,052,183\n      - Sediment: 66,648\n      - Soil: 32,157\n      - Mineral: 300,179\n      - Mixed Soil/Sediment/Rock: 838,726\n    - Biogenic Non-organic: 1,090,222\n  - Organic Material: 862,220\n    - Plant Material: 1\n    - Animal Product: 266\n  - Anthropogenic Material: 44,399\n    - Anthropogenic Metal: 269,981\n    - Ceramic Clay: 100,501\n  - Fluid Material: 0 (not used directly)\n    - Liquid Water: 24,080\n    - Gas: 1,154\n    - Non-aqueous Liquid: 44\n  - Dispersed Media: 0 (not used directly)\n    - Particulate: 122\n  - Any Ice: 4\n```\n\nTotal samples with coordinates: ~6M",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Compute Material Type Hierarchy with Sample Counts\n# \n# This analysis shows how samples are tagged at different levels of the \n# iSamples material vocabulary hierarchy.\n\ndef compute_material_hierarchy():\n    \"\"\"\n    Compute material type counts and display as a hierarchy tree.\n    \n    The iSamples material vocabulary is a 3-level SKOS hierarchy.\n    This function queries the data to show counts at each level.\n    \"\"\"\n    # Get all material counts from the data\n    query = \"\"\"\n    WITH samples AS (\n        SELECT UNNEST(p__has_material_category) as material_id\n        FROM read_parquet(?)\n        WHERE otype = 'MaterialSampleRecord' AND latitude IS NOT NULL\n    )\n    SELECT ic.label as uri, COUNT(*) as cnt\n    FROM samples s\n    JOIN read_parquet(?) ic ON ic.row_id = s.material_id\n    WHERE ic.label IS NOT NULL\n    GROUP BY ic.label\n    ORDER BY cnt DESC\n    \"\"\"\n    df = con.execute(query, [PARQUET_PATH, PARQUET_PATH]).df()\n    \n    # Build counts dict from URI last segment\n    counts = {}\n    for _, row in df.iterrows():\n        key = row['uri'].rstrip('/').split('/')[-1].lower()\n        counts[key] = row['cnt']\n    \n    # Define the hierarchy structure (based on iSamples vocabulary)\n    # https://isamplesorg.github.io/metadata/vocabularies/material.html\n    hierarchy = [\n        (\"Material\", \"material\", 0, [\n            (\"Natural Solid Material\", \"naturalsolidmaterial\", 1, [\n                (\"Earth Material\", \"earthmaterial\", 2, [\n                    (\"Rock\", \"rock\", 3, []),\n                    (\"Sediment\", \"sediment\", 3, []),\n                    (\"Soil\", \"soil\", 3, []),\n                    (\"Mineral\", \"mineral\", 3, []),\n                    (\"Mixed Soil/Sediment/Rock\", \"mixedsoilsedimentrock\", 3, []),\n                ]),\n                (\"Biogenic Non-organic\", \"biogenicnonorganicmaterial\", 2, []),\n            ]),\n            (\"Organic Material\", \"organicmaterial\", 1, [\n                (\"Plant Material\", \"plantmaterial\", 2, []),\n                (\"Animal Product\", \"organicanimalproduct\", 2, []),\n            ]),\n            (\"Anthropogenic Material\", \"anyanthropogenicmaterial\", 1, [\n                (\"Anthropogenic Metal\", \"anthropogenicmetal\", 2, []),\n                (\"Ceramic Clay\", \"ceramicclay\", 2, []),\n            ]),\n            (\"Fluid Material\", \"fluidmaterial\", 1, [\n                (\"Liquid Water\", \"liquidwater\", 2, []),\n                (\"Gas\", \"gas\", 2, []),\n                (\"Non-aqueous Liquid\", \"nonaqueousliquid\", 2, []),\n            ]),\n            (\"Dispersed Media\", \"dispersedmedia\", 1, [\n                (\"Particulate\", \"particulate\", 2, []),\n            ]),\n            (\"Any Ice\", \"anyice\", 1, []),\n        ])\n    ]\n    \n    def print_node(nodes, indent=0):\n        \"\"\"Recursively print hierarchy with counts.\"\"\"\n        for name, key, level, children in nodes:\n            cnt = counts.get(key, 0)\n            prefix = \"  \" * indent\n            marker = \"- \" if indent == 0 else \"└─ \"\n            \n            # Calculate rollup (what count WOULD be with proper rollup)\n            def calc_rollup(node_list):\n                total = 0\n                for n, k, l, c in node_list:\n                    total += counts.get(k, 0) + calc_rollup(c)\n                return total\n            \n            rollup = cnt + calc_rollup(children)\n            \n            if children and rollup != cnt:\n                print(f\"{prefix}{marker}**{name}**: {cnt:,} (rollup would be {rollup:,})\")\n            else:\n                print(f\"{prefix}{marker}**{name}**: {cnt:,}\")\n            \n            if children:\n                print_node(children, indent + 1)\n    \n    print(\"Material Type Hierarchy with Sample Counts\")\n    print(\"=\" * 50)\n    print()\n    print_node(hierarchy)\n    print()\n    \n    # Summary statistics\n    total_tags = sum(counts.values())\n    total_samples = con.execute(f\"\"\"\n        SELECT COUNT(*) FROM read_parquet('{PARQUET_PATH}')\n        WHERE otype = 'MaterialSampleRecord' AND latitude IS NOT NULL\n    \"\"\").fetchone()[0]\n    \n    # Materials per sample distribution\n    dist_query = f\"\"\"\n        SELECT \n            LEN(p__has_material_category) as num_materials,\n            COUNT(*) as num_samples\n        FROM read_parquet('{PARQUET_PATH}')\n        WHERE otype = 'MaterialSampleRecord' \n          AND latitude IS NOT NULL\n          AND p__has_material_category IS NOT NULL\n        GROUP BY LEN(p__has_material_category)\n        ORDER BY num_materials\n    \"\"\"\n    dist_df = con.execute(dist_query).df()\n    \n    print(\"Summary Statistics\")\n    print(\"-\" * 30)\n    print(f\"Total samples with coordinates: {total_samples:,}\")\n    print(f\"Total material tags: {total_tags:,}\")\n    print(f\"Unique material types: {len(counts)}\")\n    print()\n    print(\"Materials per sample:\")\n    for _, row in dist_df.iterrows():\n        print(f\"  {int(row['num_materials'])} material(s): {int(row['num_samples']):,} samples\")\n    \n    return counts, hierarchy\n\n# Run the analysis\nmaterial_counts, material_hierarchy = compute_material_hierarchy()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: If you have a different iSamples PQG parquet file from another provider, set `file_url` and `LOCAL_PATH` accordingly. All queries below will still work because they rely on PQG structure and iSamples model semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iSamples PQG Parquet Analysis (using OpenContext dataset)\n",
    "\n",
    "This notebook analyzes an iSamples Property Graph (PQG) parquet file. The sample file we use happens to be produced from OpenContext, but the schema, node types, and graph patterns are iSamples‚Äëgeneric.\n",
    "\n",
    "## Key Distinction: PQG framework vs iSamples model vs provider data\n",
    "\n",
    "We‚Äôll keep these layers straight:\n",
    "\n",
    "1. Generic PQG (Property Graph) framework\n",
    "   - Core graph fields: `s` (subject), `p` (predicate), `o` (object array), `n` (graph name)\n",
    "   - Edges are rows with `otype = '_edge_'`\n",
    "   - Graph traversal patterns (joins on s/p/o) are domain‚Äëagnostic\n",
    "\n",
    "2. iSamples metadata model (provider‚Äëagnostic domain schema)\n",
    "   - Entity types: `MaterialSampleRecord`, `SamplingEvent`, `GeospatialCoordLocation`, `SamplingSite`, `IdentifiedConcept`, `Agent`, etc.\n",
    "   - Predicates like `produced_by`, `sample_location`, `sampling_site`, `has_material_category`, etc.\n",
    "   - These are defined by the iSamples model, not specific to OpenContext\n",
    "\n",
    "3. Provider data (e.g., OpenContext)\n",
    "   - A particular provider‚Äôs content fills the iSamples model\n",
    "   - The dataset URL we load is from OpenContext, but the analysis is reusable for any iSamples PQG parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "file_url = \"https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg.parquet\"\n",
    "LOCAL_PATH = \"/Users/raymondyee/Data/iSample/oc_isamples_pqg.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if local file exists, download if not\n",
    "if not os.path.exists(LOCAL_PATH):\n",
    "    print(f\"Local file not found at {LOCAL_PATH}\")\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(LOCAL_PATH), exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading {file_url} to {LOCAL_PATH}...\")\n",
    "    urllib.request.urlretrieve(file_url, LOCAL_PATH)\n",
    "    print(\"Download completed!\")\n",
    "else:\n",
    "    print(f\"Local file already exists at {LOCAL_PATH}\")\n",
    "\n",
    "# Use local path for parquet operations\n",
    "parquet_path = LOCAL_PATH\n",
    "print(f\"Using parquet file: {parquet_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data Structure\n",
    "\n",
    "### PQG framework (generic)\n",
    "The parquet file uses a property graph model where both entities (nodes) and relationships (edges) are stored in one table. This pattern is generic and reusable across providers.\n",
    "\n",
    "Core PQG fields:\n",
    "- `s` (subject): source node row_id for an edge\n",
    "- `p` (predicate): relationship type\n",
    "- `o` (object): array of target row_ids\n",
    "- `n` (name): graph context/namespace (often null)\n",
    "\n",
    "Edges are rows with `otype = '_edge_'`.\n",
    "\n",
    "### iSamples metadata model (provider‚Äëagnostic)\n",
    "Values in `otype` and `p` map to the iSamples domain schema, independent of the specific provider:\n",
    "- Entity types: `MaterialSampleRecord`, `SamplingEvent`, `GeospatialCoordLocation`, `SamplingSite`, `IdentifiedConcept`, `Agent`, `_edge_`\n",
    "- Common predicates: `produced_by`, `sample_location`, `sampling_site`, `site_location`, `has_material_category`, `has_responsibility_actor`, etc.\n",
    "\n",
    "We‚Äôll demonstrate queries that traverse the generic PQG structure while filtering/labeling using the iSamples model.\n",
    "\n",
    "Note: The example parquet we load is produced from OpenContext content, but the analysis patterns apply to any iSamples PQG parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DuckDB connection\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Create view for the parquet file\n",
    "conn.execute(f\"CREATE VIEW pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "\n",
    "# Count records\n",
    "result = conn.execute(\"SELECT COUNT(*) FROM pqg;\").fetchone()\n",
    "print(f\"Total records: {result[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema information\n",
    "print(\"Schema information:\")\n",
    "schema_result = conn.execute(\"DESCRIBE pqg;\").fetchall()\n",
    "for row in schema_result[:10]:  # Show first 10 columns\n",
    "    print(f\"{row[0]:25} | {row[1]}\")\n",
    "print(f\"... and {len(schema_result) - 10} more columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the distribution of entity types (iSamples model types)\n",
    "entity_stats = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        otype,\n",
    "        COUNT(*) as count,\n",
    "        COUNT(DISTINCT pid) as unique_pids,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
    "    FROM pqg\n",
    "    GROUP BY otype\n",
    "    ORDER BY count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Entity Type Distribution (iSamples model types):\")\n",
    "print(entity_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph structure fields (PQG)\n",
    "\n",
    "The fields `s`, `p`, `o`, `n` are part of the generic PQG representation:\n",
    "- s (subject): row_id of the source entity\n",
    "- p (predicate): relationship type\n",
    "- o (object): array of target row_ids\n",
    "- n (name): graph context (usually null)\n",
    "\n",
    "These patterns are provider‚Äëagnostic. The iSamples model provides the semantics for common predicates such as:\n",
    "- Sample (s) produced_by (p) SamplingEvent (o)\n",
    "- Event (s) sample_location (p) GeospatialCoordLocation (o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore edge predicates (iSamples model predicates)\n",
    "edge_predicates = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        p as predicate,\n",
    "        COUNT(*) as usage_count,\n",
    "        COUNT(DISTINCT s) as unique_subjects\n",
    "    FROM pqg\n",
    "    WHERE otype = '_edge_'\n",
    "    GROUP BY p\n",
    "    ORDER BY usage_count DESC\n",
    "    LIMIT 15\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Most common relationship types (iSamples predicates):\")\n",
    "print(edge_predicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Query Examples\n",
    "\n",
    "The following queries demonstrate both:\n",
    "1. **Generic PQG patterns**: How to traverse graphs using s/p/o relationships\n",
    "2. **OpenContext specifics**: The actual entity types and predicates for archaeological data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph walk patterns used\n",
    "\n",
    "We use two traversal paths to attach coordinates to samples:\n",
    "\n",
    "- Direct event location:\n",
    "  Sample ‚Üí produced_by ‚Üí SamplingEvent ‚Üí sample_location ‚Üí GeospatialCoordLocation\n",
    "- Site-derived location:\n",
    "  Sample ‚Üí produced_by ‚Üí SamplingEvent ‚Üí sampling_site ‚Üí SamplingSite ‚Üí site_location ‚Üí GeospatialCoordLocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: Find Samples with Geographic Coordinates\n",
    "\n",
    "This query demonstrates:\n",
    "- **Generic PQG pattern**: Multi-hop graph traversal through edges\n",
    "- **OpenContext specifics**: Archaeological entity types and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find samples with geographic coordinates (via SamplingEvent)\n",
    "# PQG: traverse edges by joining on s/p/o; iSamples: filter types/predicates\n",
    "\n",
    "# Ensure we have a working connection\n",
    "try:\n",
    "    conn.execute(\"SELECT 1\").fetchone()\n",
    "except:\n",
    "    conn = duckdb.connect()\n",
    "    conn.execute(f\"CREATE VIEW pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "\n",
    "samples_with_coords = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        s.pid as sample_id,\n",
    "        s.label as sample_label,\n",
    "        s.description,\n",
    "        g.latitude,\n",
    "        g.longitude,\n",
    "        g.place_name,\n",
    "        'direct_event_location' as location_type\n",
    "    FROM pqg s\n",
    "    JOIN pqg e1   ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "    JOIN pqg evt  ON e1.o[1] = evt.row_id\n",
    "    JOIN pqg e2   ON evt.row_id = e2.s AND e2.p = 'sample_location'\n",
    "    JOIN pqg g    ON e2.o[1] = g.row_id\n",
    "    WHERE s.otype = 'MaterialSampleRecord'\n",
    "      AND evt.otype = 'SamplingEvent'\n",
    "      AND g.otype = 'GeospatialCoordLocation'\n",
    "      AND g.latitude IS NOT NULL\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"Found {len(samples_with_coords)} samples with direct event coordinates\")\n",
    "samples_with_coords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ibis for Cleaner Multi-Step Joins\n",
    "\n",
    "Ibis provides a more Pythonic interface for the same **generic PQG graph traversal patterns**, while making **OpenContext-specific** entity filtering clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Ibis for cleaner data manipulation\n",
    "import ibis\n",
    "from ibis import _\n",
    "\n",
    "ibis.options.interactive = True\n",
    "\n",
    "# Create Ibis connection using DuckDB\n",
    "ibis_conn = ibis.duckdb.connect()\n",
    "\n",
    "# Register the parquet file as a table in Ibis\n",
    "pqg = ibis_conn.read_parquet(parquet_path, table_name='pqg')\n",
    "\n",
    "print(\"Ibis setup complete!\")\n",
    "print(f\"Table columns: {pqg.columns}\")\n",
    "print(f\"Total records: {pqg.count().execute():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ibis version: Find samples with geographic coordinates through SamplingEvent\n",
    "\n",
    "# Base tables with iSamples model type filters\n",
    "samples = pqg.filter(_.otype == 'MaterialSampleRecord').alias('samples')\n",
    "events = pqg.filter(_.otype == 'SamplingEvent').alias('events')\n",
    "locations = pqg.filter(_.otype == 'GeospatialCoordLocation').alias('locations')\n",
    "edges = pqg.filter(_.otype == '_edge_').alias('edges')\n",
    "\n",
    "# Sample -> produced_by -> SamplingEvent\n",
    "sample_to_event = (\n",
    "    samples\n",
    "    .join(\n",
    "        edges.filter(_.p == 'produced_by'),\n",
    "        samples.row_id == edges.s\n",
    "    )\n",
    "    .join(\n",
    "        events,\n",
    "        edges.o[0] == events.row_id\n",
    "    )\n",
    ")\n",
    "\n",
    "# SamplingEvent -> sample_location -> GeospatialCoordLocation\n",
    "location_edges = edges.filter(_.p == 'sample_location').alias('location_edges')\n",
    "event_to_location = (\n",
    "    sample_to_event\n",
    "    .join(\n",
    "        location_edges,\n",
    "        events.row_id == location_edges.s\n",
    "    )\n",
    "    .join(\n",
    "        locations.filter(_.latitude.notnull()),\n",
    "        location_edges.o[0] == locations.row_id\n",
    "    )\n",
    ")\n",
    "\n",
    "samples_with_coords_ibis = (\n",
    "    event_to_location\n",
    "    .select(\n",
    "        sample_id=samples.pid,\n",
    "        sample_label=samples.label,\n",
    "        description=samples.description,\n",
    "        latitude=locations.latitude,\n",
    "        longitude=locations.longitude,\n",
    "        place_name=locations.place_name,\n",
    "        location_type=ibis.literal('direct_event_location')\n",
    "    )\n",
    "    .limit(100)\n",
    ")\n",
    "\n",
    "result_ibis = samples_with_coords_ibis.execute()\n",
    "print(f\"Found {len(result_ibis)} samples with direct event coordinates (Ibis)\")\n",
    "result_ibis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ibis version: Find samples via site location path\n",
    "\n",
    "sites = pqg.filter(_.otype == 'SamplingSite').alias('sites')\n",
    "\n",
    "# Define edge tables\n",
    "event_edges = edges.filter(_.p == 'produced_by').alias('event_edges')\n",
    "site_edges = edges.filter(_.p == 'sampling_site').alias('site_edges')\n",
    "site_location_edges = edges.filter(_.p == 'site_location').alias('site_location_edges')\n",
    "\n",
    "samples_via_sites_ibis = (\n",
    "    samples\n",
    "    .join(event_edges, samples.row_id == event_edges.s)\n",
    "    .join(events, event_edges.o[0] == events.row_id)\n",
    "    .join(site_edges, events.row_id == site_edges.s)\n",
    "    .join(sites, site_edges.o[0] == sites.row_id)\n",
    "    .join(site_location_edges, sites.row_id == site_location_edges.s)\n",
    "    .join(\n",
    "        locations.filter(_.latitude.notnull()),\n",
    "        site_location_edges.o[0] == locations.row_id\n",
    "    )\n",
    "    .select(\n",
    "        sample_id=samples.pid,\n",
    "        sample_label=samples.label,\n",
    "        site_name=sites.label,\n",
    "        latitude=locations.latitude,\n",
    "        longitude=locations.longitude,\n",
    "        location_type=ibis.literal('via_site_location')\n",
    "    )\n",
    "    .limit(100)\n",
    ")\n",
    "\n",
    "result_via_sites_ibis = samples_via_sites_ibis.execute()\n",
    "print(f\"Found {len(result_via_sites_ibis)} samples with site-based coordinates (Ibis)\")\n",
    "result_via_sites_ibis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ibis version: get_sample_locations_for_viz function\n",
    "\n",
    "def get_sample_locations_for_viz_ibis(limit=10000):\n",
    "    \"\"\"Extract sample locations optimized for visualization using Ibis\"\"\"\n",
    "\n",
    "    event_edges = edges.filter(_.p == 'produced_by').alias('event_edges')\n",
    "    sample_location_edges = edges.filter(_.p == 'sample_location').alias('sample_location_edges')\n",
    "    site_edges = edges.filter(_.p == 'sampling_site').alias('site_edges')\n",
    "    site_location_edges = edges.filter(_.p == 'site_location').alias('site_location_edges')\n",
    "\n",
    "    # Direct locations: Sample -> Event -> sample_location -> Location\n",
    "    direct_locations = (\n",
    "        samples\n",
    "        .join(event_edges, samples.row_id == event_edges.s)\n",
    "        .join(events, event_edges.o[0] == events.row_id)\n",
    "        .join(sample_location_edges, events.row_id == sample_location_edges.s)\n",
    "        .join(\n",
    "            locations.filter((_.latitude.notnull()) & (_.longitude.notnull()) & (~_.obfuscated)),\n",
    "            sample_location_edges.o[0] == locations.row_id\n",
    "        )\n",
    "        .select(\n",
    "            sample_id=samples.pid,\n",
    "            label=samples.label,\n",
    "            latitude=locations.latitude,\n",
    "            longitude=locations.longitude,\n",
    "            obfuscated=locations.obfuscated,\n",
    "            location_type=ibis.literal('direct')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Site locations: Sample -> Event -> Site -> site_location -> Location\n",
    "    site_locations = (\n",
    "        samples\n",
    "        .join(event_edges, samples.row_id == event_edges.s)\n",
    "        .join(events, event_edges.o[0] == events.row_id)\n",
    "        .join(site_edges, events.row_id == site_edges.s)\n",
    "        .join(sites, site_edges.o[0] == sites.row_id)\n",
    "        .join(site_location_edges, sites.row_id == site_location_edges.s)\n",
    "        .join(\n",
    "            locations.filter((_.latitude.notnull()) & (_.longitude.notnull()) & (~_.obfuscated)),\n",
    "            site_location_edges.o[0] == locations.row_id\n",
    "        )\n",
    "        .select(\n",
    "            sample_id=samples.pid,\n",
    "            label=samples.label,\n",
    "            latitude=locations.latitude,\n",
    "            longitude=locations.longitude,\n",
    "            obfuscated=locations.obfuscated,\n",
    "            location_type=ibis.literal('via_site')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return direct_locations.union(site_locations).limit(limit).execute()\n",
    "\n",
    "# Get visualization-ready data using Ibis\n",
    "viz_data_ibis = get_sample_locations_for_viz_ibis(5000)\n",
    "print(f\"Prepared {len(viz_data_ibis)} samples for visualization (Ibis version)\")\n",
    "if len(viz_data_ibis) > 0:\n",
    "    print(f\"Coordinate bounds: Lat [{viz_data_ibis.latitude.min():.2f}, {viz_data_ibis.latitude.max():.2f}], \"\n",
    "          f\"Lon [{viz_data_ibis.longitude.min():.2f}, {viz_data_ibis.longitude.max():.2f}]\")\n",
    "    print(f\"Location types: {viz_data_ibis.location_type.value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"No samples found with valid coordinates\")\n",
    "\n",
    "viz_data_ibis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Raw SQL vs Ibis\n",
    "\n",
    "Both approaches implement the same **generic PQG graph traversal patterns**. The Ibis versions offer several advantages:\n",
    "\n",
    "#### **Readability Benefits:**\n",
    "1. **Clear separation**: Generic PQG operations (joins on s/p/o) vs OpenContext filters (entity types)\n",
    "2. **Meaningful aliases**: `samples`, `events`, `locations` make the domain model clear\n",
    "3. **Method chaining**: Natural Python syntax that reads left-to-right\n",
    "4. **Type safety**: Ibis can catch column reference errors at definition time\n",
    "\n",
    "#### **Maintainability Benefits:**\n",
    "1. **Modular queries**: Easy to swap OpenContext predicates without changing graph traversal logic\n",
    "2. **Reusable components**: Base table filters separate framework from domain\n",
    "3. **IDE support**: Auto-completion works for both PQG fields and domain fields\n",
    "4. **Debugging**: Can inspect intermediate results by executing partial chains\n",
    "\n",
    "#### **Performance Considerations:**\n",
    "- Both compile to the same SQL, leveraging DuckDB's query optimizer\n",
    "- The graph traversal pattern (joining through edges) is the same\n",
    "- Performance is determined by the underlying PQG structure, not the query interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick performance and correctness comparison\n",
    "import time\n",
    "\n",
    "print(\"=== PERFORMANCE COMPARISON ===\")\n",
    "\n",
    "# Time the DuckDB SQL query\n",
    "perf_conn = duckdb.connect()\n",
    "perf_conn.execute(f\"CREATE VIEW pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "\n",
    "start_time = time.time()\n",
    "sql_result = perf_conn.execute(\"\"\"\n",
    "    SELECT COUNT(*) FROM (\n",
    "        SELECT s.pid as sample_id\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2 ON evt.row_id = e2.s AND e2.p = 'sample_location'\n",
    "        JOIN pqg g  ON e2.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.latitude IS NOT NULL\n",
    "    )\n",
    "\"\"\").fetchone()[0]\n",
    "sql_time = time.time() - start_time\n",
    "\n",
    "# Time the Ibis query\n",
    "start_time = time.time()\n",
    "ibis_count = samples_with_coords_ibis.count().execute()\n",
    "ibis_time = time.time() - start_time\n",
    "\n",
    "print(f\"Raw SQL result count: {sql_result}\")\n",
    "print(f\"Raw SQL execution time: {sql_time:.3f} seconds\")\n",
    "print(f\"Ibis result count: {ibis_count}\")\n",
    "print(f\"Ibis execution time: {ibis_time:.3f} seconds\")\n",
    "print(f\"Results match: {sql_result == ibis_count}\")\n",
    "print(f\"Performance ratio: {ibis_time/sql_time:.2f}x\")\n",
    "\n",
    "perf_conn.close()\n",
    "\n",
    "print(\"\\n=== KEY TAKEAWAYS ===\")\n",
    "print(\"‚úì Ibis provides much more readable code for complex joins\")\n",
    "print(\"‚úì Performance is comparable (compiles to same SQL)\")\n",
    "print(\"‚úì Good separation of PQG traversal from iSamples semantics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**‚úÖ Fixed Issues:**\n",
    "- Resolved `AttributeError: 'Table' object has no attribute 'location_edges'` by properly defining aliased edge tables separately\n",
    "- Fixed duplicate CTE names in the visualization function by using unique aliases\n",
    "- All Ibis queries now execute successfully\n",
    "\n",
    "**Key Improvements with Ibis:**\n",
    "1. **Much cleaner syntax** for multi-step joins - no more cryptic SQL aliases\n",
    "2. **Step-by-step query building** makes complex logic easier to understand\n",
    "3. **Reusable components** - define edge tables once, use multiple times\n",
    "4. **Better debugging** - can inspect intermediate results easily\n",
    "5. **IDE support** - auto-completion and type checking work better\n",
    "\n",
    "**Performance:** Ibis compiles to efficient SQL, so performance is equivalent to hand-written queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to ensure we have a working DuckDB connection\n",
    "def ensure_connection():\n",
    "    \"\"\"Ensure we have a working DuckDB connection with the parquet view\"\"\"\n",
    "    global conn\n",
    "    try:\n",
    "        conn.execute(\"SELECT 1\").fetchone()\n",
    "    except (NameError, Exception):\n",
    "        print(\"Recreating DuckDB connection...\")\n",
    "        conn = duckdb.connect()\n",
    "        conn.execute(f\"CREATE VIEW pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "        print(\"Connection restored!\")\n",
    "    return conn\n",
    "\n",
    "# Test the connection\n",
    "ensure_connection()\n",
    "print(\"DuckDB connection is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ark_to_url(pid: str) -> str:\n",
    "    \"\"\"Return a resolvable n2t.net URL for an ARK identifier.\n",
    "    If pid is not an ARK, return it as a string.\n",
    "    \"\"\"\n",
    "    if isinstance(pid, str) and pid.startswith(\"ark:/\"):\n",
    "        return f\"https://n2t.net/{pid}\"\n",
    "    return str(pid)\n",
    "\n",
    "# Quick smoke test if a sample_pid is already in scope (harmless if not)\n",
    "if 'sample_pid' in globals():\n",
    "    print(\"Sample URL:\", ark_to_url(sample_pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "Helper functions used across the notebook (defined early for clarity and reuse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples via the site location path for comparison\n",
    "ensure_connection()\n",
    "\n",
    "samples_via_sites = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        s.pid as sample_id,\n",
    "        s.label as sample_label,\n",
    "        site.label as site_name,\n",
    "        g.latitude,\n",
    "        g.longitude,\n",
    "        'via_site_location' as location_type\n",
    "    FROM pqg s\n",
    "    JOIN pqg e1   ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "    JOIN pqg evt  ON e1.o[1] = evt.row_id\n",
    "    JOIN pqg e2   ON evt.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "    JOIN pqg site ON e2.o[1] = site.row_id\n",
    "    JOIN pqg e3   ON site.row_id = e3.s AND e3.p = 'site_location'\n",
    "    JOIN pqg g    ON e3.o[1] = g.row_id\n",
    "    WHERE s.otype = 'MaterialSampleRecord'\n",
    "      AND evt.otype = 'SamplingEvent'\n",
    "      AND site.otype = 'SamplingSite'\n",
    "      AND g.otype = 'GeospatialCoordLocation'\n",
    "      AND g.latitude IS NOT NULL\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"Found {len(samples_via_sites)} samples with site-based coordinates\")\n",
    "samples_via_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Trace Samples Through Events to Sites\n",
    "\n",
    "This demonstrates a more complex **generic PQG traversal pattern** with **OpenContext-specific** archaeological hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace samples through events to sites\n",
    "sample_site_hierarchy = conn.execute(\"\"\"\n",
    "    WITH sample_to_site AS (\n",
    "        SELECT\n",
    "            samp.pid as sample_id,\n",
    "            samp.label as sample_label,\n",
    "            evt.pid as event_id,\n",
    "            site.pid as site_id,\n",
    "            site.label as site_name\n",
    "        FROM pqg samp\n",
    "        JOIN pqg e1   ON samp.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt  ON e1.o[1] = evt.row_id AND evt.otype = 'SamplingEvent'\n",
    "        JOIN pqg e2   ON evt.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "        JOIN pqg site ON e2.o[1] = site.row_id AND site.otype = 'SamplingSite'\n",
    "        WHERE samp.otype = 'MaterialSampleRecord'\n",
    "    )\n",
    "    SELECT\n",
    "        site_name,\n",
    "        COUNT(*) as sample_count\n",
    "    FROM sample_to_site\n",
    "    GROUP BY site_name\n",
    "    ORDER BY sample_count DESC\n",
    "    LIMIT 20\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Top sites by sample count:\")\n",
    "print(sample_site_hierarchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Explore Material Types and Categories\n",
    "\n",
    "This query shows how **OpenContext domain concepts** (material classifications) are modeled using the **generic PQG framework**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore material types and categories\n",
    "material_analysis = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        c.label as material_type,\n",
    "        c.name as category_name,\n",
    "        COUNT(DISTINCT s.row_id) as sample_count\n",
    "    FROM pqg s\n",
    "    JOIN pqg e ON s.row_id = e.s\n",
    "    JOIN pqg c ON e.o[1] = c.row_id\n",
    "    WHERE s.otype = 'MaterialSampleRecord'\n",
    "      AND e.otype = '_edge_'\n",
    "      AND e.p = 'has_material_category'\n",
    "      AND c.otype = 'IdentifiedConcept'\n",
    "    GROUP BY c.label, c.name\n",
    "    ORDER BY sample_count DESC\n",
    "    LIMIT 20\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Most common material types:\")\n",
    "print(material_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Performance Tips\n",
    "\n",
    "These tips apply to both **generic PQG patterns** and **OpenContext-specific** queries:\n",
    "\n",
    "### Generic PQG Optimization:\n",
    "1. **Filter edges first**: Use `otype = '_edge_'` early in WHERE clauses\n",
    "2. **Use array indexing carefully**: `o[1]` for first target in edge arrays\n",
    "3. **Leverage row_id indexes**: Join on row_id fields for best performance\n",
    "\n",
    "### OpenContext-Specific Optimization:\n",
    "1. **Filter by entity type early**: e.g., `otype = 'MaterialSampleRecord'`\n",
    "2. **Use domain predicates**: Filter edges by specific predicates like `produced_by`\n",
    "3. **Limit geographic queries**: Add bounds when querying latitude/longitude\n",
    "\n",
    "### Memory Management for Large Graphs:\n",
    "- Simple node counts: Fast (<1 second)\n",
    "- Single-hop edge traversal: Moderate (1-5 seconds)\n",
    "- Multi-hop graph traversal: Can be slow (5-30 seconds)\n",
    "- Full graph scans: Avoid without filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_locations_for_viz(conn, limit=10000):\n",
    "    \"\"\"Extract sample locations optimized for visualization (SQL version)\"\"\"\n",
    "    \n",
    "    return conn.execute(f\"\"\"\n",
    "        WITH direct_locations AS (\n",
    "            -- Direct path: Sample -> Event -> sample_location -> Location\n",
    "            SELECT\n",
    "                s.pid as sample_id,\n",
    "                s.label as label,\n",
    "                g.latitude,\n",
    "                g.longitude,\n",
    "                g.obfuscated,\n",
    "                'direct' as location_type\n",
    "            FROM pqg s\n",
    "            JOIN pqg e1   ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "            JOIN pqg evt  ON e1.o[1] = evt.row_id\n",
    "            JOIN pqg e2   ON evt.row_id = e2.s AND e2.p = 'sample_location'\n",
    "            JOIN pqg g    ON e2.o[1] = g.row_id\n",
    "            WHERE s.otype = 'MaterialSampleRecord'\n",
    "              AND evt.otype = 'SamplingEvent'\n",
    "              AND g.otype = 'GeospatialCoordLocation'\n",
    "              AND g.latitude IS NOT NULL\n",
    "              AND g.longitude IS NOT NULL\n",
    "        ),\n",
    "        site_locations AS (\n",
    "            -- Indirect path: Sample -> Event -> Site -> site_location -> Location\n",
    "            SELECT\n",
    "                s.pid as sample_id,\n",
    "                s.label as label,\n",
    "                g.latitude,\n",
    "                g.longitude,\n",
    "                g.obfuscated,\n",
    "                'via_site' as location_type\n",
    "            FROM pqg s\n",
    "            JOIN pqg e1   ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "            JOIN pqg evt  ON e1.o[1] = evt.row_id\n",
    "            JOIN pqg e2   ON evt.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "            JOIN pqg site ON e2.o[1] = site.row_id\n",
    "            JOIN pqg e3   ON site.row_id = e3.s AND e3.p = 'site_location'\n",
    "            JOIN pqg g    ON e3.o[1] = g.row_id\n",
    "            WHERE s.otype = 'MaterialSampleRecord'\n",
    "              AND evt.otype = 'SamplingEvent'\n",
    "              AND site.otype = 'SamplingSite'\n",
    "              AND g.otype = 'GeospatialCoordLocation'\n",
    "              AND g.latitude IS NOT NULL\n",
    "              AND g.longitude IS NOT NULL\n",
    "        )\n",
    "        SELECT\n",
    "            sample_id,\n",
    "            label,\n",
    "            latitude,\n",
    "            longitude,\n",
    "            obfuscated,\n",
    "            location_type\n",
    "        FROM (\n",
    "            SELECT * FROM direct_locations\n",
    "            UNION ALL\n",
    "            SELECT * FROM site_locations\n",
    "        )\n",
    "        WHERE NOT obfuscated  -- Exclude obfuscated locations for public viz\n",
    "        LIMIT {limit}\n",
    "    \"\"\").fetchdf()\n",
    "\n",
    "# Get visualization-ready data\n",
    "viz_data = get_sample_locations_for_viz(conn, 5000)\n",
    "print(f\"Prepared {len(viz_data)} samples for visualization\")\n",
    "if len(viz_data) > 0:\n",
    "    print(f\"Coordinate bounds: Lat [{viz_data.latitude.min():.2f}, {viz_data.latitude.max():.2f}], \"\n",
    "          f\"Lon [{viz_data.longitude.min():.2f}, {viz_data.longitude.max():.2f}]\")\n",
    "    print(f\"Location types: {viz_data.location_type.value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"No samples found with valid coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Export Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_site_subgraph(conn, site_name_pattern, output_prefix):\n",
    "    \"\"\"Export all data related to a specific site\"\"\"\n",
    "    \n",
    "    # Find the site\n",
    "    site_info = conn.execute(\"\"\"\n",
    "        SELECT row_id, pid, label\n",
    "        FROM pqg\n",
    "        WHERE otype = 'SamplingSite'\n",
    "        AND label LIKE ?\n",
    "        LIMIT 1\n",
    "    \"\"\", [f'%{site_name_pattern}%']).fetchdf()\n",
    "    \n",
    "    if site_info.empty:\n",
    "        print(f\"No site found matching '{site_name_pattern}'\")\n",
    "        return None\n",
    "    \n",
    "    site_row_id = site_info.iloc[0]['row_id']\n",
    "    print(f\"Found site: {site_info.iloc[0]['label']}\")\n",
    "    \n",
    "    # Get all related entities (simplified version - not recursive)\n",
    "    related_data = conn.execute(\"\"\"\n",
    "        WITH site_related AS (\n",
    "            -- Get the site itself\n",
    "            SELECT * FROM pqg WHERE row_id = ?\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            -- Get edges from the site\n",
    "            SELECT * FROM pqg e\n",
    "            WHERE e.otype = '_edge_' AND e.s = ?\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            -- Get entities connected to the site\n",
    "            SELECT n.* FROM pqg e\n",
    "            JOIN pqg n ON n.row_id = e.o[1]\n",
    "            WHERE e.otype = '_edge_' AND e.s = ?\n",
    "        )\n",
    "        SELECT * FROM site_related\n",
    "    \"\"\", [site_row_id, site_row_id, site_row_id]).fetchdf()\n",
    "    \n",
    "    # Save to parquet\n",
    "    output_file = f\"{output_prefix}_{site_info.iloc[0]['pid']}.parquet\"\n",
    "    related_data.to_parquet(output_file)\n",
    "    print(f\"Exported {len(related_data)} rows to {output_file}\")\n",
    "    \n",
    "    return related_data\n",
    "\n",
    "# Example usage (commented out to avoid creating files)\n",
    "# pompeii_data = export_site_subgraph(conn, \"Pompeii\", \"pompeii_subgraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for location data quality\n",
    "location_quality = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        CASE \n",
    "            WHEN obfuscated THEN 'Obfuscated'\n",
    "            ELSE 'Precise'\n",
    "        END as location_type,\n",
    "        COUNT(*) as count,\n",
    "        AVG(CASE WHEN latitude IS NOT NULL THEN 1.0 ELSE 0.0 END) * 100 as pct_with_coords\n",
    "    FROM pqg\n",
    "    WHERE otype = 'GeospatialCoordLocation'\n",
    "    GROUP BY location_type\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Location Data Quality:\")\n",
    "print(location_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for orphaned nodes (nodes not connected by any edge)\n",
    "orphan_check = conn.execute(\"\"\"\n",
    "    WITH connected_nodes AS (\n",
    "        SELECT DISTINCT s as row_id FROM pqg WHERE otype = '_edge_'\n",
    "        UNION\n",
    "        SELECT DISTINCT unnest(o) as row_id FROM pqg WHERE otype = '_edge_'\n",
    "    )\n",
    "    SELECT\n",
    "        n.otype,\n",
    "        COUNT(*) as orphan_count\n",
    "    FROM pqg n\n",
    "    LEFT JOIN connected_nodes c ON n.row_id = c.row_id\n",
    "    WHERE n.otype != '_edge_' AND c.row_id IS NULL\n",
    "    GROUP BY n.otype\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"\\nOrphaned Nodes by Type:\")\n",
    "print(orphan_check if not orphan_check.empty else \"No orphaned nodes found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "summary = conn.execute(\"\"\"\n",
    "    WITH stats AS (\n",
    "        SELECT\n",
    "            COUNT(*) as total_rows,\n",
    "            COUNT(DISTINCT pid) as unique_pids,\n",
    "            COUNT(CASE WHEN otype = '_edge_' THEN 1 END) as edge_count,\n",
    "            COUNT(CASE WHEN otype != '_edge_' THEN 1 END) as node_count,\n",
    "            COUNT(DISTINCT CASE WHEN otype != '_edge_' THEN otype END) as entity_types,\n",
    "            COUNT(DISTINCT p) as relationship_types\n",
    "        FROM pqg\n",
    "    )\n",
    "    SELECT * FROM stats\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "for col in summary.columns:\n",
    "    print(f\"{col}: {summary[col].iloc[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug: Specific Geo Point Analysis\n",
    "\n",
    "Testing queries for parquet_cesium.qmd debugging. This section demonstrates:\n",
    "- **Generic PQG debugging**: How to trace edge connections\n",
    "- **OpenContext validation**: Verifying archaeological data relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug specific geo location from parquet_cesium.qmd\n",
    "# This section remains provider-agnostic and uses iSamples model semantics\n",
    "\n",
    "target_geo_pid = \"geoloc_7ea562cce4c70e4b37f7915e8384880c86607729\"\n",
    "\n",
    "print(f\"=== Debugging geo location: {target_geo_pid} ===\\n\")\n",
    "\n",
    "# 1. Find the geo location record\n",
    "geo_record = conn.execute(\"\"\"\n",
    "    SELECT row_id, pid, otype, latitude, longitude \n",
    "    FROM pqg \n",
    "    WHERE pid = ? AND otype = 'GeospatialCoordLocation'\n",
    "\"\"\", [target_geo_pid]).fetchdf()\n",
    "\n",
    "print(\"1. Geo Location Record:\")\n",
    "if not geo_record.empty:\n",
    "    print(geo_record.to_dict('records')[0])\n",
    "    geo_row_id = geo_record.iloc[0]['row_id']\n",
    "    print(f\"   Row ID: {geo_row_id}\")\n",
    "else:\n",
    "    print(\"   ‚ùå Geo location not found!\")\n",
    "    geo_row_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check what edges point to this geo location\n",
    "if geo_row_id is not None:\n",
    "    geo_row_id_int = int(geo_row_id)\n",
    "    edges_to_geo = conn.execute(\"\"\"\n",
    "        SELECT s, p, otype as edge_type, pid as edge_pid\n",
    "        FROM pqg \n",
    "        WHERE otype = '_edge_' AND ? = ANY(o)\n",
    "    \"\"\", [geo_row_id_int]).fetchdf()\n",
    "\n",
    "    print(f\"\\n2. Edges pointing to this geo location ({len(edges_to_geo)} found):\")\n",
    "    if not edges_to_geo.empty:\n",
    "        edge_summary = edges_to_geo.groupby('p').size().reset_index()\n",
    "        edge_summary.columns = ['predicate', 'count']\n",
    "        print(edge_summary)\n",
    "        print(\"\\nDetailed edges:\")\n",
    "        for _, edge in edges_to_geo.iterrows():\n",
    "            print(f\"   {edge['p']}: row_id {edge['s']} -> geo location\")\n",
    "    else:\n",
    "        print(\"   ‚ùå No edges point to this geo location!\")\n",
    "else:\n",
    "    print(\"\\n2. Skipping edge analysis - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Direct event samples\n",
    "if geo_row_id is not None:\n",
    "    direct_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            s.name as sample_name,\n",
    "            evt.pid as event_id,\n",
    "            evt.label as event_label,\n",
    "            'direct_event_location' as location_path\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1  ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2  ON evt.row_id = e2.s AND e2.p = 'sample_location'\n",
    "        JOIN pqg g   ON e2.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 20\n",
    "    \"\"\", [target_geo_pid]).fetchdf()\n",
    "\n",
    "    print(f\"\\n3. Direct Event Samples ({len(direct_samples)} found):\")\n",
    "    if not direct_samples.empty:\n",
    "        print(direct_samples[['sample_id', 'sample_label', 'event_id', 'event_label']].head())\n",
    "    else:\n",
    "        print(\"   ‚ùå No direct event samples found!\")\n",
    "else:\n",
    "    print(\"\\n3. Skipping direct samples query - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Site-associated samples\n",
    "if geo_row_id is not None:\n",
    "    site_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            s.name as sample_name,\n",
    "            evt.pid as event_id,\n",
    "            evt.label as event_label,\n",
    "            site.label as site_name,\n",
    "            'via_site_location' as location_path\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1   ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt  ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2   ON evt.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "        JOIN pqg site ON e2.o[1] = site.row_id\n",
    "        JOIN pqg e3   ON site.row_id = e3.s AND e3.p = 'site_location'\n",
    "        JOIN pqg g    ON e3.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND site.otype = 'SamplingSite'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 20\n",
    "    \"\"\", [target_geo_pid]).fetchdf()\n",
    "\n",
    "    print(f\"\\n4. Site-Associated Samples ({len(site_samples)} found):\")\n",
    "    if not site_samples.empty:\n",
    "        print(site_samples[['sample_id', 'sample_label', 'site_name', 'event_id']].head())\n",
    "    else:\n",
    "        print(\"   ‚ùå No site-associated samples found!\")\n",
    "else:\n",
    "    print(\"\\n4. Skipping site samples query - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. If we found samples, get detailed metadata for the first sample\n",
    "all_samples = []\n",
    "if 'direct_samples' in locals() and not direct_samples.empty:\n",
    "    all_samples.extend(direct_samples.to_dict('records'))\n",
    "if 'site_samples' in locals() and not site_samples.empty:\n",
    "    all_samples.extend(site_samples.to_dict('records'))\n",
    "\n",
    "if all_samples:\n",
    "    first_sample = all_samples[0]\n",
    "    sample_pid = first_sample['sample_id']\n",
    "\n",
    "    print(f\"\\n5. Detailed metadata for sample: {sample_pid}\")\n",
    "    print(f\"   Resolvable URL: {ark_to_url(sample_pid)}\")\n",
    "    print(f\"   Sample label: {first_sample.get('sample_label', 'N/A')}\")\n",
    "    print(f\"   Location path: {first_sample.get('location_path', 'N/A')}\")\n",
    "\n",
    "    # Materials for this sample\n",
    "    materials = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            mat.pid as material_id,\n",
    "            mat.label as material_type,\n",
    "            mat.name as material_category\n",
    "        FROM pqg s\n",
    "        JOIN pqg e   ON s.row_id = e.s AND e.p = 'has_material_category'\n",
    "        JOIN pqg mat ON e.o[1] = mat.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND s.pid = ?\n",
    "          AND e.otype = '_edge_'\n",
    "          AND mat.otype = 'IdentifiedConcept'\n",
    "    \"\"\", [sample_pid]).fetchdf()\n",
    "\n",
    "    print(f\"\\n   Materials ({len(materials)} found):\")\n",
    "    if not materials.empty:\n",
    "        for _, mat in materials.iterrows():\n",
    "            print(f\"     - {mat['material_type']} ({ark_to_url(mat['material_id'])})\")\n",
    "    else:\n",
    "        print(\"     ‚ùå No materials found!\")\n",
    "\n",
    "    # Agents responsible for this sample\n",
    "    agents = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            agent.pid as agent_id,\n",
    "            agent.label as agent_name,\n",
    "            agent.name as agent_role\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1    ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt   ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2    ON evt.row_id = e2.s AND e2.p = 'responsibility'\n",
    "        JOIN pqg agent ON e2.o[1] = agent.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND s.pid = ?\n",
    "          AND e1.otype = '_edge_'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND e2.otype = '_edge_'\n",
    "          AND agent.otype = 'Agent'\n",
    "        LIMIT 10\n",
    "    \"\"\", [sample_pid]).fetchdf()\n",
    "\n",
    "    print(f\"\\n   Responsible Agents ({len(agents)} found):\")\n",
    "    if not agents.empty:\n",
    "        for _, agent in agents.iterrows():\n",
    "            print(f\"     - {agent['agent_name']} ({ark_to_url(agent['agent_id'])})\")\n",
    "    else:\n",
    "        print(\"     ‚ùå No agents found!\")\n",
    "else:\n",
    "    print(\"\\n5. No samples found to analyze metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Summary of findings for this geo location\n",
    "print(f\"\\n=== SUMMARY for {target_geo_pid} ===\")\n",
    "if geo_row_id is not None:\n",
    "    print(f\"‚úÖ Geo location found (row_id: {geo_row_id})\")\n",
    "    print(f\"üìç Coordinates: {geo_record.iloc[0]['latitude']}, {geo_record.iloc[0]['longitude']}\")\n",
    "\n",
    "    total_samples = len(all_samples)\n",
    "    direct_count = len([s for s in all_samples if s.get('location_path') == 'direct_event_location'])\n",
    "    site_count = len([s for s in all_samples if s.get('location_path') == 'via_site_location'])\n",
    "\n",
    "    print(f\"üî¨ Total samples found: {total_samples}\")\n",
    "    print(f\"   - Direct event samples: {direct_count}\")\n",
    "    print(f\"   - Site-associated samples: {site_count}\")\n",
    "\n",
    "    if total_samples > 0:\n",
    "        print(\"‚úÖ Sample metadata retrieval successful!\")\n",
    "    else:\n",
    "        print(\"‚ùå No samples found for this location\")\n",
    "else:\n",
    "    print(\"‚ùå Geo location not found in dataset!\")\n",
    "\n",
    "print(f\"\\n=== END DEBUG for {target_geo_pid} ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Test with a different geo location that has sample_location edges\n",
    "sample_location_geos = conn.execute(\"\"\"\n",
    "    SELECT g.pid, g.latitude, g.longitude, COUNT(*) as edge_count\n",
    "    FROM pqg e\n",
    "    JOIN pqg g ON e.o[1] = g.row_id\n",
    "    WHERE e.otype = '_edge_'\n",
    "      AND e.p = 'sample_location'\n",
    "      AND g.otype = 'GeospatialCoordLocation'\n",
    "    GROUP BY g.pid, g.latitude, g.longitude\n",
    "    ORDER BY edge_count DESC\n",
    "    LIMIT 3\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"=== Testing with geo locations that have direct sample_location edges ===\")\n",
    "print(sample_location_geos)\n",
    "\n",
    "if not sample_location_geos.empty:\n",
    "    test_geo_pid = sample_location_geos.iloc[0]['pid']\n",
    "    print(f\"\\nTesting direct samples query with: {test_geo_pid}\")\n",
    "\n",
    "    test_direct_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            evt.pid as event_id,\n",
    "            evt.label as event_label\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1  ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2  ON evt.row_id = e2.s AND e2.p = 'sample_location'\n",
    "        JOIN pqg g   ON e2.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 5\n",
    "    \"\"\", [test_geo_pid]).fetchdf()\n",
    "\n",
    "    print(f\"Direct samples found: {len(test_direct_samples)}\")\n",
    "    if not test_direct_samples.empty:\n",
    "        print(\"‚úÖ Direct event samples exist\")\n",
    "        print(test_direct_samples[['sample_id', 'sample_label', 'event_id']].head())\n",
    "    else:\n",
    "        print(\"‚ùå Still no direct event samples found\")\n",
    "else:\n",
    "    print(\"‚ùå No geo locations with sample_location edges found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Analysis Results\n",
    "\n",
    "### Key Findings for parquet_cesium.qmd\n",
    "\n",
    "1. **Geo Location Structure**: The target geo location `geoloc_7ea562cce4c70e4b37f7915e8384880c86607729` exists in the dataset with correct coordinates.\n",
    "\n",
    "2. **Sample Association**: This specific location has **1 site-associated sample** but **0 direct event samples**.\n",
    "\n",
    "3. **Query Validation**: Both query paths work correctly:\n",
    "   - **Direct path**: `Sample ‚Üí SamplingEvent ‚Üí sample_location ‚Üí GeospatialCoordLocation`\n",
    "   - **Site path**: `Sample ‚Üí SamplingEvent ‚Üí SamplingSite ‚Üí site_location ‚Üí GeospatialCoordLocation`\n",
    "\n",
    "4. **Data Availability**: The dataset contains both types of sample associations, but not every geo location has both types.\n",
    "\n",
    "### Recommendations for parquet_cesium.qmd\n",
    "\n",
    "- The JavaScript queries are correctly structured and should work\n",
    "- Some geo locations may only have site-associated samples (like our test case)\n",
    "- Consider showing both direct and site-associated samples in the UI\n",
    "- Add debug logging to identify when no samples are found vs. query errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis complete!\n",
    "print(\"\\nAnalysis complete!\")\n",
    "print(\"Note: DuckDB connection remains open for interactive use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PQG key-value metadata (iSamples generic)\n",
    "\n",
    "The parquet contains KV metadata describing the iSamples PQG schema (see https://github.com/isamplesorg/pqg). We‚Äôll load the keys `pqg_version`, `pqg_primary_key`, `pqg_node_types`, `pqg_edge_fields`, `pqg_literal_fields` to make the notebook self‚Äëdescribing and provider‚Äëagnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read PQG key-value metadata using PyArrow (provider-agnostic)\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "try:\n",
    "    md = pq.read_metadata(parquet_path)\n",
    "    kv_raw = md.metadata or {}\n",
    "    # Decode byte keys/values to strings\n",
    "    kv = { (k.decode() if isinstance(k, (bytes, bytearray)) else str(k)):\n",
    "           (v.decode() if isinstance(v, (bytes, bytearray)) else str(v))\n",
    "           for k, v in kv_raw.items() }\n",
    "\n",
    "    wanted_keys = [\"pqg_version\", \"pqg_primary_key\", \"pqg_node_types\", \"pqg_edge_fields\", \"pqg_literal_fields\"]\n",
    "    selected = {k: kv.get(k) for k in wanted_keys if k in kv}\n",
    "\n",
    "    print(\"PQG KV metadata (selected):\")\n",
    "    if selected:\n",
    "        for k in wanted_keys:\n",
    "            if k in selected:\n",
    "                print(f\"- {k}: {selected[k][:120]}{'...' if len(selected[k])>120 else ''}\")\n",
    "    else:\n",
    "        print(\"No PQG KV metadata keys found in file metadata\")\n",
    "except Exception as e:\n",
    "    print(\"Unable to read parquet metadata via PyArrow:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isamples-python-3.12.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: If you have a different iSamples PQG parquet file from another provider, set `file_url` and `LOCAL_PATH` accordingly. All queries below will still work because they rely on PQG structure and iSamples model semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iSamples PQG Parquet Analysis (using OpenContext dataset)\n",
    "\n",
    "This notebook analyzes an iSamples Property Graph (PQG) parquet file. The sample file we use happens to be produced from OpenContext, but the schema, node types, and graph patterns are iSamples‚Äëgeneric.\n",
    "\n",
    "## Key Distinction: PQG framework vs iSamples model vs provider data\n",
    "\n",
    "We‚Äôll keep these layers straight:\n",
    "\n",
    "1. Generic PQG (Property Graph) framework\n",
    "   - Core graph fields: `s` (subject), `p` (predicate), `o` (object array), `n` (graph name)\n",
    "   - Edges are rows with `otype = '_edge_'`\n",
    "   - Graph traversal patterns (joins on s/p/o) are domain‚Äëagnostic\n",
    "\n",
    "2. iSamples metadata model (provider‚Äëagnostic domain schema)\n",
    "   - Entity types: `MaterialSampleRecord`, `SamplingEvent`, `GeospatialCoordLocation`, `SamplingSite`, `IdentifiedConcept`, `Agent`, etc.\n",
    "   - Predicates like `produced_by`, `sample_location`, `sampling_site`, `has_material_category`, etc.\n",
    "   - These are defined by the iSamples model, not specific to OpenContext\n",
    "\n",
    "3. Provider data (e.g., OpenContext)\n",
    "   - A particular provider‚Äôs content fills the iSamples model\n",
    "   - The dataset URL we load is from OpenContext, but the analysis is reusable for any iSamples PQG parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "file_url = \"https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg.parquet\"\n",
    "# LOCAL_PATH is configured for Raymond Yee's local machine \n",
    "\n",
    "# ~/Data/iSample/pqg_refining/oc_isamples_pqg.parquet\n",
    "LOCAL_PATH = os.path.join(Path.home(), \"Data\", \"iSample\", \"oc_isamples_pqg.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local file not found at /Users/raymondyee/Data/iSample/pqg_refining/oc_isamples_pqg.parquet\n",
      "Downloading https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg.parquet to /tmp/oc_isamples_pqg.parquet...\n",
      "Download completed!\n",
      "Using parquet file: /tmp/oc_isamples_pqg.parquet\n"
     ]
    }
   ],
   "source": [
    "# Check if local file exists, download to generic location if not\n",
    "\n",
    "if not os.path.exists(LOCAL_PATH):\n",
    "    print(f\"Local file not found at {LOCAL_PATH}\")\n",
    "\n",
    "    # if the file is not there, let's use tempfile module to create a temp file path.\n",
    "    # put tempfile in /tmp/oc_isamples_pqg.parquet\n",
    "    LOCAL_PATH = os.path.join(\"/tmp\", \"oc_isamples_pqg.parquet\")\n",
    "    os.makedirs(os.path.dirname(LOCAL_PATH), exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading {file_url} to {LOCAL_PATH}...\")\n",
    "    urllib.request.urlretrieve(file_url, LOCAL_PATH)\n",
    "    print(\"Download completed!\")\n",
    "else:\n",
    "    print(f\"Local file already exists at {LOCAL_PATH}\")\n",
    "\n",
    "# Use local path for parquet operations\n",
    "parquet_path = LOCAL_PATH\n",
    "print(f\"Using parquet file: {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 11,786,509\n"
     ]
    }
   ],
   "source": [
    "# Create a DuckDB connection\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Create view for the parquet file\n",
    "conn.execute(f\"CREATE VIEW pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "\n",
    "# Count records\n",
    "result = conn.execute(\"SELECT COUNT(*) FROM pqg;\").fetchone()\n",
    "print(f\"Total records: {result[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema information:\n",
      "row_id                    | INTEGER\n",
      "pid                       | VARCHAR\n",
      "tcreated                  | INTEGER\n",
      "tmodified                 | INTEGER\n",
      "otype                     | VARCHAR\n",
      "s                         | INTEGER\n",
      "p                         | VARCHAR\n",
      "o                         | INTEGER[]\n",
      "n                         | VARCHAR\n",
      "altids                    | VARCHAR[]\n",
      "... and 30 more columns\n"
     ]
    }
   ],
   "source": [
    "# Schema information\n",
    "print(\"Schema information:\")\n",
    "schema_result = conn.execute(\"DESCRIBE pqg;\").fetchall()\n",
    "for row in schema_result[:10]:  # Show first 10 columns\n",
    "    print(f\"{row[0]:25} | {row[1]}\")\n",
    "print(f\"... and {len(schema_result) - 10} more columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Type Distribution (iSamples model types):\n",
      "                     otype    count  unique_pids  percentage\n",
      "0                   _edge_  9321819      9321819       79.09\n",
      "1     MaterialSampleRecord  1110412      1110412        9.42\n",
      "2            SamplingEvent  1110412      1110412        9.42\n",
      "3  GeospatialCoordLocation   199147       199147        1.69\n",
      "4        IdentifiedConcept    25929        25929        0.22\n",
      "5             SamplingSite    18213        18213        0.15\n",
      "6                    Agent      577          577        0.00\n"
     ]
    }
   ],
   "source": [
    "# Examine the distribution of entity types (iSamples model types)\n",
    "entity_stats = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        otype,\n",
    "        COUNT(*) as count,\n",
    "        COUNT(DISTINCT pid) as unique_pids,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
    "    FROM pqg\n",
    "    GROUP BY otype\n",
    "    ORDER BY count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Entity Type Distribution (iSamples model types):\")\n",
    "print(entity_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Analysis: All Sentence Types in the Dataset\n",
    "\n",
    "Now let's compute ALL sentence types (subject-predicate-object patterns) in the parquet file, following the pattern we discovered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL SENTENCE TYPES IN THE DATASET\n",
      "==================================================\n",
      "Found 10 unique sentence types:\n",
      "\n",
      "MaterialSampleRecord --produced_by--> SamplingEvent\n",
      "  Frequency: 1,110,412 relationships\n",
      "  Unique subjects: 1,110,412, Unique objects: 1,110,412\n",
      "\n",
      "MaterialSampleRecord --has_sample_object_type--> IdentifiedConcept\n",
      "  Frequency: 1,110,412 relationships\n",
      "  Unique subjects: 1,110,412, Unique objects: 5\n",
      "\n",
      "MaterialSampleRecord --has_material_category--> IdentifiedConcept\n",
      "  Frequency: 1,110,412 relationships\n",
      "  Unique subjects: 1,110,412, Unique objects: 10\n",
      "\n",
      "MaterialSampleRecord --has_context_category--> IdentifiedConcept\n",
      "  Frequency: 1,110,412 relationships\n",
      "  Unique subjects: 1,110,412, Unique objects: 2\n",
      "\n",
      "SamplingEvent --sampling_site--> SamplingSite\n",
      "  Frequency: 1,110,412 relationships\n",
      "  Unique subjects: 1,110,412, Unique objects: 18,213\n",
      "\n",
      "MaterialSampleRecord --keywords--> IdentifiedConcept\n",
      "  Frequency: 1,110,359 relationships\n",
      "  Unique subjects: 1,110,359, Unique objects: 2,311\n",
      "\n",
      "SamplingEvent --sample_location--> GeospatialCoordLocation\n",
      "  Frequency: 1,110,334 relationships\n",
      "  Unique subjects: 1,110,334, Unique objects: 191,282\n",
      "\n",
      "SamplingEvent --responsibility--> Agent\n",
      "  Frequency: 1,109,332 relationships\n",
      "  Unique subjects: 1,109,332, Unique objects: 191\n",
      "\n",
      "MaterialSampleRecord --registrant--> Agent\n",
      "  Frequency: 421,521 relationships\n",
      "  Unique subjects: 421,521, Unique objects: 367\n",
      "\n",
      "SamplingSite --site_location--> GeospatialCoordLocation\n",
      "  Frequency: 18,213 relationships\n",
      "  Unique subjects: 18,213, Unique objects: 18,213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE ALL SENTENCE TYPES: Subject -> Predicate -> Object patterns\n",
    "print(\"ALL SENTENCE TYPES IN THE DATASET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# For each predicate, find what subject types use it and what object types they point to\n",
    "all_sentence_types = conn.execute(\"\"\"\n",
    "    WITH relationship_data AS (\n",
    "        -- Get all relationships (where p is not null)\n",
    "        SELECT s, p, o[1] as target_id\n",
    "        FROM pqg \n",
    "        WHERE p IS NOT NULL AND array_length(o) > 0\n",
    "    ),\n",
    "    subject_entities AS (\n",
    "        -- Get subject entity types\n",
    "        SELECT row_id, otype as subject_type\n",
    "        FROM pqg \n",
    "        WHERE p IS NULL\n",
    "    ),\n",
    "    object_entities AS (\n",
    "        -- Get object entity types  \n",
    "        SELECT row_id, otype as object_type\n",
    "        FROM pqg \n",
    "        WHERE p IS NULL\n",
    "    )\n",
    "    SELECT \n",
    "        subject_entities.subject_type,\n",
    "        relationship_data.p as predicate,\n",
    "        object_entities.object_type,\n",
    "        COUNT(*) as frequency,\n",
    "        COUNT(DISTINCT relationship_data.s) as unique_subjects,\n",
    "        COUNT(DISTINCT relationship_data.target_id) as unique_objects\n",
    "    FROM relationship_data\n",
    "    JOIN subject_entities ON relationship_data.s = subject_entities.row_id\n",
    "    JOIN object_entities ON relationship_data.target_id = object_entities.row_id\n",
    "    GROUP BY subject_entities.subject_type, relationship_data.p, object_entities.object_type\n",
    "    ORDER BY frequency DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"Found {len(all_sentence_types)} unique sentence types:\")\n",
    "print()\n",
    "\n",
    "# Display all sentence types\n",
    "for idx, row in all_sentence_types.iterrows():\n",
    "    subject = row['subject_type']\n",
    "    predicate = row['predicate']\n",
    "    object_type = row['object_type']\n",
    "    freq = row['frequency']\n",
    "    unique_subj = row['unique_subjects']\n",
    "    unique_obj = row['unique_objects']\n",
    "    \n",
    "    print(f\"{subject} --{predicate}--> {object_type}\")\n",
    "    print(f\"  Frequency: {freq:,} relationships\")\n",
    "    print(f\"  Unique subjects: {unique_subj:,}, Unique objects: {unique_obj:,}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE TYPE ANALYSIS\n",
      "========================================\n",
      "Sentence types grouped by SUBJECT:\n",
      "\n",
      "MaterialSampleRecord:\n",
      "  Uses 6 different predicates: produced_by, has_sample_object_type, has_material_category, has_context_category, keywords, registrant\n",
      "  Total relationships: 5,973,528\n",
      "\n",
      "SamplingEvent:\n",
      "  Uses 3 different predicates: sampling_site, sample_location, responsibility\n",
      "  Total relationships: 3,330,078\n",
      "\n",
      "SamplingSite:\n",
      "  Uses 1 different predicates: site_location\n",
      "  Total relationships: 18,213\n",
      "\n",
      "\n",
      "SENTENCE TYPE PATTERNS:\n",
      "------------------------------\n",
      "1. MaterialSampleRecord entities have the most relationships:\n",
      "   - produced_by ‚Üí SamplingEvent (1,110,412 times)\n",
      "   - has_sample_object_type ‚Üí IdentifiedConcept (1,110,412 times)\n",
      "   - has_material_category ‚Üí IdentifiedConcept (1,110,412 times)\n",
      "   - has_context_category ‚Üí IdentifiedConcept (1,110,412 times)\n",
      "   - keywords ‚Üí IdentifiedConcept (1,110,359 times)\n",
      "   - registrant ‚Üí Agent (421,521 times)\n",
      "\n",
      "2. SamplingEvent entities connect to:\n",
      "   - sampling_site ‚Üí SamplingSite (1,110,412 times)\n",
      "   - sample_location ‚Üí GeospatialCoordLocation (1,110,334 times)\n",
      "   - responsibility ‚Üí Agent (1,109,332 times)\n",
      "\n",
      "3. SamplingSite entities:\n",
      "   - site_location ‚Üí GeospatialCoordLocation (18,213 times)\n",
      "\n",
      "TOTAL: 10 unique sentence types define the complete grammar of this dataset!\n"
     ]
    }
   ],
   "source": [
    "# SENTENCE TYPE ANALYSIS SUMMARY\n",
    "print(\"SENTENCE TYPE ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Group sentence types by subject type\n",
    "subject_groups = all_sentence_types.groupby('subject_type').agg({\n",
    "    'predicate': 'count',\n",
    "    'frequency': 'sum'\n",
    "}).rename(columns={'predicate': 'num_predicates', 'frequency': 'total_relationships'})\n",
    "\n",
    "print(\"Sentence types grouped by SUBJECT:\")\n",
    "for subject, data in subject_groups.iterrows():\n",
    "    predicates_for_subject = all_sentence_types[all_sentence_types['subject_type'] == subject]['predicate'].tolist()\n",
    "    print(f\"\\n{subject}:\")\n",
    "    print(f\"  Uses {data['num_predicates']} different predicates: {', '.join(predicates_for_subject)}\")\n",
    "    print(f\"  Total relationships: {data['total_relationships']:,}\")\n",
    "\n",
    "print(f\"\\n\\nSENTENCE TYPE PATTERNS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Analyze the patterns\n",
    "print(\"1. MaterialSampleRecord entities have the most relationships:\")\n",
    "msr_types = all_sentence_types[all_sentence_types['subject_type'] == 'MaterialSampleRecord']\n",
    "for _, row in msr_types.iterrows():\n",
    "    print(f\"   - {row['predicate']} ‚Üí {row['object_type']} ({row['frequency']:,} times)\")\n",
    "\n",
    "print(f\"\\n2. SamplingEvent entities connect to:\")\n",
    "se_types = all_sentence_types[all_sentence_types['subject_type'] == 'SamplingEvent']\n",
    "for _, row in se_types.iterrows():\n",
    "    print(f\"   - {row['predicate']} ‚Üí {row['object_type']} ({row['frequency']:,} times)\")\n",
    "\n",
    "print(f\"\\n3. SamplingSite entities:\")\n",
    "ss_types = all_sentence_types[all_sentence_types['subject_type'] == 'SamplingSite']\n",
    "for _, row in ss_types.iterrows():\n",
    "    print(f\"   - {row['predicate']} ‚Üí {row['object_type']} ({row['frequency']:,} times)\")\n",
    "\n",
    "print(f\"\\nTOTAL: {len(all_sentence_types)} unique sentence types define the complete grammar of this dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical Edge Sentence Types from LinkML Schema\n",
    "\n",
    "To understand how many edge sentence types are theoretically possible, we parse the actual iSamples LinkML schema and extract only the relationships that create edges between entities (not properties like strings or dates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Reading live iSamples LinkML schema from GitHub: https://raw.githubusercontent.com/isamplesorg/metadata/refs/heads/main/src/schemas/isamples_core.yaml\n",
      "üìã Extracted 57 total relationships from live schema\n",
      "üîó Filtered to 14 edge relationships (entity‚Üíentity)\n",
      "\n",
      "üéØ Found 14 theoretical edge sentence types from live schema\n"
     ]
    }
   ],
   "source": [
    "# Parse the iSamples LinkML schema to derive theoretical edge sentence types\n",
    "import yaml\n",
    "import urllib.request\n",
    "\n",
    "# Use the live GitHub schema instead of local file\n",
    "schema_url = \"https://raw.githubusercontent.com/isamplesorg/metadata/refs/heads/main/src/schemas/isamples_core.yaml\"\n",
    "\n",
    "print(f\"‚úÖ Reading live iSamples LinkML schema from GitHub: {schema_url}\")\n",
    "\n",
    "try:\n",
    "    # Download and parse the LinkML schema from GitHub\n",
    "    with urllib.request.urlopen(schema_url) as response:\n",
    "        schema_content = response.read().decode('utf-8')\n",
    "    \n",
    "    schema = yaml.safe_load(schema_content)\n",
    "    \n",
    "    # Extract all relationships from classes and their slots\n",
    "    all_theoretical_relationships = []\n",
    "    classes = schema.get('classes', {})\n",
    "    \n",
    "    for class_name, class_def in classes.items():\n",
    "        slots = class_def.get('slots', [])\n",
    "        for slot_name in slots:\n",
    "            # Look up slot definition to get target type\n",
    "            slot_def = schema.get('slots', {}).get(slot_name, {})\n",
    "            slot_range = slot_def.get('range', 'Unknown')\n",
    "            all_theoretical_relationships.append((class_name, slot_name, slot_range))\n",
    "    \n",
    "    print(f\"üìã Extracted {len(all_theoretical_relationships)} total relationships from live schema\")\n",
    "    \n",
    "    # Filter to edge relationships only (entity ‚Üí entity, not entity ‚Üí primitive)\n",
    "    # Updated with all entity classes found in the live schema\n",
    "    isamples_entity_classes = {\n",
    "        'MaterialSampleRecord', 'SamplingEvent', 'SamplingSite', 'GeospatialCoordLocation',\n",
    "        'Agent', 'IdentifiedConcept', 'MaterialSampleCuration', 'SampleRelation'\n",
    "    }\n",
    "    \n",
    "    theoretical_edge_relationships = [\n",
    "        (subj, pred, obj) for subj, pred, obj in all_theoretical_relationships \n",
    "        if obj in isamples_entity_classes\n",
    "    ]\n",
    "    \n",
    "    print(f\"üîó Filtered to {len(theoretical_edge_relationships)} edge relationships (entity‚Üíentity)\")\n",
    "    THEORETICAL_RELATIONSHIPS = [(s, p, o, f\"{s} ‚Üí {o}\") for s, p, o in theoretical_edge_relationships]\n",
    "    \n",
    "    print(f\"\\nüéØ Found {len(theoretical_edge_relationships)} theoretical edge sentence types from live schema\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading schema from GitHub: {e}\")\n",
    "    print(\"Using fallback - cannot derive from actual schema\")\n",
    "    theoretical_edge_relationships = []\n",
    "    THEORETICAL_RELATIONSHIPS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ **SYSTEMATIC ANALYSIS: All Possible EDGE Sentence Types**\n",
      "======================================================================\n",
      "‚úÖ Loaded 14 total theoretical relationships from LinkML schema\n",
      "\n",
      "üìã **iSamples Entity Classes**: ['Agent', 'GeospatialCoordLocation', 'IdentifiedConcept', 'MaterialSampleCuration', 'MaterialSampleRecord', 'SampleRelation', 'SamplingEvent', 'SamplingSite']\n",
      "\n",
      "üîó **Theoretical EDGE Relationships** (entity‚Üíentity): 14\n",
      " 1. (MaterialSampleRecord, produced_by, SamplingEvent)\n",
      " 2. (MaterialSampleRecord, has_context_category, IdentifiedConcept)\n",
      " 3. (MaterialSampleRecord, has_material_category, IdentifiedConcept)\n",
      " 4. (MaterialSampleRecord, has_sample_object_type, IdentifiedConcept)\n",
      " 5. (MaterialSampleRecord, keywords, IdentifiedConcept)\n",
      " 6. (MaterialSampleRecord, related_resource, SampleRelation)\n",
      " 7. (MaterialSampleRecord, curation, MaterialSampleCuration)\n",
      " 8. (MaterialSampleRecord, registrant, Agent)\n",
      " 9. (SamplingSite, site_location, GeospatialCoordLocation)\n",
      "10. (SamplingEvent, has_context_category, IdentifiedConcept)\n",
      "11. (SamplingEvent, responsibility, Agent)\n",
      "12. (SamplingEvent, sampling_site, SamplingSite)\n",
      "13. (SamplingEvent, sample_location, GeospatialCoordLocation)\n",
      "14. (MaterialSampleCuration, responsibility, Agent)\n",
      "\n",
      "‚úÖ **Discovered in OpenContext** (all are edges): 10\n",
      " 1. (MaterialSampleRecord, has_context_category, IdentifiedConcept) ‚Üí 1,110,412 instances\n",
      " 2. (MaterialSampleRecord, has_material_category, IdentifiedConcept) ‚Üí 1,110,412 instances\n",
      " 3. (MaterialSampleRecord, has_sample_object_type, IdentifiedConcept) ‚Üí 1,110,412 instances\n",
      " 4. (MaterialSampleRecord, keywords, IdentifiedConcept) ‚Üí 1,110,359 instances\n",
      " 5. (MaterialSampleRecord, produced_by, SamplingEvent) ‚Üí 1,110,412 instances\n",
      " 6. (MaterialSampleRecord, registrant, Agent) ‚Üí 421,521 instances\n",
      " 7. (SamplingEvent, responsibility, Agent) ‚Üí 1,109,332 instances\n",
      " 8. (SamplingEvent, sample_location, GeospatialCoordLocation) ‚Üí 1,110,334 instances\n",
      " 9. (SamplingEvent, sampling_site, SamplingSite) ‚Üí 1,110,412 instances\n",
      "10. (SamplingSite, site_location, GeospatialCoordLocation) ‚Üí 18,213 instances\n",
      "\n",
      "‚ùå **MISSING** theoretical edge sentence types (4):\n",
      " 1. (MaterialSampleCuration, responsibility, Agent)\n",
      " 2. (MaterialSampleRecord, curation, MaterialSampleCuration)\n",
      " 3. (MaterialSampleRecord, related_resource, SampleRelation)\n",
      " 4. (SamplingEvent, has_context_category, IdentifiedConcept)\n",
      "\n",
      "‚úÖ **IMPLEMENTED** theoretical edge sentence types (10):\n",
      " 1. (MaterialSampleRecord, has_context_category, IdentifiedConcept)\n",
      " 2. (MaterialSampleRecord, has_material_category, IdentifiedConcept)\n",
      " 3. (MaterialSampleRecord, has_sample_object_type, IdentifiedConcept)\n",
      " 4. (MaterialSampleRecord, keywords, IdentifiedConcept)\n",
      " 5. (MaterialSampleRecord, produced_by, SamplingEvent)\n",
      " 6. (MaterialSampleRecord, registrant, Agent)\n",
      " 7. (SamplingEvent, responsibility, Agent)\n",
      " 8. (SamplingEvent, sample_location, GeospatialCoordLocation)\n",
      " 9. (SamplingEvent, sampling_site, SamplingSite)\n",
      "10. (SamplingSite, site_location, GeospatialCoordLocation)\n",
      "\n",
      "üìä **SUMMARY: Edge Sentence Types Only**\n",
      "‚Ä¢ Theoretical edge sentence types: 14\n",
      "‚Ä¢ Discovered in OpenContext: 10\n",
      "‚Ä¢ Implementation coverage: 10/14 = 71.4%\n",
      "‚Ä¢ Missing from OpenContext: 4\n",
      "‚Ä¢ Bonus patterns in OpenContext: 0\n",
      "\n",
      "üéØ **Answer**: There are 14 theoretically possible EDGE sentence types\n",
      "   OpenContext implements 10 of them (71.4% coverage)\n",
      "   All OpenContext sentence types are valid edges (otype='_edge_') connecting entities\n"
     ]
    }
   ],
   "source": [
    "# Let's systematically compute ALL possible (subject_type, predicate, object_type) sentence types\n",
    "# where otype = '_edge_' (actual graph edges, not literals)\n",
    "\n",
    "print(\"üî¨ **SYSTEMATIC ANALYSIS: All Possible EDGE Sentence Types**\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# First, let's see what we actually extracted from the LinkML schema\n",
    "print(f\"‚úÖ Loaded {len(THEORETICAL_RELATIONSHIPS)} total theoretical relationships from LinkML schema\")\n",
    "\n",
    "# The key insight: we only want EDGE relationships (entity ‚Üí entity), not entity ‚Üí literal\n",
    "# In parquet files, edges have otype='_edge_' and connect entities, while literals are stored as entity properties\n",
    "\n",
    "# Use the same entity classes as defined in the schema parsing cell for consistency\n",
    "print(f\"\\nüìã **iSamples Entity Classes**: {sorted(isamples_entity_classes)}\")\n",
    "\n",
    "# Filter to only edge relationships (entity ‚Üí entity, not entity ‚Üí literal/primitive)\n",
    "theoretical_edge_relationships = []\n",
    "for subj, pred, obj, desc in THEORETICAL_RELATIONSHIPS:\n",
    "    if obj in isamples_entity_classes:  # Object must be an entity class\n",
    "        theoretical_edge_relationships.append((subj, pred, obj))\n",
    "\n",
    "print(f\"\\nüîó **Theoretical EDGE Relationships** (entity‚Üíentity): {len(theoretical_edge_relationships)}\")\n",
    "for i, (subj, pred, obj) in enumerate(theoretical_edge_relationships, 1):\n",
    "    print(f\"{i:2d}. ({subj}, {pred}, {obj})\")\n",
    "\n",
    "# What we discovered in OpenContext data (all are edges since we filtered to otype='_edge_')\n",
    "discovered_edge_types = set()\n",
    "for _, row in all_sentence_types.iterrows():\n",
    "    subj_type = row['subject_type']\n",
    "    predicate = row['predicate'] \n",
    "    obj_type = row['object_type']\n",
    "    discovered_edge_types.add((subj_type, predicate, obj_type))\n",
    "\n",
    "print(f\"\\n‚úÖ **Discovered in OpenContext** (all are edges): {len(discovered_edge_types)}\")\n",
    "for i, (subj, pred, obj) in enumerate(sorted(discovered_edge_types), 1):\n",
    "    # Get frequency\n",
    "    matching = all_sentence_types[\n",
    "        (all_sentence_types['subject_type'] == subj) & \n",
    "        (all_sentence_types['predicate'] == pred) & \n",
    "        (all_sentence_types['object_type'] == obj)\n",
    "    ]\n",
    "    freq = matching['frequency'].iloc[0] if not matching.empty else 0\n",
    "    print(f\"{i:2d}. ({subj}, {pred}, {obj}) ‚Üí {freq:,} instances\")\n",
    "\n",
    "# Find missing theoretical edge relationships\n",
    "theoretical_edge_tuples = set(theoretical_edge_relationships)\n",
    "missing_edge_relationships = theoretical_edge_tuples - discovered_edge_types\n",
    "implemented_edge_relationships = theoretical_edge_tuples & discovered_edge_types\n",
    "\n",
    "print(f\"\\n‚ùå **MISSING** theoretical edge sentence types ({len(missing_edge_relationships)}):\")\n",
    "for i, (subj, pred, obj) in enumerate(sorted(missing_edge_relationships), 1):\n",
    "    print(f\"{i:2d}. ({subj}, {pred}, {obj})\")\n",
    "\n",
    "print(f\"\\n‚úÖ **IMPLEMENTED** theoretical edge sentence types ({len(implemented_edge_relationships)}):\")\n",
    "for i, (subj, pred, obj) in enumerate(sorted(implemented_edge_relationships), 1):\n",
    "    print(f\"{i:2d}. ({subj}, {pred}, {obj})\")\n",
    "\n",
    "# Check for bonus edge relationships (found but not in theory)\n",
    "bonus_edge_relationships = discovered_edge_types - theoretical_edge_tuples\n",
    "if bonus_edge_relationships:\n",
    "    print(f\"\\nüéÅ **BONUS** edge relationships ({len(bonus_edge_relationships)} not in LinkML schema):\")\n",
    "    for i, (subj, pred, obj) in enumerate(sorted(bonus_edge_relationships), 1):\n",
    "        print(f\"{i:2d}. ({subj}, {pred}, {obj})\")\n",
    "\n",
    "print(f\"\\nüìä **SUMMARY: Edge Sentence Types Only**\")\n",
    "print(f\"‚Ä¢ Theoretical edge sentence types: {len(theoretical_edge_relationships)}\")\n",
    "print(f\"‚Ä¢ Discovered in OpenContext: {len(discovered_edge_types)}\")\n",
    "print(f\"‚Ä¢ Implementation coverage: {len(implemented_edge_relationships)}/{len(theoretical_edge_relationships)} = {100*len(implemented_edge_relationships)/len(theoretical_edge_relationships):.1f}%\")\n",
    "print(f\"‚Ä¢ Missing from OpenContext: {len(missing_edge_relationships)}\")\n",
    "print(f\"‚Ä¢ Bonus patterns in OpenContext: {len(bonus_edge_relationships)}\")\n",
    "\n",
    "# Store results for further analysis\n",
    "THEORETICAL_EDGE_COUNT = len(theoretical_edge_relationships)\n",
    "DISCOVERED_EDGE_COUNT = len(discovered_edge_types)\n",
    "COVERAGE_PERCENTAGE = 100 * len(implemented_edge_relationships) / len(theoretical_edge_relationships)\n",
    "\n",
    "print(f\"\\nüéØ **Answer**: There are {THEORETICAL_EDGE_COUNT} theoretically possible EDGE sentence types\")\n",
    "print(f\"   OpenContext implements {DISCOVERED_EDGE_COUNT} of them ({COVERAGE_PERCENTAGE:.1f}% coverage)\")\n",
    "print(f\"   All OpenContext sentence types are valid edges (otype='_edge_') connecting entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PQG Grammar Analysis: 14 Theoretical Edge Sentence Types\n",
    "\n",
    "Looking at the **fundamental PQG grammar** derived from the live iSamples LinkML schema:\n",
    "\n",
    "### Complete Theoretical Grammar (14 Edge Types)\n",
    "The iSamples model defines **14 theoretically possible edge sentence types** (entity‚Üíentity relationships):\n",
    "\n",
    "**MaterialSampleRecord relationships (7):**\n",
    "1. `MaterialSampleRecord ‚Üí SamplingEvent` (produced_by) \n",
    "2. `MaterialSampleRecord ‚Üí IdentifiedConcept` (has_context_category)\n",
    "3. `MaterialSampleRecord ‚Üí IdentifiedConcept` (has_material_category) \n",
    "4. `MaterialSampleRecord ‚Üí IdentifiedConcept` (has_sample_object_type)\n",
    "5. `MaterialSampleRecord ‚Üí IdentifiedConcept` (keywords)\n",
    "6. `MaterialSampleRecord ‚Üí SampleRelation` (related_resource) \n",
    "7. `MaterialSampleRecord ‚Üí MaterialSampleCuration` (curation)\n",
    "8. `MaterialSampleRecord ‚Üí Agent` (registrant)\n",
    "\n",
    "**SamplingEvent relationships (4):**\n",
    "9. `SamplingEvent ‚Üí IdentifiedConcept` (has_context_category)\n",
    "10. `SamplingEvent ‚Üí Agent` (responsibility)\n",
    "11. `SamplingEvent ‚Üí SamplingSite` (sampling_site)\n",
    "12. `SamplingEvent ‚Üí GeospatialCoordLocation` (sample_location)\n",
    "\n",
    "**SamplingSite relationships (1):**\n",
    "13. `SamplingSite ‚Üí GeospatialCoordLocation` (site_location)\n",
    "\n",
    "**MaterialSampleCuration relationships (1):**\n",
    "14. `MaterialSampleCuration ‚Üí Agent` (responsibility)\n",
    "\n",
    "### OpenContext Implementation: 10/14 (71.4% coverage)\n",
    "\n",
    "OpenContext implements 10 of these 14 theoretical edge types, missing:\n",
    "- Curation workflows (`MaterialSampleCuration` relationships)\n",
    "- Cross-sample references (`SampleRelation` relationships)  \n",
    "- Event context classification (`SamplingEvent ‚Üí has_context_category`)\n",
    "- Resource linking (`MaterialSampleRecord ‚Üí related_resource`)\n",
    "\n",
    "This represents a **complete PQG grammar analysis** showing that **14 edge sentence types** are theoretically possible in the iSamples model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common relationship types (iSamples predicates):\n",
      "                predicate  usage_count  unique_subjects\n",
      "0   has_material_category      1110412          1110412\n",
      "1    has_context_category      1110412          1110412\n",
      "2           sampling_site      1110412          1110412\n",
      "3  has_sample_object_type      1110412          1110412\n",
      "4             produced_by      1110412          1110412\n",
      "5                keywords      1110359          1110359\n",
      "6         sample_location      1110334          1110334\n",
      "7          responsibility      1109332          1109332\n",
      "8              registrant       421521           421521\n",
      "9           site_location        18213            18213\n"
     ]
    }
   ],
   "source": [
    "# Explore edge predicates (iSamples model predicates)\n",
    "edge_predicates = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        p as predicate,\n",
    "        COUNT(*) as usage_count,\n",
    "        COUNT(DISTINCT s) as unique_subjects\n",
    "    FROM pqg\n",
    "    WHERE otype = '_edge_'\n",
    "    GROUP BY p\n",
    "    ORDER BY usage_count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Most common relationship types (iSamples predicates):\")\n",
    "print(edge_predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "['row_id', 'pid', 'tcreated', 'tmodified', 'otype', 's', 'p', 'o', 'n', 'altids', 'geometry', 'authorized_by', 'has_feature_of_interest', 'affiliation', 'sampling_purpose', 'complies_with', 'project', 'alternate_identifiers', 'relationship', 'elevation', 'sample_identifier', 'dc_rights', 'result_time', 'contact_information', 'latitude', 'target', 'role', 'scheme_uri', 'is_part_of', 'scheme_name', 'name', 'longitude', 'obfuscated', 'curation_location', 'last_modified_time', 'access_constraints', 'place_name', 'description', 'label', 'thumbnail_url']\n",
      "\n",
      "Sample row:\n",
      "row_id                                                                     1\n",
      "pid                          geoloc_1b9d137af503afe20873ccbd9797b64eb0d4bcfb\n",
      "tcreated                                                                <NA>\n",
      "tmodified                                                               <NA>\n",
      "otype                                                GeospatialCoordLocation\n",
      "s                                                                       <NA>\n",
      "p                                                                       None\n",
      "o                                                                       <NA>\n",
      "n                                                                       None\n",
      "altids                                                                  <NA>\n",
      "geometry                   [1, 1, 0, 0, 0, 162, 105, 71, 173, 38, 243, 54...\n",
      "authorized_by                                                           <NA>\n",
      "has_feature_of_interest                                                 None\n",
      "affiliation                                                             None\n",
      "sampling_purpose                                                        None\n",
      "complies_with                                                           <NA>\n",
      "project                                                                 None\n",
      "alternate_identifiers                                                   <NA>\n",
      "relationship                                                            None\n",
      "elevation                                                               None\n",
      "sample_identifier                                                       None\n",
      "dc_rights                                                               None\n",
      "result_time                                                             None\n",
      "contact_information                                                     None\n",
      "latitude                                                           37.904054\n",
      "target                                                                  None\n",
      "role                                                                    None\n",
      "scheme_uri                                                              None\n",
      "is_part_of                                                              <NA>\n",
      "scheme_name                                                             None\n",
      "name                                                                    None\n",
      "longitude                                                          22.949809\n",
      "obfuscated                                                             False\n",
      "curation_location                                                       None\n",
      "last_modified_time                                                      None\n",
      "access_constraints                                                      <NA>\n",
      "place_name                                                              <NA>\n",
      "description                                                             None\n",
      "label                                                                   None\n",
      "thumbnail_url                                                           None\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# First, let's check what columns we actually have in the dataset\n",
    "schema_check = conn.execute(\"\"\"\n",
    "    SELECT * FROM pqg LIMIT 1\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Available columns:\")\n",
    "print(schema_check.columns.tolist())\n",
    "print(\"\\nSample row:\")\n",
    "print(schema_check.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_site_subgraph(conn, site_name_pattern, output_prefix):\n",
    "    \"\"\"Export all data related to a specific site\"\"\"\n",
    "    \n",
    "    # Find the site\n",
    "    site_info = conn.execute(\"\"\"\n",
    "        SELECT row_id, pid, label\n",
    "        FROM pqg\n",
    "        WHERE otype = 'SamplingSite'\n",
    "        AND label LIKE ?\n",
    "        LIMIT 1\n",
    "    \"\"\", [f'%{site_name_pattern}%']).fetchdf()\n",
    "    \n",
    "    if site_info.empty:\n",
    "        print(f\"No site found matching '{site_name_pattern}'\")\n",
    "        return None\n",
    "    \n",
    "    site_row_id = site_info.iloc[0]['row_id']\n",
    "    print(f\"Found site: {site_info.iloc[0]['label']}\")\n",
    "    \n",
    "    # Get all related entities (simplified version - not recursive)\n",
    "    related_data = conn.execute(\"\"\"\n",
    "        WITH site_related AS (\n",
    "            -- Get the site itself\n",
    "            SELECT * FROM pqg WHERE row_id = ?\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            -- Get edges from the site\n",
    "            SELECT * FROM pqg e\n",
    "            WHERE e.otype = '_edge_' AND e.s = ?\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            -- Get entities connected to the site\n",
    "            SELECT n.* FROM pqg e\n",
    "            JOIN pqg n ON n.row_id = e.o[1]\n",
    "            WHERE e.otype = '_edge_' AND e.s = ?\n",
    "        )\n",
    "        SELECT * FROM site_related\n",
    "    \"\"\", [site_row_id, site_row_id, site_row_id]).fetchdf()\n",
    "    \n",
    "    # Save to parquet\n",
    "    output_file = f\"{output_prefix}_{site_info.iloc[0]['pid']}.parquet\"\n",
    "    related_data.to_parquet(output_file)\n",
    "    print(f\"Exported {len(related_data)} rows to {output_file}\")\n",
    "    \n",
    "    return related_data\n",
    "\n",
    "# Example usage (commented out to avoid creating files)\n",
    "# pompeii_data = export_site_subgraph(conn, \"Pompeii\", \"pompeii_subgraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Data Quality:\n",
      "  location_type   count  pct_with_coords\n",
      "0       Precise  197221        99.999493\n",
      "1    Obfuscated    1926       100.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for location data quality\n",
    "location_quality = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        CASE \n",
    "            WHEN obfuscated THEN 'Obfuscated'\n",
    "            ELSE 'Precise'\n",
    "        END as location_type,\n",
    "        COUNT(*) as count,\n",
    "        AVG(CASE WHEN latitude IS NOT NULL THEN 1.0 ELSE 0.0 END) * 100 as pct_with_coords\n",
    "    FROM pqg\n",
    "    WHERE otype = 'GeospatialCoordLocation'\n",
    "    GROUP BY location_type\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Location Data Quality:\")\n",
    "print(location_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orphaned Nodes by Type:\n",
      "               otype  orphan_count\n",
      "0              Agent             1\n",
      "1  IdentifiedConcept         16990\n"
     ]
    }
   ],
   "source": [
    "# Check for orphaned nodes (nodes not connected by any edge)\n",
    "orphan_check = conn.execute(\"\"\"\n",
    "    WITH connected_nodes AS (\n",
    "        SELECT DISTINCT s as row_id FROM pqg WHERE otype = '_edge_'\n",
    "        UNION\n",
    "        SELECT DISTINCT unnest(o) as row_id FROM pqg WHERE otype = '_edge_'\n",
    "    )\n",
    "    SELECT\n",
    "        n.otype,\n",
    "        COUNT(*) as orphan_count\n",
    "    FROM pqg n\n",
    "    LEFT JOIN connected_nodes c ON n.row_id = c.row_id\n",
    "    WHERE n.otype != '_edge_' AND c.row_id IS NULL\n",
    "    GROUP BY n.otype\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"\\nOrphaned Nodes by Type:\")\n",
    "print(orphan_check if not orphan_check.empty else \"No orphaned nodes found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "total_rows: 11,786,509\n",
      "unique_pids: 11,786,509\n",
      "edge_count: 9,321,819\n",
      "node_count: 2,464,690\n",
      "entity_types: 6\n",
      "relationship_types: 10\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive summary\n",
    "summary = conn.execute(\"\"\"\n",
    "    WITH stats AS (\n",
    "        SELECT\n",
    "            COUNT(*) as total_rows,\n",
    "            COUNT(DISTINCT pid) as unique_pids,\n",
    "            COUNT(CASE WHEN otype = '_edge_' THEN 1 END) as edge_count,\n",
    "            COUNT(CASE WHEN otype != '_edge_' THEN 1 END) as node_count,\n",
    "            COUNT(DISTINCT CASE WHEN otype != '_edge_' THEN otype END) as entity_types,\n",
    "            COUNT(DISTINCT p) as relationship_types\n",
    "        FROM pqg\n",
    "    )\n",
    "    SELECT * FROM stats\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "for col in summary.columns:\n",
    "    print(f\"{col}: {summary[col].iloc[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug: Specific Geo Point Analysis\n",
    "\n",
    "Testing queries for parquet_cesium.qmd debugging. This section demonstrates:\n",
    "- **Generic PQG debugging**: How to trace edge connections\n",
    "- **OpenContext validation**: Verifying archaeological data relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def ark_to_url(pid: str) -> str:\n",
    "    \"\"\"Return a resolvable n2t.net URL for an ARK identifier.\n",
    "    If pid is not an ARK, return it as a string.\n",
    "    \"\"\"\n",
    "    if isinstance(pid, str) and pid.startswith(\"ark:/\"):\n",
    "        return f\"https://n2t.net/{pid}\"\n",
    "    return str(pid)\n",
    "\n",
    "def ensure_connection():\n",
    "    \"\"\"Ensure we have a working DuckDB connection with the parquet view\"\"\"\n",
    "    global conn\n",
    "    try:\n",
    "        conn.execute(\"SELECT 1\").fetchone()\n",
    "    except (NameError, Exception):\n",
    "        print(\"Recreating DuckDB connection...\")\n",
    "        conn = duckdb.connect()\n",
    "        conn.execute(f\"CREATE VIEW pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "        print(\"Connection restored!\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Debugging geo location: geoloc_7ea562cce4c70e4b37f7915e8384880c86607729 ===\n",
      "\n",
      "1. Geo Location Record:\n",
      "{'row_id': 194991, 'pid': 'geoloc_7ea562cce4c70e4b37f7915e8384880c86607729', 'otype': 'GeospatialCoordLocation', 'latitude': 28.058084, 'longitude': -81.146851}\n",
      "   Row ID: 194991\n"
     ]
    }
   ],
   "source": [
    "# Debug specific geo location from parquet_cesium.qmd\n",
    "# This section remains provider-agnostic and uses iSamples model semantics\n",
    "\n",
    "target_geo_pid = \"geoloc_7ea562cce4c70e4b37f7915e8384880c86607729\"\n",
    "\n",
    "print(f\"=== Debugging geo location: {target_geo_pid} ===\\n\")\n",
    "\n",
    "# 1. Find the geo location record\n",
    "geo_record = conn.execute(\"\"\"\n",
    "    SELECT row_id, pid, otype, latitude, longitude \n",
    "    FROM pqg \n",
    "    WHERE pid = ? AND otype = 'GeospatialCoordLocation'\n",
    "\"\"\", [target_geo_pid]).fetchdf()\n",
    "\n",
    "print(\"1. Geo Location Record:\")\n",
    "if not geo_record.empty:\n",
    "    print(geo_record.to_dict('records')[0])\n",
    "    geo_row_id = geo_record.iloc[0]['row_id']\n",
    "    print(f\"   Row ID: {geo_row_id}\")\n",
    "else:\n",
    "    print(\"   ‚ùå Geo location not found!\")\n",
    "    geo_row_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c7777d927f44869fcaf27e5ad11da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Edges pointing to this geo location (1 found):\n",
      "       predicate  count\n",
      "0  site_location      1\n",
      "\n",
      "Detailed edges:\n",
      "   site_location: row_id 217020 -> geo location\n"
     ]
    }
   ],
   "source": [
    "# 2. Check what edges point to this geo location\n",
    "if geo_row_id is not None:\n",
    "    geo_row_id_int = int(geo_row_id)\n",
    "    edges_to_geo = conn.execute(\"\"\"\n",
    "        SELECT s, p, otype as edge_type, pid as edge_pid\n",
    "        FROM pqg \n",
    "        WHERE otype = '_edge_' AND ? = ANY(o)\n",
    "    \"\"\", [geo_row_id_int]).fetchdf()\n",
    "\n",
    "    print(f\"\\n2. Edges pointing to this geo location ({len(edges_to_geo)} found):\")\n",
    "    if not edges_to_geo.empty:\n",
    "        edge_summary = edges_to_geo.groupby('p').size().reset_index()\n",
    "        edge_summary.columns = ['predicate', 'count']\n",
    "        print(edge_summary)\n",
    "        print(\"\\nDetailed edges:\")\n",
    "        for _, edge in edges_to_geo.iterrows():\n",
    "            print(f\"   {edge['p']}: row_id {edge['s']} -> geo location\")\n",
    "    else:\n",
    "        print(\"   ‚ùå No edges point to this geo location!\")\n",
    "else:\n",
    "    print(\"\\n2. Skipping edge analysis - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Direct Event Samples (0 found):\n",
      "   ‚ùå No direct event samples found!\n"
     ]
    }
   ],
   "source": [
    "# 3. Direct event samples\n",
    "if geo_row_id is not None:\n",
    "    direct_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            s.name as sample_name,\n",
    "            evt.pid as event_id,\n",
    "            evt.label as event_label,\n",
    "            'direct_event_location' as location_path\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1  ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2  ON evt.row_id = e2.s AND e2.p = 'sample_location'\n",
    "        JOIN pqg g   ON e2.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 20\n",
    "    \"\"\", [target_geo_pid]).fetchdf()\n",
    "\n",
    "    print(f\"\\n3. Direct Event Samples ({len(direct_samples)} found):\")\n",
    "    if not direct_samples.empty:\n",
    "        print(direct_samples[['sample_id', 'sample_label', 'event_id', 'event_label']].head())\n",
    "    else:\n",
    "        print(\"   ‚ùå No direct event samples found!\")\n",
    "else:\n",
    "    print(\"\\n3. Skipping direct samples query - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Site-Associated Samples (1 found):\n",
      "              sample_id    sample_label       site_name  \\\n",
      "0  ark:/28722/k2x63t42w  Assemblage 364  Osceola County   \n",
      "\n",
      "                                            event_id  \n",
      "0  sampevent_b19416f025a0b804563976f00aa78a8524c2...  \n"
     ]
    }
   ],
   "source": [
    "# 4. Site-associated samples\n",
    "if geo_row_id is not None:\n",
    "    site_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            s.name as sample_name,\n",
    "            evt.pid as event_id,\n",
    "            evt.label as event_label,\n",
    "            site.label as site_name,\n",
    "            'via_site_location' as location_path\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1   ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt  ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2   ON evt.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "        JOIN pqg site ON e2.o[1] = site.row_id\n",
    "        JOIN pqg e3   ON site.row_id = e3.s AND e3.p = 'site_location'\n",
    "        JOIN pqg g    ON e3.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND site.otype = 'SamplingSite'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 20\n",
    "    \"\"\", [target_geo_pid]).fetchdf()\n",
    "\n",
    "    print(f\"\\n4. Site-Associated Samples ({len(site_samples)} found):\")\n",
    "    if not site_samples.empty:\n",
    "        print(site_samples[['sample_id', 'sample_label', 'site_name', 'event_id']].head())\n",
    "    else:\n",
    "        print(\"   ‚ùå No site-associated samples found!\")\n",
    "else:\n",
    "    print(\"\\n4. Skipping site samples query - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Detailed metadata for sample: ark:/28722/k2x63t42w\n",
      "   Resolvable URL: https://n2t.net/ark:/28722/k2x63t42w\n",
      "   Sample label: Assemblage 364\n",
      "   Location path: via_site_location\n",
      "\n",
      "   Materials (1 found):\n",
      "     - Material (https://w3id.org/isample/vocabulary/material/1.0/material)\n",
      "\n",
      "   Responsible Agents (1 found):\n",
      "     - None (https://opencontext.org/persons/ce3e13cb-c7b6-4d61-55fe-bb0d52a8374a)\n"
     ]
    }
   ],
   "source": [
    "# 5. If we found samples, get detailed metadata for the first sample\n",
    "all_samples = []\n",
    "if 'direct_samples' in locals() and not direct_samples.empty:\n",
    "    all_samples.extend(direct_samples.to_dict('records'))\n",
    "if 'site_samples' in locals() and not site_samples.empty:\n",
    "    all_samples.extend(site_samples.to_dict('records'))\n",
    "\n",
    "if all_samples:\n",
    "    first_sample = all_samples[0]\n",
    "    sample_pid = first_sample['sample_id']\n",
    "\n",
    "    print(f\"\\n5. Detailed metadata for sample: {sample_pid}\")\n",
    "    print(f\"   Resolvable URL: {ark_to_url(sample_pid)}\")\n",
    "    print(f\"   Sample label: {first_sample.get('sample_label', 'N/A')}\")\n",
    "    print(f\"   Location path: {first_sample.get('location_path', 'N/A')}\")\n",
    "\n",
    "    # Materials for this sample\n",
    "    materials = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            mat.pid as material_id,\n",
    "            mat.label as material_type,\n",
    "            mat.name as material_category\n",
    "        FROM pqg s\n",
    "        JOIN pqg e   ON s.row_id = e.s AND e.p = 'has_material_category'\n",
    "        JOIN pqg mat ON e.o[1] = mat.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND s.pid = ?\n",
    "          AND e.otype = '_edge_'\n",
    "          AND mat.otype = 'IdentifiedConcept'\n",
    "    \"\"\", [sample_pid]).fetchdf()\n",
    "\n",
    "    print(f\"\\n   Materials ({len(materials)} found):\")\n",
    "    if not materials.empty:\n",
    "        for _, mat in materials.iterrows():\n",
    "            print(f\"     - {mat['material_type']} ({ark_to_url(mat['material_id'])})\")\n",
    "    else:\n",
    "        print(\"     ‚ùå No materials found!\")\n",
    "\n",
    "    # Agents responsible for this sample\n",
    "    agents = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            agent.pid as agent_id,\n",
    "            agent.label as agent_name,\n",
    "            agent.name as agent_role\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1    ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt   ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2    ON evt.row_id = e2.s AND e2.p = 'responsibility'\n",
    "        JOIN pqg agent ON e2.o[1] = agent.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND s.pid = ?\n",
    "          AND e1.otype = '_edge_'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND e2.otype = '_edge_'\n",
    "          AND agent.otype = 'Agent'\n",
    "        LIMIT 10\n",
    "    \"\"\", [sample_pid]).fetchdf()\n",
    "\n",
    "    print(f\"\\n   Responsible Agents ({len(agents)} found):\")\n",
    "    if not agents.empty:\n",
    "        for _, agent in agents.iterrows():\n",
    "            print(f\"     - {agent['agent_name']} ({ark_to_url(agent['agent_id'])})\")\n",
    "    else:\n",
    "        print(\"     ‚ùå No agents found!\")\n",
    "else:\n",
    "    print(\"\\n5. No samples found to analyze metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY for geoloc_7ea562cce4c70e4b37f7915e8384880c86607729 ===\n",
      "‚úÖ Geo location found (row_id: 194991)\n",
      "üìç Coordinates: 28.058084, -81.146851\n",
      "üî¨ Total samples found: 1\n",
      "   - Direct event samples: 0\n",
      "   - Site-associated samples: 1\n",
      "‚úÖ Sample metadata retrieval successful!\n",
      "\n",
      "=== END DEBUG for geoloc_7ea562cce4c70e4b37f7915e8384880c86607729 ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Summary of findings for this geo location\n",
    "print(f\"\\n=== SUMMARY for {target_geo_pid} ===\")\n",
    "if geo_row_id is not None:\n",
    "    print(f\"‚úÖ Geo location found (row_id: {geo_row_id})\")\n",
    "    print(f\"üìç Coordinates: {geo_record.iloc[0]['latitude']}, {geo_record.iloc[0]['longitude']}\")\n",
    "\n",
    "    total_samples = len(all_samples)\n",
    "    direct_count = len([s for s in all_samples if s.get('location_path') == 'direct_event_location'])\n",
    "    site_count = len([s for s in all_samples if s.get('location_path') == 'via_site_location'])\n",
    "\n",
    "    print(f\"üî¨ Total samples found: {total_samples}\")\n",
    "    print(f\"   - Direct event samples: {direct_count}\")\n",
    "    print(f\"   - Site-associated samples: {site_count}\")\n",
    "\n",
    "    if total_samples > 0:\n",
    "        print(\"‚úÖ Sample metadata retrieval successful!\")\n",
    "    else:\n",
    "        print(\"‚ùå No samples found for this location\")\n",
    "else:\n",
    "    print(\"‚ùå Geo location not found in dataset!\")\n",
    "\n",
    "print(f\"\\n=== END DEBUG for {target_geo_pid} ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing with geo locations that have direct sample_location edges ===\n",
      "                                               pid   latitude  longitude  \\\n",
      "0  geoloc_35842a4fa478ae28c68f54d1db36c8e968d62dcb  37.668196  32.827191   \n",
      "1  geoloc_17bae610b87227ef806161bdb40ac97b4cd8ef5e  30.328700  35.442100   \n",
      "2  geoloc_045c25c9e19aeac434ef19616cf2130175cfd130  35.034889  32.421841   \n",
      "\n",
      "   edge_count  \n",
      "0      131022  \n",
      "1      108846  \n",
      "2       52252  \n",
      "\n",
      "Testing direct samples query with: geoloc_35842a4fa478ae28c68f54d1db36c8e968d62dcb\n",
      "Direct samples found: 5\n",
      "‚úÖ Direct event samples exist\n",
      "              sample_id sample_label  \\\n",
      "0  ark:/28722/k2668d05z  16253.F1834   \n",
      "1  ark:/28722/k2h991t2x     8864.F27   \n",
      "2  ark:/28722/k2bv7f09q     1128.F82   \n",
      "3  ark:/28722/k2cv4fm0m    15763.F26   \n",
      "4  ark:/28722/k26m36047   16590.F831   \n",
      "\n",
      "                                            event_id  \n",
      "0  sampevent_44cdd124049ade33ac5da5b9a96ebe227a40...  \n",
      "1  sampevent_84770032a3e6eef593a2f68f1da5f6cc98b5...  \n",
      "2  sampevent_3243d03424bba12b726698f890dbc126a581...  \n",
      "3  sampevent_0adb3e718023bb1e97644c5e51273de1b4c2...  \n",
      "4  sampevent_e8ba93331fec26360e8e688158d669623bfe...  \n"
     ]
    }
   ],
   "source": [
    "# 7. Test with a different geo location that has sample_location edges\n",
    "sample_location_geos = conn.execute(\"\"\"\n",
    "    SELECT g.pid, g.latitude, g.longitude, COUNT(*) as edge_count\n",
    "    FROM pqg e\n",
    "    JOIN pqg g ON e.o[1] = g.row_id\n",
    "    WHERE e.otype = '_edge_'\n",
    "      AND e.p = 'sample_location'\n",
    "      AND g.otype = 'GeospatialCoordLocation'\n",
    "    GROUP BY g.pid, g.latitude, g.longitude\n",
    "    ORDER BY edge_count DESC\n",
    "    LIMIT 3\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"=== Testing with geo locations that have direct sample_location edges ===\")\n",
    "print(sample_location_geos)\n",
    "\n",
    "if not sample_location_geos.empty:\n",
    "    test_geo_pid = sample_location_geos.iloc[0]['pid']\n",
    "    print(f\"\\nTesting direct samples query with: {test_geo_pid}\")\n",
    "\n",
    "    test_direct_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            evt.pid as event_id,\n",
    "            evt.label as event_label\n",
    "        FROM pqg s\n",
    "        JOIN pqg e1  ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN pqg evt ON e1.o[1] = evt.row_id\n",
    "        JOIN pqg e2  ON evt.row_id = e2.s AND e2.p = 'sample_location'\n",
    "        JOIN pqg g   ON e2.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND evt.otype = 'SamplingEvent'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 5\n",
    "    \"\"\", [test_geo_pid]).fetchdf()\n",
    "\n",
    "    print(f\"Direct samples found: {len(test_direct_samples)}\")\n",
    "    if not test_direct_samples.empty:\n",
    "        print(\"‚úÖ Direct event samples exist\")\n",
    "        print(test_direct_samples[['sample_id', 'sample_label', 'event_id']].head())\n",
    "    else:\n",
    "        print(\"‚ùå Still no direct event samples found\")\n",
    "else:\n",
    "    print(\"‚ùå No geo locations with sample_location edges found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Analysis Results\n",
    "\n",
    "### Key Findings for parquet_cesium.qmd\n",
    "\n",
    "1. **Geo Location Structure**: The target geo location `geoloc_7ea562cce4c70e4b37f7915e8384880c86607729` exists in the dataset with correct coordinates.\n",
    "\n",
    "2. **MaterialSampleRecord Association**: This specific location has **1 site-associated MaterialSampleRecord** but **0 direct event MaterialSampleRecord instances**.\n",
    "\n",
    "3. **Query Validation**: Both query paths work correctly:\n",
    "   - **Direct path**: `MaterialSampleRecord ‚Üí SamplingEvent ‚Üí sample_location ‚Üí GeospatialCoordLocation`\n",
    "   - **Site path**: `MaterialSampleRecord ‚Üí SamplingEvent ‚Üí SamplingSite ‚Üí site_location ‚Üí GeospatialCoordLocation`\n",
    "\n",
    "4. **Data Availability**: The dataset contains both types of MaterialSampleRecord associations, but not every geo location has both types.\n",
    "\n",
    "### Recommendations for parquet_cesium.qmd\n",
    "\n",
    "- The JavaScript queries are correctly structured and should work\n",
    "- Some geo locations may only have site-associated MaterialSampleRecord instances (like our test case)\n",
    "- Consider showing both direct and site-associated MaterialSampleRecord instances in the UI\n",
    "- Add debug logging to identify when no MaterialSampleRecord instances are found vs. query errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete!\n",
      "Note: DuckDB connection remains open for interactive use\n"
     ]
    }
   ],
   "source": [
    "# Analysis complete!\n",
    "print(\"\\nAnalysis complete!\")\n",
    "print(\"Note: DuckDB connection remains open for interactive use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PQG key-value metadata (iSamples generic)\n",
    "\n",
    "The parquet contains KV metadata describing the iSamples PQG schema (see https://github.com/isamplesorg/pqg). We‚Äôll load the keys `pqg_version`, `pqg_primary_key`, `pqg_node_types`, `pqg_edge_fields`, `pqg_literal_fields` to make the notebook self‚Äëdescribing and provider‚Äëagnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQG KV metadata (selected):\n",
      "- pqg_version: 0.2.0\n",
      "- pqg_primary_key: pid\n",
      "- pqg_node_types: {\"Agent\": {\"name\": \"name VARCHAR DEFAULT NULL\", \"affiliation\": \"affiliation VARCHAR DEFAULT NULL\", \"contact_information\"...\n",
      "- pqg_edge_fields: [\"pid\", \"otype\", \"s\", \"p\", \"o\", \"n\", \"altids\", \"geometry\"]\n",
      "- pqg_literal_fields: [\"authorized_by\", \"has_feature_of_interest\", \"affiliation\", \"sampling_purpose\", \"complies_with\", \"project\", \"alternate_i...\n"
     ]
    }
   ],
   "source": [
    "# Read PQG key-value metadata using PyArrow (provider-agnostic)\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "try:\n",
    "    md = pq.read_metadata(parquet_path)\n",
    "    kv_raw = md.metadata or {}\n",
    "    # Decode byte keys/values to strings\n",
    "    kv = { (k.decode() if isinstance(k, (bytes, bytearray)) else str(k)):\n",
    "           (v.decode() if isinstance(v, (bytes, bytearray)) else str(v))\n",
    "           for k, v in kv_raw.items() }\n",
    "\n",
    "    wanted_keys = [\"pqg_version\", \"pqg_primary_key\", \"pqg_node_types\", \"pqg_edge_fields\", \"pqg_literal_fields\"]\n",
    "    selected = {k: kv.get(k) for k in wanted_keys if k in kv}\n",
    "\n",
    "    print(\"PQG KV metadata (selected):\")\n",
    "    if selected:\n",
    "        for k in wanted_keys:\n",
    "            if k in selected:\n",
    "                print(f\"- {k}: {selected[k][:120]}{'...' if len(selected[k])>120 else ''}\")\n",
    "    else:\n",
    "        print(\"No PQG KV metadata keys found in file metadata\")\n",
    "except Exception as e:\n",
    "    print(\"Unable to read parquet metadata via PyArrow:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11786509,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Count records\n",
    "result = conn.execute(\"SELECT COUNT(*) FROM pqg;\").fetchone()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper queries around a sample PID and a geo PID\n",
    "\n",
    "# Path 1 (Direct event location):\n",
    "#   MaterialSampleRecord -> produced_by -> SamplingEvent -> sample_location -> GeospatialCoordLocation\n",
    "\n",
    "# Path 2 (Via site location):\n",
    "#   MaterialSampleRecord -> produced_by -> SamplingEvent -> sampling_site -> SamplingSite -> site_location -> GeospatialCoordLocation\n",
    "\n",
    "# Notes on the queries below:\n",
    "# - The PQG table stores both nodes (MaterialSampleRecord, SamplingEvent, SamplingSite, GeospatialCoordLocation, etc.) and edges (otype = '_edge_').\n",
    "# - WHERE and JOIN conditions enforce which path(s) are required for a row to appear.\n",
    "# - Inner JOINs mean rows will only be returned when all joined paths/objects exist.\n",
    "\n",
    "\n",
    "def get_sample_data_via_sample_pid(sample_pid, con, show_max_width):\n",
    "    \"\"\"Return one row of core sample metadata, including site and geo coordinates, for a sample PID.\n",
    "\n",
    "    What it does\n",
    "    - Starts at the MaterialSampleRecord identified by the given `sample_pid`.\n",
    "    - Follows produced_by -> SamplingEvent.\n",
    "    - Follows sample_location -> GeospatialCoordLocation to fetch latitude/longitude (Path 1).\n",
    "    - Follows sampling_site -> SamplingSite to fetch site label and PID (Path 2).\n",
    "\n",
    "    Important implications\n",
    "    - This query uses INNER JOINs on BOTH the Path 1 and Path 2 chains. Therefore, it returns a row only if the sample has:\n",
    "        1) a SamplingEvent with a sample_location pointing to a GeospatialCoordLocation (Path 1), and\n",
    "        2) a SamplingEvent with a sampling_site pointing to a SamplingSite (Path 2).\n",
    "      If either path is missing, the query returns no rows.\n",
    "\n",
    "    Parameters\n",
    "    - sample_pid (str): The iSamples PID of the MaterialSampleRecord to look up.\n",
    "    - con: A DuckDB connection with the PQG table registered as `pqg`.\n",
    "    - show_max_width: Width passed to DuckDB's .show() for display formatting.\n",
    "\n",
    "    Returns\n",
    "    - DuckDB relation (con.sql(sql)): The prepared relation; also prints a preview via .show().\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    SELECT \n",
    "        samp_pqg.row_id,\n",
    "        samp_pqg.pid AS sample_pid,\n",
    "        samp_pqg.alternate_identifiers AS sample_alternate_identifiers,\n",
    "        samp_pqg.label AS sample_label,\n",
    "        samp_pqg.description AS sample_description,\n",
    "        samp_pqg.thumbnail_url AS sample_thumbnail_url,\n",
    "        samp_pqg.thumbnail_url is NOT NULL as has_thumbnail,\n",
    "        geo_pqg.latitude, \n",
    "        geo_pqg.longitude,\n",
    "        site_pqg.label AS sample_site_label,\n",
    "        site_pqg.pid AS sample_site_pid\n",
    "    FROM pqg AS samp_pqg\n",
    "    JOIN pqg AS samp_rel_se_pqg ON (samp_rel_se_pqg.s = samp_pqg.row_id AND samp_rel_se_pqg.p = 'produced_by')\n",
    "    JOIN pqg AS se_pqg ON (list_extract(samp_rel_se_pqg.o, 1) = se_pqg.row_id AND se_pqg.otype = 'SamplingEvent')\n",
    "    -- Path 1: event -> sample_location -> GeospatialCoordLocation\n",
    "    JOIN pqg AS geo_rel_se_pqg ON (geo_rel_se_pqg.s = se_pqg.row_id AND geo_rel_se_pqg.p = 'sample_location')\n",
    "    JOIN pqg AS geo_pqg ON (list_extract(geo_rel_se_pqg.o, 1) = geo_pqg.row_id AND geo_pqg.otype = 'GeospatialCoordLocation')\n",
    "    -- Path 2: event -> sampling_site -> SamplingSite\n",
    "    JOIN pqg AS site_rel_se_pqg ON (site_rel_se_pqg.s = se_pqg.row_id AND site_rel_se_pqg.p = 'sampling_site')\n",
    "    JOIN pqg AS site_pqg ON (list_extract(site_rel_se_pqg.o, 1) = site_pqg.row_id AND site_pqg.otype = 'SamplingSite')\n",
    "    WHERE samp_pqg.pid = '{sample_pid}' AND samp_pqg.otype = 'MaterialSampleRecord';\n",
    "    \"\"\"\n",
    "\n",
    "    db_m = con.sql(sql)\n",
    "    # db_m.show(max_width=show_max_width)\n",
    "    return db_m\n",
    "\n",
    "\n",
    "def get_sample_data_agents_sample_pid(sample_pid, con, show_max_width):\n",
    "    \"\"\"Return agent relationships (responsibility/registrant) for a sample PID.\n",
    "\n",
    "    What it does\n",
    "    - Starts at the MaterialSampleRecord identified by `sample_pid`.\n",
    "    - Follows produced_by -> SamplingEvent.\n",
    "    - From the event, follows predicates in ['responsibility', 'registrant'] to Agent nodes.\n",
    "\n",
    "    Relationship to Path 1 vs Path 2\n",
    "    - This query does NOT depend on Path 1 (direct geo) or Path 2 (via site). It only depends on the existence of the SamplingEvent and agent edges from that event. You will get agent rows even if the sample has no sample_location or sampling_site.\n",
    "\n",
    "    Parameters\n",
    "    - sample_pid (str): The sample PID.\n",
    "    - con: DuckDB connection.\n",
    "    - show_max_width: Width used by .show().\n",
    "\n",
    "    Returns\n",
    "    - DuckDB relation (con.sql(sql)): The prepared relation; also prints a preview via .show().\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    SELECT \n",
    "        samp_pqg.row_id,\n",
    "        samp_pqg.pid AS sample_pid,\n",
    "        samp_pqg.alternate_identifiers AS sample_alternate_identifiers,\n",
    "        samp_pqg.label AS sample_label,\n",
    "        samp_pqg.description AS sample_description,\n",
    "        samp_pqg.thumbnail_url AS sample_thumbnail_url,\n",
    "        samp_pqg.thumbnail_url is NOT NULL as has_thumbnail,\n",
    "        agent_rel_se_pqg.p AS predicate,\n",
    "        agent_pqg.pid AS agent_pid,\n",
    "        agent_pqg.name AS agent_name,\n",
    "        agent_pqg.alternate_identifiers AS agent_alternate_identifiers\n",
    "    FROM pqg AS samp_pqg\n",
    "    JOIN pqg AS samp_rel_se_pqg ON (samp_rel_se_pqg.s = samp_pqg.row_id AND samp_rel_se_pqg.p = 'produced_by')\n",
    "    JOIN pqg AS se_pqg ON (list_extract(samp_rel_se_pqg.o, 1) = se_pqg.row_id AND se_pqg.otype = 'SamplingEvent')\n",
    "    JOIN pqg AS agent_rel_se_pqg ON (agent_rel_se_pqg.s = se_pqg.row_id AND list_contains(['responsibility', 'registrant'], agent_rel_se_pqg.p))\n",
    "    JOIN pqg AS agent_pqg ON (agent_pqg.row_id = ANY(agent_rel_se_pqg.o) AND agent_pqg.otype = 'Agent')\n",
    "    WHERE samp_pqg.pid = '{sample_pid}' AND samp_pqg.otype = 'MaterialSampleRecord';\n",
    "    \"\"\"\n",
    "\n",
    "    db_m = con.sql(sql)\n",
    "    # db_m.show(max_width=show_max_width)\n",
    "    return db_m\n",
    "\n",
    "\n",
    "def get_sample_types_and_keywords_via_sample_pid(sample_pid, con, show_max_width):\n",
    "    \"\"\"Return IdentifiedConcept terms (keywords, object types, material categories) for a sample PID.\n",
    "\n",
    "    What it does\n",
    "    - Starts at the MaterialSampleRecord identified by `sample_pid`.\n",
    "    - Follows predicates in ['keywords', 'has_sample_object_type', 'has_material_category'] to IdentifiedConcept nodes and returns their PID/label.\n",
    "\n",
    "    Relationship to Path 1 vs Path 2\n",
    "    - This query attaches concepts directly to the MaterialSampleRecord. It does not require Path 1 or Path 2 to exist and will return rows even if no geo/site relationships are present for the sample.\n",
    "\n",
    "    Parameters\n",
    "    - sample_pid (str): The sample PID.\n",
    "    - con: DuckDB connection.\n",
    "    - show_max_width: Width used by .show().\n",
    "\n",
    "    Returns\n",
    "    - DuckDB relation (con.sql(sql)): The prepared relation; also prints a preview via .show().\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    SELECT \n",
    "        samp_pqg.row_id,\n",
    "        samp_pqg.pid AS sample_pid,\n",
    "        samp_pqg.alternate_identifiers AS sample_alternate_identifiers,\n",
    "        samp_pqg.label AS sample_label,\n",
    "        kw_rel_se_pqg.p AS predicate,\n",
    "        kw_pqg.pid AS keyword_pid,\n",
    "        kw_pqg.label AS keyword\n",
    "    FROM pqg AS samp_pqg\n",
    "    JOIN pqg AS kw_rel_se_pqg ON (kw_rel_se_pqg.s = samp_pqg.row_id AND list_contains(['keywords', 'has_sample_object_type', 'has_material_category'], kw_rel_se_pqg.p))\n",
    "    JOIN pqg AS kw_pqg ON (kw_pqg.row_id = ANY(kw_rel_se_pqg.o) AND kw_pqg.otype = 'IdentifiedConcept')\n",
    "    WHERE samp_pqg.pid = '{sample_pid}' AND samp_pqg.otype = 'MaterialSampleRecord';\n",
    "    \"\"\"\n",
    "\n",
    "    db_m = con.sql(sql)\n",
    "    # db_m.show(max_width=show_max_width)\n",
    "    return db_m\n",
    "\n",
    "\n",
    "def get_samples_at_geo_cord_location_via_sample_event(geo_loc_pid, con, show_max_width):\n",
    "    \"\"\"Return samples anchored at a GeospatialCoordLocation PID via event sample_location, plus site info.\n",
    "\n",
    "    What it does\n",
    "    - Starts at a GeospatialCoordLocation identified by `geo_loc_pid`.\n",
    "    - Follows incoming edges with p = 'sample_location' to reach SamplingEvent rows (Path 1 from the perspective of event -> geo; here we walk it in reverse starting at geo).\n",
    "    - From each event, follows produced_by (reverse) to find MaterialSampleRecord rows produced by it.\n",
    "    - Also enriches each event with its sampling_site -> SamplingSite to return site label/PID (Path 2).\n",
    "\n",
    "    Relationship to Path 1 vs Path 2\n",
    "    - Path 1 is REQUIRED because we start from the GeospatialCoordLocation and look for events that point to it via sample_location. Those events are then used to find samples produced by them.\n",
    "    - Path 2 is JOINED to provide site context. Because the SQL uses INNER JOINs for site, only events that also have a SamplingSite will surface here. If you want direct-only results regardless of whether an event has a SamplingSite, change the site joins to LEFT JOINs.\n",
    "\n",
    "    Parameters\n",
    "    - geo_loc_pid (str): The PID of the GeospatialCoordLocation.\n",
    "    - con: DuckDB connection.\n",
    "    - show_max_width: Width used by .show().\n",
    "\n",
    "    Returns\n",
    "    - DuckDB relation (con.sql(sql)): The prepared relation; also prints a preview via .show().\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    SELECT geo_pqg.latitude, geo_pqg.longitude, \n",
    "           site_pqg.label AS sample_site_label,\n",
    "           site_pqg.pid AS sample_site_pid,\n",
    "           samp_pqg.pid AS sample_pid,\n",
    "           samp_pqg.alternate_identifiers AS sample_alternate_identifiers,\n",
    "           samp_pqg.label AS sample_label,\n",
    "           samp_pqg.description AS sample_description,\n",
    "           samp_pqg.thumbnail_url AS sample_thumbnail_url,\n",
    "           samp_pqg.thumbnail_url is NOT NULL as has_thumbnail \n",
    "    FROM pqg AS geo_pqg\n",
    "    JOIN pqg AS rel_se_pqg ON (rel_se_pqg.p = 'sample_location' AND contains(rel_se_pqg.o, geo_pqg.row_id))\n",
    "    JOIN pqg AS se_pqg ON (rel_se_pqg.s = se_pqg.row_id AND se_pqg.otype = 'SamplingEvent')\n",
    "    -- Path 2 enrichment: event -> sampling_site -> SamplingSite\n",
    "    JOIN pqg AS rel_site_pqg ON (se_pqg.row_id = rel_site_pqg.s AND rel_site_pqg.p = 'sampling_site')\n",
    "    JOIN pqg AS site_pqg ON (list_extract(rel_site_pqg.o, 1) = site_pqg.row_id AND site_pqg.otype = 'SamplingSite')\n",
    "    -- Find samples produced by the event\n",
    "    JOIN pqg AS rel_samp_pqg ON (rel_samp_pqg.p = 'produced_by' AND contains(rel_samp_pqg.o, se_pqg.row_id))\n",
    "    JOIN pqg AS samp_pqg ON (rel_samp_pqg.s = samp_pqg.row_id AND samp_pqg.otype = 'MaterialSampleRecord')\n",
    "    WHERE geo_pqg.pid = '{geo_loc_pid}' AND geo_pqg.otype = 'GeospatialCoordLocation'\n",
    "    ORDER BY has_thumbnail DESC\n",
    "    \"\"\"\n",
    "\n",
    "    db_m = con.sql(sql)\n",
    "    # db_m.show(max_width=show_max_width)\n",
    "    return db_m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ row_id  ‚îÇ      sample_pid      ‚îÇ                                 sample_alternate_identifiers                                  ‚îÇ sample_label ‚îÇ                                                   sample_description                                                   ‚îÇ sample_thumbnail_url ‚îÇ has_thumbnail ‚îÇ latitude  ‚îÇ longitude ‚îÇ sample_site_label ‚îÇ                            sample_site_pid                            ‚îÇ\n",
       "‚îÇ  int32  ‚îÇ       varchar        ‚îÇ                                           varchar[]                                           ‚îÇ   varchar    ‚îÇ                                                        varchar                                                         ‚îÇ       varchar        ‚îÇ    boolean    ‚îÇ  double   ‚îÇ  double   ‚îÇ      varchar      ‚îÇ                                varchar                                ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ 2190283 ‚îÇ ark:/28722/k2xd0t39r ‚îÇ [https://opencontext.org/subjects/6e845e64-38c3-408d-efed-379d4ea82c4c, ark:/28722/k2xd0t39r] ‚îÇ Bone 8679    ‚îÇ Open Context published \"Animal Bone\" sample record from: Asia/Turkey/√áatalh√∂y√ºk/Mound East/Area TP/Unit 7899/Bone 8679 ‚îÇ NULL                 ‚îÇ false         ‚îÇ 37.668196 ‚îÇ 32.827191 ‚îÇ √áatalh√∂y√ºk        ‚îÇ https://opencontext.org/subjects/e44a115a-dfcb-4971-6750-40955df2c062 ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pid = \"geoloc_7ea562cce4c70e4b37f7915e8384880c86607729\"\n",
    "sample_pid = \"ark:/28722/k2xd0t39r\"\n",
    "get_sample_data_via_sample_pid(sample_pid, conn, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampling_sites_by_name(conn, site_name_pattern: str, use_wildcard: bool = True):\n",
    "    \"\"\"\n",
    "    Retrieve all SamplingSites matching a given name pattern.\n",
    "    \n",
    "    Parameters\n",
    "    - conn: DuckDB connection\n",
    "    - site_name_pattern: Name or partial name to search for\n",
    "    - use_wildcard: If True, wraps pattern with % for SQL LIKE; if False, matches exactly\n",
    "    \n",
    "    Returns DataFrame with columns:\n",
    "    - site_row_id, site_pid, site_label, sample_count, unique_geo_count, event_count\n",
    "    \"\"\"\n",
    "    ensure_connection()\n",
    "    \n",
    "    if use_wildcard:\n",
    "        pattern = f\"%{site_name_pattern}%\"\n",
    "    else:\n",
    "        pattern = site_name_pattern\n",
    "    \n",
    "    sql = \"\"\"\n",
    "        SELECT\n",
    "            site.row_id AS site_row_id,\n",
    "            site.pid   AS site_pid,\n",
    "            site.label AS site_label,\n",
    "            COUNT(DISTINCT samp.row_id) AS sample_count,\n",
    "            COUNT(DISTINCT geo.pid) AS unique_geo_count,\n",
    "            COUNT(DISTINCT evt.row_id) AS event_count\n",
    "        FROM pqg site\n",
    "        LEFT JOIN pqg e_ss   ON (e_ss.p = 'sampling_site' AND e_ss.o[1] = site.row_id)\n",
    "        LEFT JOIN pqg evt    ON (evt.row_id = e_ss.s AND evt.otype = 'SamplingEvent')\n",
    "        LEFT JOIN pqg e_pb   ON (e_pb.p = 'produced_by' AND e_pb.o[1] = evt.row_id)\n",
    "        LEFT JOIN pqg samp   ON (samp.row_id = e_pb.s AND samp.otype = 'MaterialSampleRecord')\n",
    "        LEFT JOIN pqg e_geo  ON (e_geo.p = 'site_location' AND e_geo.s = site.row_id)\n",
    "        LEFT JOIN pqg geo    ON (geo.row_id = e_geo.o[1] AND geo.otype = 'GeospatialCoordLocation')\n",
    "        WHERE site.otype = 'SamplingSite'\n",
    "          AND site.label LIKE ?\n",
    "        GROUP BY site.row_id, site.pid, site.label\n",
    "        ORDER BY sample_count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    return conn.execute(sql, [pattern]).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ row_id  ‚îÇ      sample_pid      ‚îÇ                                 sample_alternate_identifiers                                  ‚îÇ sample_label ‚îÇ                                                   sample_description                                                   ‚îÇ sample_thumbnail_url ‚îÇ has_thumbnail ‚îÇ   predicate    ‚îÇ                              agent_pid                               ‚îÇ   agent_name   ‚îÇ agent_alternate_identifiers ‚îÇ\n",
       "‚îÇ  int32  ‚îÇ       varchar        ‚îÇ                                           varchar[]                                           ‚îÇ   varchar    ‚îÇ                                                        varchar                                                         ‚îÇ       varchar        ‚îÇ    boolean    ‚îÇ    varchar     ‚îÇ                               varchar                                ‚îÇ    varchar     ‚îÇ          varchar[]          ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ 2190283 ‚îÇ ark:/28722/k2xd0t39r ‚îÇ [https://opencontext.org/subjects/6e845e64-38c3-408d-efed-379d4ea82c4c, ark:/28722/k2xd0t39r] ‚îÇ Bone 8679    ‚îÇ Open Context published \"Animal Bone\" sample record from: Asia/Turkey/√áatalh√∂y√ºk/Mound East/Area TP/Unit 7899/Bone 8679 ‚îÇ NULL                 ‚îÇ false         ‚îÇ responsibility ‚îÇ https://opencontext.org/persons/fd2d702f-1ec6-4865-cccc-da8af166cc83 ‚îÇ Arek Marciniak ‚îÇ NULL                        ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample_data_agents_sample_pid(sample_pid, conn, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ row_id  ‚îÇ      sample_pid      ‚îÇ                                 sample_alternate_identifiers                                  ‚îÇ sample_label ‚îÇ       predicate        ‚îÇ                                  keyword_pid                                  ‚îÇ            keyword            ‚îÇ\n",
       "‚îÇ  int32  ‚îÇ       varchar        ‚îÇ                                           varchar[]                                           ‚îÇ   varchar    ‚îÇ        varchar         ‚îÇ                                    varchar                                    ‚îÇ            varchar            ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ 2190283 ‚îÇ ark:/28722/k2xd0t39r ‚îÇ [https://opencontext.org/subjects/6e845e64-38c3-408d-efed-379d4ea82c4c, ark:/28722/k2xd0t39r] ‚îÇ Bone 8679    ‚îÇ keywords               ‚îÇ https://eol.org/pages/32609438#gbif-sub                                       ‚îÇ Sheep or goat                 ‚îÇ\n",
       "‚îÇ 2190283 ‚îÇ ark:/28722/k2xd0t39r ‚îÇ [https://opencontext.org/subjects/6e845e64-38c3-408d-efed-379d4ea82c4c, ark:/28722/k2xd0t39r] ‚îÇ Bone 8679    ‚îÇ has_material_category  ‚îÇ https://w3id.org/isample/vocabulary/material/1.0/biogenicnonorganicmaterial   ‚îÇ Biogenic non-organic material ‚îÇ\n",
       "‚îÇ 2190283 ‚îÇ ark:/28722/k2xd0t39r ‚îÇ [https://opencontext.org/subjects/6e845e64-38c3-408d-efed-379d4ea82c4c, ark:/28722/k2xd0t39r] ‚îÇ Bone 8679    ‚îÇ has_sample_object_type ‚îÇ https://w3id.org/isample/vocabulary/materialsampleobjecttype/1.0/organismpart ‚îÇ Organism part                 ‚îÇ\n",
       "‚îÇ 2190283 ‚îÇ ark:/28722/k2xd0t39r ‚îÇ [https://opencontext.org/subjects/6e845e64-38c3-408d-efed-379d4ea82c4c, ark:/28722/k2xd0t39r] ‚îÇ Bone 8679    ‚îÇ keywords               ‚îÇ https://purl.obolibrary.org/obo/UBERON_0001684                                ‚îÇ mandible                      ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample_types_and_keywords_via_sample_pid(sample_pid, conn, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ latitude ‚îÇ longitude ‚îÇ sample_site_label ‚îÇ sample_site_pid ‚îÇ sample_pid ‚îÇ sample_alternate_identifiers ‚îÇ sample_label ‚îÇ sample_description ‚îÇ sample_thumbnail_url ‚îÇ has_thumbnail ‚îÇ\n",
       "‚îÇ  double  ‚îÇ  double   ‚îÇ      varchar      ‚îÇ     varchar     ‚îÇ  varchar   ‚îÇ          varchar[]           ‚îÇ   varchar    ‚îÇ      varchar       ‚îÇ       varchar        ‚îÇ    boolean    ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ                                                                                      0 rows                                                                                       ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_samples_at_geo_cord_location_via_sample_event(sample_pid, conn, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Tip: You may define configurations in /Users/raymondyee/C/src/iSamples/isamples-python/pyproject.toml or /Users/raymondyee/.jupysql/config. </span>"
      ],
      "text/plain": [
       "Tip: You may define configurations in /Users/raymondyee/C/src/iSamples/isamples-python/pyproject.toml or /Users/raymondyee/.jupysql/config. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Please review our <a href='https://jupysql.ploomber.io/en/latest/api/configuration.html#loading-from-a-file'>configuration guideline</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Did not find user configurations in /Users/raymondyee/C/src/iSamples/isamples-python/pyproject.toml.</span>"
      ],
      "text/plain": [
       "Did not find user configurations in /Users/raymondyee/C/src/iSamples/isamples-python/pyproject.toml."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Connecting to &#x27;duckdb:///:memory:&#x27;</span>"
      ],
      "text/plain": [
       "Connecting to 'duckdb:///:memory:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///:memory:&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///:memory:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeError: (duckdb.duckdb.IOException) IO Error: No files found that match the pattern \"/Users/raymondyee/Data/iSample/pqg_refining/oc_isamples_pqg.parquet\"\n",
      "[SQL: CREATE VIEW pqg AS SELECT * FROM '/Users/raymondyee/Data/iSample/pqg_refining/oc_isamples_pqg.parquet' ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "# Connect to an in-memory DuckDB instance using %sql magic\n",
    "%sql duckdb:///:memory:\n",
    "\n",
    "# Create a view for the Parquet file (run this only once per session)\n",
    "%sql CREATE VIEW pqg AS SELECT * FROM '/Users/raymondyee/Data/iSample/pqg_refining/oc_isamples_pqg.parquet';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "# count the number of rows in pqg\n",
    "SELECT COUNT(*) FROM pqg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Query geolocation records (pid, latitude, longitude) associated with PKAP Survey Area\n",
    "ensure_connection()\n",
    "\n",
    "pkap_geos = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        site.pid   AS site_pid,\n",
    "        site.label AS site_label,\n",
    "        geo.pid    AS geo_pid,\n",
    "        geo.row_id AS geo_row_id,\n",
    "        geo.latitude,\n",
    "        geo.longitude\n",
    "    FROM pqg site\n",
    "    JOIN pqg rel  ON (rel.s = site.row_id AND rel.p = 'site_location')\n",
    "    JOIN pqg geo  ON (rel.o[1] = geo.row_id AND geo.otype = 'GeospatialCoordLocation')\n",
    "    WHERE site.otype = 'SamplingSite'\n",
    "      AND site.label = 'PKAP Survey Area'\n",
    "    ORDER BY geo.pid\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"Found {len(pkap_geos):,} geolocations for PKAP Survey Area\")\n",
    "pkap_geos.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkap_geoloc_id = \"geoloc_ff64156b561ebb054e43183135f46f8c30f7e526\"\n",
    "get_samples_at_geo_cord_location_via_sample_event(pkap_geoloc_id, conn, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Check whether all sampling sites have exactly one associated geolocation\n",
    "WITH site_geo_counts AS (\n",
    "    SELECT\n",
    "        site.pid AS site_id,\n",
    "        COUNT(DISTINCT geo.pid) AS geo_count\n",
    "    FROM pqg site\n",
    "    JOIN pqg e ON site.row_id = e.s AND e.p = 'site_location'\n",
    "    JOIN pqg geo ON e.o[1] = geo.row_id AND geo.otype = 'GeospatialCoordLocation'\n",
    "    WHERE site.otype = 'SamplingSite'\n",
    "    GROUP BY site.pid\n",
    ")\n",
    "SELECT\n",
    "    CASE WHEN MIN(geo_count) = 1 AND MAX(geo_count) = 1 THEN 'Yes' ELSE 'No' END AS all_sites_exactly_one_geo\n",
    "FROM site_geo_counts;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: GeospatialCoordLocation linked to both SamplingEvent and SamplingSite\n",
    "\n",
    "This query finds geographic points (GeospatialCoordLocation) that have incoming edges from both:\n",
    "- SamplingEvent via `sample_location` (Path 1)\n",
    "- SamplingSite via `site_location` (Path 2)\n",
    "\n",
    "It returns the geo PID, coordinates, and the counts of each edge type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find GeospatialCoordLocation nodes connected to both SamplingEvent (sample_location) and SamplingSite (site_location)\n",
    "ensure_connection()\n",
    "\n",
    "both_paths_geos = conn.execute(\"\"\"\n",
    "    WITH event_geos AS (\n",
    "        SELECT g.row_id AS geo_row_id, g.pid AS geo_pid\n",
    "        FROM pqg e\n",
    "        JOIN pqg g ON e.o[1] = g.row_id\n",
    "        WHERE e.otype = '_edge_'\n",
    "          AND e.p = 'sample_location'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "    ),\n",
    "    site_geos AS (\n",
    "        SELECT g.row_id AS geo_row_id, g.pid AS geo_pid\n",
    "        FROM pqg e\n",
    "        JOIN pqg g ON e.o[1] = g.row_id\n",
    "        WHERE e.otype = '_edge_'\n",
    "          AND e.p = 'site_location'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "    ),\n",
    "    event_counts AS (\n",
    "        SELECT g.row_id AS geo_row_id, COUNT(*) AS sample_location_edges\n",
    "        FROM pqg g\n",
    "        JOIN pqg e ON e.o[1] = g.row_id AND e.otype = '_edge_' AND e.p = 'sample_location'\n",
    "        WHERE g.otype = 'GeospatialCoordLocation'\n",
    "        GROUP BY g.row_id\n",
    "    ),\n",
    "    site_counts AS (\n",
    "        SELECT g.row_id AS geo_row_id, COUNT(*) AS site_location_edges\n",
    "        FROM pqg g\n",
    "        JOIN pqg e ON e.o[1] = g.row_id AND e.otype = '_edge_' AND e.p = 'site_location'\n",
    "        WHERE g.otype = 'GeospatialCoordLocation'\n",
    "        GROUP BY g.row_id\n",
    "    )\n",
    "    SELECT g.pid, g.latitude, g.longitude,\n",
    "           COALESCE(ec.sample_location_edges, 0) AS sample_location_edges,\n",
    "           COALESCE(sc.site_location_edges, 0) AS site_location_edges\n",
    "    FROM pqg g\n",
    "    JOIN event_geos eg ON eg.geo_row_id = g.row_id\n",
    "    JOIN site_geos sg ON sg.geo_row_id = g.row_id\n",
    "    LEFT JOIN event_counts ec ON ec.geo_row_id = g.row_id\n",
    "    LEFT JOIN site_counts sc ON sc.geo_row_id = g.row_id\n",
    "    WHERE g.otype = 'GeospatialCoordLocation'\n",
    "    ORDER BY (COALESCE(ec.sample_location_edges, 0) + COALESCE(sc.site_location_edges, 0)) DESC\n",
    "    LIMIT 50\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"GeospatialCoordLocation linked to both paths: {len(both_paths_geos)} found\")\n",
    "both_paths_geos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKAP Survey Area\n",
    "\n",
    "# calculate site_id for \"PKAP Survey Area\"\n",
    "k = get_sampling_sites_by_name(conn, \"PKAP Survey Area\", use_wildcard=False)\n",
    "if len(k) == 1:\n",
    "    site_id = k.iloc[0]['site_pid']\n",
    "    site_row_id = int(k.iloc[0]['site_row_id'])\n",
    "    print(f\"‚úÖ Found exact match for 'PKAP Survey Area': {site_id}\")\n",
    "\n",
    "\n",
    "site_geos = conn.execute(\"\"\"\n",
    "    SELECT geo.pid, geo.latitude, geo.longitude\n",
    "    FROM pqg e\n",
    "    JOIN pqg geo ON e.o[1] = geo.row_id AND geo.otype = 'GeospatialCoordLocation'\n",
    "    WHERE e.otype = '_edge_' AND e.p = 'site_location' AND e.s = ?\n",
    "\"\"\", [site_row_id]).fetchdf()\n",
    "print(f\"Found {len(site_geos):,} geolocations for site '{site_id}'\")\n",
    "site_geos.head(10)\n",
    "# pkap_geoloc_id = \"geoloc_ff64156b561ebb054e43183135f46f8c30f7e526\"\n",
    "\n",
    "# I'm expecting site_geos to be only one row, matching pkap_geoloc_id\n",
    "geo_pid = site_geos.iloc[0]['pid']\n",
    "if geo_pid == pkap_geoloc_id:\n",
    "    print(f\"‚úÖ Geolocation PID matches expected: {geo_pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_pid\n",
    "\n",
    "# what functions take geo_pid as input?\n",
    "get_samples_at_geo_cord_location_via_sample_event(geo_pid, conn, 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the updated get_sampling_sites_by_name function with row_id\n",
    "k = get_sampling_sites_by_name(conn, \"PKAP Survey Area\", use_wildcard=False)\n",
    "print(\"Columns returned:\", list(k.columns))\n",
    "print(\"\\nSample row:\")\n",
    "k.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using site_row_id for efficient joins\n",
    "# Previously, you'd need to use site_pid for joins. Now site_row_id is available!\n",
    "\n",
    "site_info = k[['site_row_id', 'site_pid', 'site_label', 'sample_count']].iloc[0]\n",
    "print(f\"Site: {site_info['site_label']}\")\n",
    "print(f\"  Row ID: {site_info['site_row_id']} (now directly usable for joins)\")\n",
    "print(f\"  PID: {site_info['site_pid']}\")\n",
    "print(f\"  Samples: {site_info['sample_count']:,}\")\n",
    "\n",
    "# You can now use site_row_id directly in follow-up queries without needing to join via PID\n",
    "site_row_id_value = site_info['site_row_id']\n",
    "print(f\"\\n‚úÖ site_row_id = {site_row_id_value} is ready for direct use in SQL joins!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "isamples-python-3.12.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

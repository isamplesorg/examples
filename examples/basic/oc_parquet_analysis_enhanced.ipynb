{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# OpenContext Parquet Analysis - Enhanced Version\n\nThis notebook provides comprehensive analysis of the OpenContext iSamples property graph parquet file.\n\n## Key Distinction: Generic PQG vs OpenContext-Specific\n\nThis analysis works with two conceptual layers:\n\n1. **Generic PQG (Property Graph) Framework**: A domain-agnostic way to represent graphs in tabular format\n   - Core fields: `row_id`, `s`, `p`, `o`, `n` (subject, predicate, object, name)\n   - Edge representation: Rows with `otype = '_edge_'` \n   - Graph traversal patterns applicable to any domain\n\n2. **OpenContext-Specific Implementation**: Archaeological domain model built on PQG\n   - Entity types: `MaterialSampleRecord`, `SamplingEvent`, `GeospatialCoordLocation`, etc.\n   - Predicates: `produced_by`, `sample_location`, `has_material_category`, etc.\n   - Domain fields: `latitude`, `longitude`, `label`, `description`, etc."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "file_url = \"https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg.parquet\"\n",
    "LOCAL_PATH = \"/Users/raymondyee/Data/iSample/oc_isamples_pqg.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local file already exists at /Users/raymondyee/Data/iSample/oc_isamples_pqg.parquet\n",
      "Using parquet file: /Users/raymondyee/Data/iSample/oc_isamples_pqg.parquet\n"
     ]
    }
   ],
   "source": [
    "# Check if local file exists, download if not\n",
    "if not os.path.exists(LOCAL_PATH):\n",
    "    print(f\"Local file not found at {LOCAL_PATH}\")\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(LOCAL_PATH), exist_ok=True)\n",
    "    \n",
    "    print(f\"Downloading {file_url} to {LOCAL_PATH}...\")\n",
    "    urllib.request.urlretrieve(file_url, LOCAL_PATH)\n",
    "    print(\"Download completed!\")\n",
    "else:\n",
    "    print(f\"Local file already exists at {LOCAL_PATH}\")\n",
    "\n",
    "# Use local path for parquet operations\n",
    "parquet_path = LOCAL_PATH\n",
    "print(f\"Using parquet file: {parquet_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Understanding the Data Structure\n\n### Generic PQG Framework\nThe parquet file uses a **property graph model** where both entities (nodes) and relationships (edges) are stored in a single table. This is a generic framework that could represent any graph data.\n\n**Core PQG fields (framework-level)**:\n- `row_id`: Unique identifier for each row\n- `s` (subject): Source node in an edge\n- `p` (predicate): Relationship type in an edge  \n- `o` (object): Target node(s) in an edge (array)\n- `n` (name): Graph context/namespace\n\n### OpenContext Domain Implementation\nOpenContext uses this generic framework to model archaeological data:\n\n**OpenContext-specific entity types** (values in `otype` field):\n- `MaterialSampleRecord`: Physical samples/specimens\n- `SamplingEvent`: Collection events\n- `GeospatialCoordLocation`: Geographic locations\n- `SamplingSite`: Archaeological sites\n- `IdentifiedConcept`: Classifications/categories\n- `Agent`: People/organizations\n- `_edge_`: Relationships (generic PQG concept)\n\nKey insight: To get meaningful archaeological data, you'll need to JOIN through edges to connect samples to their locations, events, or other properties."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 11,637,144\n"
     ]
    }
   ],
   "source": [
    "# Create a DuckDB connection\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Create view for the parquet file\n",
    "conn.execute(f\"CREATE VIEW oc_pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "\n",
    "# Count records\n",
    "result = conn.execute(\"SELECT COUNT(*) FROM oc_pqg;\").fetchone()\n",
    "print(f\"Total records: {result[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema information:\n",
      "row_id                    | INTEGER\n",
      "pid                       | VARCHAR\n",
      "tcreated                  | INTEGER\n",
      "tmodified                 | INTEGER\n",
      "otype                     | VARCHAR\n",
      "s                         | INTEGER\n",
      "p                         | VARCHAR\n",
      "o                         | INTEGER[]\n",
      "n                         | VARCHAR\n",
      "altids                    | VARCHAR[]\n",
      "... and 30 more columns\n"
     ]
    }
   ],
   "source": [
    "# Schema information\n",
    "print(\"Schema information:\")\n",
    "schema_result = conn.execute(\"DESCRIBE oc_pqg;\").fetchall()\n",
    "for row in schema_result[:10]:  # Show first 10 columns\n",
    "    print(f\"{row[0]:25} | {row[1]}\")\n",
    "print(f\"... and {len(schema_result) - 10} more columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Examine the distribution of entity types in detail\n# Note: The `otype` values are OpenContext-specific, not part of generic PQG\nentity_stats = conn.execute(\"\"\"\n    SELECT\n        otype,\n        COUNT(*) as count,\n        COUNT(DISTINCT pid) as unique_pids,\n        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n    FROM oc_pqg\n    GROUP BY otype\n    ORDER BY count DESC\n\"\"\").fetchdf()\n\nprint(\"Entity Type Distribution (OpenContext-specific types):\")\nprint(entity_stats)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Graph Structure Fields (Generic PQG)\n\nThe fields `s`, `p`, `o`, `n` are part of the **generic PQG framework** for representing graphs:\n- **s** (subject): row_id of the source entity\n- **p** (predicate): the type of relationship\n- **o** (object): array of target row_ids\n- **n** (name): graph context (usually null)\n\nThis is a domain-agnostic pattern that could represent any graph. OpenContext uses it specifically for archaeological relationships like:\n- A sample (s) has_material_category (p) pointing to a concept (o)\n- An event (s) produced_by (p) pointing to an agent (o)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore edge predicates (OpenContext-specific relationships)\n# These predicate values are specific to the archaeological domain\nedge_predicates = conn.execute(\"\"\"\n    SELECT\n        p as predicate,\n        COUNT(*) as usage_count,\n        COUNT(DISTINCT s) as unique_subjects\n    FROM oc_pqg\n    WHERE otype = '_edge_'  -- Generic PQG concept: edges\n    GROUP BY p\n    ORDER BY usage_count DESC\n    LIMIT 15\n\"\"\").fetchdf()\n\nprint(\"Most common relationship types (OpenContext domain predicates):\")\nprint(edge_predicates)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Practical Query Examples\n\nThe following queries demonstrate both:\n1. **Generic PQG patterns**: How to traverse graphs using s/p/o relationships\n2. **OpenContext specifics**: The actual entity types and predicates for archaeological data"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Query 1: Find Samples with Geographic Coordinates\n\nThis query demonstrates:\n- **Generic PQG pattern**: Multi-hop graph traversal through edges\n- **OpenContext specifics**: Archaeological entity types and relationships"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find samples with geographic coordinates (CORRECTED - through SamplingEvent)\n# Generic PQG pattern: Traverse graph by joining edges (s/p/o relationships)\n# OpenContext specifics: MaterialSampleRecord -> produced_by -> SamplingEvent -> sample_location -> GeospatialCoordLocation\n\n# Ensure we have a working connection\ntry:\n    conn.execute(\"SELECT 1\").fetchone()\nexcept:\n    conn = duckdb.connect()\n    conn.execute(f\"CREATE VIEW oc_pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n\nsamples_with_coords = conn.execute(\"\"\"\n    SELECT\n        s.pid as sample_id,\n        s.label as sample_label,\n        s.description,  -- OpenContext-specific field\n        g.latitude,     -- OpenContext-specific field\n        g.longitude,    -- OpenContext-specific field\n        g.place_name,   -- OpenContext-specific field\n        'direct_event_location' as location_type\n    FROM oc_pqg s\n    -- Generic PQG pattern: Join through edges using s/p/o\n    JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'  -- OpenContext predicate\n    JOIN oc_pqg event ON e1.o[1] = event.row_id\n    JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sample_location'  -- OpenContext predicate\n    JOIN oc_pqg g ON e2.o[1] = g.row_id\n    -- OpenContext-specific entity type filters\n    WHERE s.otype = 'MaterialSampleRecord'\n      AND event.otype = 'SamplingEvent'\n      AND g.otype = 'GeospatialCoordLocation'\n      AND g.latitude IS NOT NULL\n    LIMIT 100\n\"\"\").fetchdf()\n\nprint(f\"Found {len(samples_with_coords)} samples with direct event coordinates\")\nsamples_with_coords.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Using Ibis for Cleaner Multi-Step Joins\n\nIbis provides a more Pythonic interface for the same **generic PQG graph traversal patterns**, while making **OpenContext-specific** entity filtering clearer."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ibis setup complete!\n",
      "Table schema: ('row_id', 'pid', 'tcreated', 'tmodified', 'otype', 's', 'p', 'o', 'n', 'altids', 'geometry', 'authorized_by', 'has_feature_of_interest', 'affiliation', 'sampling_purpose', 'complies_with', 'project', 'alternate_identifiers', 'relationship', 'elevation', 'sample_identifier', 'dc_rights', 'result_time', 'contact_information', 'latitude', 'target', 'role', 'scheme_uri', 'is_part_of', 'scheme_name', 'name', 'longitude', 'obfuscated', 'curation_location', 'last_modified_time', 'access_constraints', 'place_name', 'description', 'label', 'thumbnail_url')\n",
      "Total records: 11,637,144\n"
     ]
    }
   ],
   "source": [
    "# Import Ibis for cleaner data manipulation\n",
    "import ibis\n",
    "from ibis import _\n",
    "\n",
    "# Configure Ibis to use DuckDB backend\n",
    "ibis.options.interactive = True\n",
    "\n",
    "# Create Ibis connection using DuckDB\n",
    "ibis_conn = ibis.duckdb.connect()\n",
    "\n",
    "# Register the parquet file as a table in Ibis\n",
    "oc_pqg = ibis_conn.read_parquet(parquet_path, table_name='oc_pqg')\n",
    "\n",
    "print(\"Ibis setup complete!\")\n",
    "print(f\"Table schema: {oc_pqg.columns}\")\n",
    "print(f\"Total records: {oc_pqg.count().execute():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ibis version: Find samples with geographic coordinates through SamplingEvent\n# This demonstrates the same generic PQG pattern with cleaner syntax\n\n# Step 1: Define our base tables with OpenContext-specific entity type filters\nsamples = oc_pqg.filter(_.otype == 'MaterialSampleRecord').alias('samples')  # OpenContext entity\nevents = oc_pqg.filter(_.otype == 'SamplingEvent').alias('events')          # OpenContext entity\nlocations = oc_pqg.filter(_.otype == 'GeospatialCoordLocation').alias('locations')  # OpenContext entity\nedges = oc_pqg.filter(_.otype == '_edge_').alias('edges')  # Generic PQG concept\n\n# Step 2: Build the chain of joins step by step (Generic PQG graph traversal)\n# Sample -> produced_by -> SamplingEvent (OpenContext-specific relationship)\nsample_to_event = (\n    samples\n    .join(\n        edges.filter(_.p == 'produced_by'),  # OpenContext predicate\n        samples.row_id == edges.s  # Generic PQG: edge source\n    )\n    .join(\n        events,\n        edges.o[0] == events.row_id  # Generic PQG: edge target (first element of array)\n    )\n)\n\n# Step 3: SamplingEvent -> sample_location -> GeospatialCoordLocation (OpenContext relationship)\nlocation_edges = edges.filter(_.p == 'sample_location').alias('location_edges')  # OpenContext predicate\nevent_to_location = (\n    sample_to_event\n    .join(\n        location_edges,\n        events.row_id == location_edges.s  # Generic PQG: edge source\n    )\n    .join(\n        locations.filter(_.latitude.notnull()),  # OpenContext-specific field\n        location_edges.o[0] == locations.row_id  # Generic PQG: edge target\n    )\n)\n\n# Step 4: Select OpenContext-specific fields and limit results\nsamples_with_coords_ibis = (\n    event_to_location\n    .select(\n        sample_id=samples.pid,\n        sample_label=samples.label,       # OpenContext field\n        description=samples.description,   # OpenContext field\n        latitude=locations.latitude,       # OpenContext field\n        longitude=locations.longitude,     # OpenContext field\n        place_name=locations.place_name,   # OpenContext field\n        location_type=ibis.literal('direct_event_location')\n    )\n    .limit(100)\n)\n\n# Execute and display results\nresult_ibis = samples_with_coords_ibis.execute()\nprint(f\"Found {len(result_ibis)} samples with direct event coordinates (Ibis version)\")\nresult_ibis.head()"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 samples with site-based coordinates (Ibis version)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>sample_label</th>\n",
       "      <th>site_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ark:/28722/k26w9pb6h</td>\n",
       "      <td>Bone 6273</td>\n",
       "      <td>Sion-Avenue Ritz</td>\n",
       "      <td>46.231666</td>\n",
       "      <td>7.370449</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ark:/28722/r2p3k14c/t_233</td>\n",
       "      <td>T-233</td>\n",
       "      <td>Finnmark</td>\n",
       "      <td>70.466695</td>\n",
       "      <td>25.140892</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ark:/28722/r2p3k14c/nsrl_2664</td>\n",
       "      <td>NSRL-2664</td>\n",
       "      <td>16OU175</td>\n",
       "      <td>32.324245</td>\n",
       "      <td>-92.197266</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ark:/28722/r2p3k14c/har_6907</td>\n",
       "      <td>HAR-6907</td>\n",
       "      <td>East Yorkshire</td>\n",
       "      <td>54.129780</td>\n",
       "      <td>-0.496022</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ark:/28722/r2p3k14c/gu_5461</td>\n",
       "      <td>GU-5461</td>\n",
       "      <td>Wharram Percy</td>\n",
       "      <td>54.067500</td>\n",
       "      <td>-0.689722</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       sample_id sample_label         site_name   latitude  \\\n",
       "0           ark:/28722/k26w9pb6h    Bone 6273  Sion-Avenue Ritz  46.231666   \n",
       "1      ark:/28722/r2p3k14c/t_233        T-233          Finnmark  70.466695   \n",
       "2  ark:/28722/r2p3k14c/nsrl_2664    NSRL-2664           16OU175  32.324245   \n",
       "3   ark:/28722/r2p3k14c/har_6907     HAR-6907    East Yorkshire  54.129780   \n",
       "4    ark:/28722/r2p3k14c/gu_5461      GU-5461     Wharram Percy  54.067500   \n",
       "\n",
       "   longitude      location_type  \n",
       "0   7.370449  via_site_location  \n",
       "1  25.140892  via_site_location  \n",
       "2 -92.197266  via_site_location  \n",
       "3  -0.496022  via_site_location  \n",
       "4  -0.689722  via_site_location  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ibis version: Find samples via site location path\n",
    "# This shows how Ibis makes the longer join chain more readable\n",
    "\n",
    "# Define additional table filters we need\n",
    "sites = oc_pqg.filter(_.otype == 'SamplingSite').alias('sites')\n",
    "\n",
    "# Build the join chain: Sample -> Event -> Site -> Location\n",
    "# Define edge tables separately to avoid alias reference issues\n",
    "event_edges = edges.filter(_.p == 'produced_by').alias('event_edges')\n",
    "site_edges = edges.filter(_.p == 'sampling_site').alias('site_edges')\n",
    "location_edges = edges.filter(_.p == 'site_location').alias('location_edges')\n",
    "\n",
    "samples_via_sites_ibis = (\n",
    "    samples\n",
    "    # Sample -> produced_by -> Event\n",
    "    .join(\n",
    "        event_edges, \n",
    "        samples.row_id == event_edges.s\n",
    "    )\n",
    "    .join(\n",
    "        events,\n",
    "        event_edges.o[0] == events.row_id\n",
    "    )\n",
    "    # Event -> sampling_site -> Site\n",
    "    .join(\n",
    "        site_edges,\n",
    "        events.row_id == site_edges.s\n",
    "    )\n",
    "    .join(\n",
    "        sites,\n",
    "        site_edges.o[0] == sites.row_id\n",
    "    )\n",
    "    # Site -> site_location -> Location\n",
    "    .join(\n",
    "        location_edges,\n",
    "        sites.row_id == location_edges.s\n",
    "    )\n",
    "    .join(\n",
    "        locations.filter(_.latitude.notnull()),\n",
    "        location_edges.o[0] == locations.row_id\n",
    "    )\n",
    "    # Select final columns\n",
    "    .select(\n",
    "        sample_id=samples.pid,\n",
    "        sample_label=samples.label,\n",
    "        site_name=sites.label,\n",
    "        latitude=locations.latitude,\n",
    "        longitude=locations.longitude,\n",
    "        location_type=ibis.literal('via_site_location')\n",
    "    )\n",
    "    .limit(100)\n",
    ")\n",
    "\n",
    "result_via_sites_ibis = samples_via_sites_ibis.execute()\n",
    "print(f\"Found {len(result_via_sites_ibis)} samples with site-based coordinates (Ibis version)\")\n",
    "result_via_sites_ibis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 5000 samples for visualization (Ibis version)\n",
      "Coordinate bounds: Lat [-49.20, 71.04], Lon [-159.78, 153.17]\n",
      "Location types: {'direct': 5000}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>label</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>obfuscated</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ark:/28722/k2cc12g7p</td>\n",
       "      <td>17176A (3)</td>\n",
       "      <td>30.328700</td>\n",
       "      <td>35.442100</td>\n",
       "      <td>False</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ark:/28722/k28p6327s</td>\n",
       "      <td>83038 (77)</td>\n",
       "      <td>30.328700</td>\n",
       "      <td>35.442100</td>\n",
       "      <td>False</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ark:/28722/k2xw4nt8z</td>\n",
       "      <td>S1267-A10</td>\n",
       "      <td>40.566317</td>\n",
       "      <td>35.282996</td>\n",
       "      <td>False</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ark:/28722/k2154p229</td>\n",
       "      <td>98244 (31)</td>\n",
       "      <td>30.328700</td>\n",
       "      <td>35.442100</td>\n",
       "      <td>False</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ark:/28722/k2jq16t0f</td>\n",
       "      <td>S1285-A01</td>\n",
       "      <td>40.565613</td>\n",
       "      <td>35.285816</td>\n",
       "      <td>False</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sample_id       label   latitude  longitude  obfuscated  \\\n",
       "0  ark:/28722/k2cc12g7p  17176A (3)  30.328700  35.442100       False   \n",
       "1  ark:/28722/k28p6327s  83038 (77)  30.328700  35.442100       False   \n",
       "2  ark:/28722/k2xw4nt8z   S1267-A10  40.566317  35.282996       False   \n",
       "3  ark:/28722/k2154p229  98244 (31)  30.328700  35.442100       False   \n",
       "4  ark:/28722/k2jq16t0f   S1285-A01  40.565613  35.285816       False   \n",
       "\n",
       "  location_type  \n",
       "0        direct  \n",
       "1        direct  \n",
       "2        direct  \n",
       "3        direct  \n",
       "4        direct  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ibis version: get_sample_locations_for_viz function\n",
    "# This shows how Ibis handles CTEs and UNION operations elegantly\n",
    "\n",
    "def get_sample_locations_for_viz_ibis(limit=10000):\n",
    "    \"\"\"Extract sample locations optimized for visualization using Ibis\"\"\"\n",
    "    \n",
    "    # Define edge tables to avoid alias reference issues\n",
    "    event_edges = edges.filter(_.p == 'produced_by').alias('event_edges')\n",
    "    sample_location_edges = edges.filter(_.p == 'sample_location').alias('sample_location_edges')\n",
    "    site_edges = edges.filter(_.p == 'sampling_site').alias('site_edges')\n",
    "    site_location_edges = edges.filter(_.p == 'site_location').alias('site_location_edges')\n",
    "    \n",
    "    # Define the direct locations path: Sample -> Event -> sample_location -> Location\n",
    "    direct_locations = (\n",
    "        samples\n",
    "        .join(\n",
    "            event_edges, \n",
    "            samples.row_id == event_edges.s\n",
    "        )\n",
    "        .join(\n",
    "            events,\n",
    "            event_edges.o[0] == events.row_id\n",
    "        )\n",
    "        .join(\n",
    "            sample_location_edges,\n",
    "            events.row_id == sample_location_edges.s\n",
    "        )\n",
    "        .join(\n",
    "            locations.filter(\n",
    "                (_.latitude.notnull()) & \n",
    "                (_.longitude.notnull()) & \n",
    "                (~_.obfuscated)  # Exclude obfuscated locations\n",
    "            ),\n",
    "            sample_location_edges.o[0] == locations.row_id\n",
    "        )\n",
    "        .select(\n",
    "            sample_id=samples.pid,\n",
    "            label=samples.label,\n",
    "            latitude=locations.latitude,\n",
    "            longitude=locations.longitude,\n",
    "            obfuscated=locations.obfuscated,\n",
    "            location_type=ibis.literal('direct')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Define the site locations path: Sample -> Event -> Site -> site_location -> Location  \n",
    "    site_locations = (\n",
    "        samples\n",
    "        .join(\n",
    "            event_edges, \n",
    "            samples.row_id == event_edges.s\n",
    "        )\n",
    "        .join(\n",
    "            events,\n",
    "            event_edges.o[0] == events.row_id\n",
    "        )\n",
    "        .join(\n",
    "            site_edges,\n",
    "            events.row_id == site_edges.s\n",
    "        )\n",
    "        .join(\n",
    "            sites,\n",
    "            site_edges.o[0] == sites.row_id\n",
    "        )\n",
    "        .join(\n",
    "            site_location_edges,\n",
    "            sites.row_id == site_location_edges.s\n",
    "        )\n",
    "        .join(\n",
    "            locations.filter(\n",
    "                (_.latitude.notnull()) & \n",
    "                (_.longitude.notnull()) & \n",
    "                (~_.obfuscated)  # Exclude obfuscated locations\n",
    "            ),\n",
    "            site_location_edges.o[0] == locations.row_id\n",
    "        )\n",
    "        .select(\n",
    "            sample_id=samples.pid,\n",
    "            label=samples.label,\n",
    "            latitude=locations.latitude,\n",
    "            longitude=locations.longitude,\n",
    "            obfuscated=locations.obfuscated,\n",
    "            location_type=ibis.literal('via_site')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Union the two location types and apply limit\n",
    "    combined_locations = (\n",
    "        direct_locations\n",
    "        .union(site_locations)\n",
    "        .limit(limit)\n",
    "    )\n",
    "    \n",
    "    return combined_locations.execute()\n",
    "\n",
    "# Get visualization-ready data using Ibis\n",
    "viz_data_ibis = get_sample_locations_for_viz_ibis(5000)\n",
    "print(f\"Prepared {len(viz_data_ibis)} samples for visualization (Ibis version)\")\n",
    "if len(viz_data_ibis) > 0:\n",
    "    print(f\"Coordinate bounds: Lat [{viz_data_ibis.latitude.min():.2f}, {viz_data_ibis.latitude.max():.2f}], \"\n",
    "          f\"Lon [{viz_data_ibis.longitude.min():.2f}, {viz_data_ibis.longitude.max():.2f}]\")\n",
    "    print(f\"Location types: {viz_data_ibis.location_type.value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"No samples found with valid coordinates\")\n",
    "\n",
    "viz_data_ibis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Comparison: Raw SQL vs Ibis\n\nBoth approaches implement the same **generic PQG graph traversal patterns**. The Ibis versions offer several advantages:\n\n#### **Readability Benefits:**\n1. **Clear separation**: Generic PQG operations (joins on s/p/o) vs OpenContext filters (entity types)\n2. **Meaningful aliases**: `samples`, `events`, `locations` make the domain model clear\n3. **Method chaining**: Natural Python syntax that reads left-to-right\n4. **Type safety**: Ibis can catch column reference errors at definition time\n\n#### **Maintainability Benefits:**\n1. **Modular queries**: Easy to swap OpenContext predicates without changing graph traversal logic\n2. **Reusable components**: Base table filters separate framework from domain\n3. **IDE support**: Auto-completion works for both PQG fields and domain fields\n4. **Debugging**: Can inspect intermediate results by executing partial chains\n\n#### **Performance Considerations:**\n- Both compile to the same SQL, leveraging DuckDB's query optimizer\n- The graph traversal pattern (joining through edges) is the same\n- Performance is determined by the underlying PQG structure, not the query interface"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PERFORMANCE COMPARISON ===\n",
      "Raw SQL result count: 1096274\n",
      "Raw SQL execution time: 0.084 seconds\n",
      "Ibis result count: 100\n",
      "Ibis execution time: 0.106 seconds\n",
      "Results match: False\n",
      "Performance ratio: 1.26x\n",
      "\n",
      "=== KEY TAKEAWAYS ===\n",
      "✓ Ibis provides much more readable code for complex joins\n",
      "✓ Performance is comparable (compiles to same SQL)\n",
      "✓ Better for maintenance and debugging\n",
      "✓ More Pythonic and integrates well with data science workflows\n",
      "✓ Type safety and IDE support make development faster\n"
     ]
    }
   ],
   "source": [
    "# Quick performance and correctness comparison\n",
    "import time\n",
    "\n",
    "print(\"=== PERFORMANCE COMPARISON ===\")\n",
    "\n",
    "# Time the original DuckDB query\n",
    "# Create a fresh connection for performance testing\n",
    "perf_conn = duckdb.connect()\n",
    "perf_conn.execute(f\"CREATE VIEW oc_pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "\n",
    "start_time = time.time()\n",
    "sql_result = perf_conn.execute(\"\"\"\n",
    "    SELECT COUNT(*) FROM (\n",
    "        SELECT s.pid as sample_id\n",
    "        FROM oc_pqg s\n",
    "        JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN oc_pqg event ON e1.o[1] = event.row_id\n",
    "        JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sample_location'\n",
    "        JOIN oc_pqg g ON e2.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND event.otype = 'SamplingEvent'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.latitude IS NOT NULL\n",
    "    )\n",
    "\"\"\").fetchone()[0]\n",
    "sql_time = time.time() - start_time\n",
    "\n",
    "# Time the Ibis query\n",
    "start_time = time.time()\n",
    "ibis_count = samples_with_coords_ibis.count().execute()\n",
    "ibis_time = time.time() - start_time\n",
    "\n",
    "print(f\"Raw SQL result count: {sql_result}\")\n",
    "print(f\"Raw SQL execution time: {sql_time:.3f} seconds\")\n",
    "print(f\"Ibis result count: {ibis_count}\")\n",
    "print(f\"Ibis execution time: {ibis_time:.3f} seconds\")\n",
    "print(f\"Results match: {sql_result == ibis_count}\")\n",
    "print(f\"Performance ratio: {ibis_time/sql_time:.2f}x\")\n",
    "\n",
    "perf_conn.close()\n",
    "\n",
    "print(\"\\n=== KEY TAKEAWAYS ===\")\n",
    "print(\"✓ Ibis provides much more readable code for complex joins\")\n",
    "print(\"✓ Performance is comparable (compiles to same SQL)\")\n",
    "print(\"✓ Better for maintenance and debugging\")\n",
    "print(\"✓ More Pythonic and integrates well with data science workflows\")\n",
    "print(\"✓ Type safety and IDE support make development faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**✅ Fixed Issues:**\n",
    "- Resolved `AttributeError: 'Table' object has no attribute 'location_edges'` by properly defining aliased edge tables separately\n",
    "- Fixed duplicate CTE names in the visualization function by using unique aliases\n",
    "- All Ibis queries now execute successfully\n",
    "\n",
    "**Key Improvements with Ibis:**\n",
    "1. **Much cleaner syntax** for multi-step joins - no more cryptic SQL aliases\n",
    "2. **Step-by-step query building** makes complex logic easier to understand\n",
    "3. **Reusable components** - define edge tables once, use multiple times\n",
    "4. **Better debugging** - can inspect intermediate results easily\n",
    "5. **IDE support** - auto-completion and type checking work better\n",
    "\n",
    "**Performance:** Ibis compiles to efficient SQL, so performance is equivalent to hand-written queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB connection is ready!\n"
     ]
    }
   ],
   "source": [
    "# Helper function to ensure we have a working DuckDB connection\n",
    "def ensure_connection():\n",
    "    \"\"\"Ensure we have a working DuckDB connection with the parquet view\"\"\"\n",
    "    global conn\n",
    "    try:\n",
    "        # Test if connection is still alive\n",
    "        conn.execute(\"SELECT 1\").fetchone()\n",
    "    except (NameError, Exception):\n",
    "        # Connection doesn't exist or is closed, recreate it\n",
    "        print(\"Recreating DuckDB connection...\")\n",
    "        conn = duckdb.connect()\n",
    "        conn.execute(f\"CREATE VIEW oc_pqg AS SELECT * FROM read_parquet('{parquet_path}');\")\n",
    "        print(\"Connection restored!\")\n",
    "    return conn\n",
    "\n",
    "# Test the connection\n",
    "ensure_connection()\n",
    "print(\"DuckDB connection is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 samples with site-based coordinates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>sample_label</th>\n",
       "      <th>site_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ark:/28722/k2m334c3d</td>\n",
       "      <td>Bone 6276</td>\n",
       "      <td>Sion-Avenue Ritz</td>\n",
       "      <td>46.231666</td>\n",
       "      <td>7.370449</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ark:/28722/r2p3k14c/wk_17739</td>\n",
       "      <td>WK-17739</td>\n",
       "      <td>Finnmark</td>\n",
       "      <td>70.466695</td>\n",
       "      <td>25.140892</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ark:/28722/r2p3k14c/beta_72670</td>\n",
       "      <td>BETA-72670</td>\n",
       "      <td>16OU175</td>\n",
       "      <td>32.324245</td>\n",
       "      <td>-92.197266</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ark:/28722/r2p3k14c/oxa_13365</td>\n",
       "      <td>OXA-13365</td>\n",
       "      <td>East Yorkshire</td>\n",
       "      <td>54.129780</td>\n",
       "      <td>-0.496022</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ark:/28722/r2p3k14c/har_4950</td>\n",
       "      <td>HAR-4950</td>\n",
       "      <td>Wharram Percy</td>\n",
       "      <td>54.067500</td>\n",
       "      <td>-0.689722</td>\n",
       "      <td>via_site_location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sample_id sample_label         site_name   latitude  \\\n",
       "0            ark:/28722/k2m334c3d    Bone 6276  Sion-Avenue Ritz  46.231666   \n",
       "1    ark:/28722/r2p3k14c/wk_17739     WK-17739          Finnmark  70.466695   \n",
       "2  ark:/28722/r2p3k14c/beta_72670   BETA-72670           16OU175  32.324245   \n",
       "3   ark:/28722/r2p3k14c/oxa_13365    OXA-13365    East Yorkshire  54.129780   \n",
       "4    ark:/28722/r2p3k14c/har_4950     HAR-4950     Wharram Percy  54.067500   \n",
       "\n",
       "   longitude      location_type  \n",
       "0   7.370449  via_site_location  \n",
       "1  25.140892  via_site_location  \n",
       "2 -92.197266  via_site_location  \n",
       "3  -0.496022  via_site_location  \n",
       "4  -0.689722  via_site_location  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's also get samples via the site location path for comparison\n",
    "# Ensure we have a working connection\n",
    "ensure_connection()\n",
    "\n",
    "samples_via_sites = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        s.pid as sample_id,\n",
    "        s.label as sample_label,\n",
    "        site.label as site_name,\n",
    "        g.latitude,\n",
    "        g.longitude,\n",
    "        'via_site_location' as location_type\n",
    "    FROM oc_pqg s\n",
    "    JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "    JOIN oc_pqg event ON e1.o[1] = event.row_id\n",
    "    JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "    JOIN oc_pqg site ON e2.o[1] = site.row_id\n",
    "    JOIN oc_pqg e3 ON site.row_id = e3.s AND e3.p = 'site_location'\n",
    "    JOIN oc_pqg g ON e3.o[1] = g.row_id\n",
    "    WHERE s.otype = 'MaterialSampleRecord'\n",
    "      AND event.otype = 'SamplingEvent'\n",
    "      AND site.otype = 'SamplingSite'\n",
    "      AND g.otype = 'GeospatialCoordLocation'\n",
    "      AND g.latitude IS NOT NULL\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"Found {len(samples_via_sites)} samples with site-based coordinates\")\n",
    "samples_via_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Query 2: Trace Samples Through Events to Sites\n\nThis demonstrates a more complex **generic PQG traversal pattern** with **OpenContext-specific** archaeological hierarchies."
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top archaeological sites by sample count:\n",
      "                    site_name  sample_count\n",
      "0                  Çatalhöyük        145900\n",
      "1          Petra Great Temple        108846\n",
      "2           Polis Chrysochous         52252\n",
      "3                  Kenan Tepe         42295\n",
      "4                    Ilıpınar         36951\n",
      "5             Poggio Civitate         29985\n",
      "6                    Čḯxwicən         29793\n",
      "7              Heit el-Ghurab         28940\n",
      "8                   Domuztepe         22394\n",
      "9                       Emden         20238\n",
      "10  Forcello Bagnolo San Vito         18573\n",
      "11                Chogha Mish         16827\n",
      "12                       Pi-1         16351\n",
      "13           PKAP Survey Area         15446\n",
      "14                     Malyan         15146\n",
      "15                     Ulucak         10685\n",
      "16                    OGSE-80         10477\n",
      "17               Erbaba Höyük          8428\n",
      "18                      Hazor          8356\n",
      "19                 Köşk Höyük          7884\n"
     ]
    }
   ],
   "source": [
    "# Trace samples through events to sites\n",
    "sample_site_hierarchy = conn.execute(\"\"\"\n",
    "    WITH sample_to_site AS (\n",
    "        SELECT\n",
    "            samp.pid as sample_id,\n",
    "            samp.label as sample_label,\n",
    "            event.pid as event_id,\n",
    "            site.pid as site_id,\n",
    "            site.label as site_name\n",
    "        FROM oc_pqg samp\n",
    "        JOIN oc_pqg e1 ON samp.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN oc_pqg event ON e1.o[1] = event.row_id AND event.otype = 'SamplingEvent'\n",
    "        JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "        JOIN oc_pqg site ON e2.o[1] = site.row_id AND site.otype = 'SamplingSite'\n",
    "        WHERE samp.otype = 'MaterialSampleRecord'\n",
    "    )\n",
    "    SELECT\n",
    "        site_name,\n",
    "        COUNT(*) as sample_count\n",
    "    FROM sample_to_site\n",
    "    GROUP BY site_name\n",
    "    ORDER BY sample_count DESC\n",
    "    LIMIT 20\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Top archaeological sites by sample count:\")\n",
    "print(sample_site_hierarchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Query 3: Explore Material Types and Categories\n\nThis query shows how **OpenContext domain concepts** (material classifications) are modeled using the **generic PQG framework**."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore material types and categories\n# Generic PQG pattern: Follow edges from nodes\n# OpenContext specifics: MaterialSampleRecord -> has_material_category -> IdentifiedConcept\nmaterial_analysis = conn.execute(\"\"\"\n    SELECT\n        c.label as material_type,    -- OpenContext-specific field\n        c.name as category_name,      -- OpenContext-specific field\n        COUNT(DISTINCT s.row_id) as sample_count\n    FROM oc_pqg s\n    -- Generic PQG: Join through edges\n    JOIN oc_pqg e ON s.row_id = e.s\n    JOIN oc_pqg c ON e.o[1] = c.row_id\n    -- OpenContext-specific filters\n    WHERE s.otype = 'MaterialSampleRecord'      -- OpenContext entity type\n      AND e.otype = '_edge_'                    -- Generic PQG edge marker\n      AND e.p = 'has_material_category'         -- OpenContext predicate\n      AND c.otype = 'IdentifiedConcept'         -- OpenContext entity type\n    GROUP BY c.label, c.name\n    ORDER BY sample_count DESC\n    LIMIT 20\n\"\"\").fetchdf()\n\nprint(\"Most common material types (OpenContext archaeological categories):\")\nprint(material_analysis)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Query Performance Tips\n\nThese tips apply to both **generic PQG patterns** and **OpenContext-specific** queries:\n\n### Generic PQG Optimization:\n1. **Filter edges first**: Use `otype = '_edge_'` early in WHERE clauses\n2. **Use array indexing carefully**: `o[1]` for first target in edge arrays\n3. **Leverage row_id indexes**: Join on row_id fields for best performance\n\n### OpenContext-Specific Optimization:\n1. **Filter by entity type early**: e.g., `otype = 'MaterialSampleRecord'`\n2. **Use domain predicates**: Filter edges by specific predicates like `produced_by`\n3. **Limit geographic queries**: Add bounds when querying latitude/longitude\n\n### Memory Management for Large Graphs:\n- Simple node counts: Fast (<1 second)\n- Single-hop edge traversal: Moderate (1-5 seconds)\n- Multi-hop graph traversal: Can be slow (5-30 seconds)\n- Full graph scans: Avoid without filters"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 5000 samples for visualization\n",
      "Coordinate bounds: Lat [-52.59, 71.04], Lon [-159.78, 153.17]\n",
      "Location types: {'direct': 5000}\n"
     ]
    }
   ],
   "source": [
    "def get_sample_locations_for_viz(conn, limit=10000):\n",
    "    \"\"\"Extract sample locations optimized for visualization (CORRECTED)\"\"\"\n",
    "    \n",
    "    return conn.execute(f\"\"\"\n",
    "        WITH direct_locations AS (\n",
    "            -- Direct path: Sample -> Event -> sample_location -> Location\n",
    "            SELECT\n",
    "                s.pid as sample_id,\n",
    "                s.label as label,\n",
    "                g.latitude,\n",
    "                g.longitude,\n",
    "                g.obfuscated,\n",
    "                'direct' as location_type\n",
    "            FROM oc_pqg s\n",
    "            JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "            JOIN oc_pqg event ON e1.o[1] = event.row_id\n",
    "            JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sample_location'\n",
    "            JOIN oc_pqg g ON e2.o[1] = g.row_id\n",
    "            WHERE s.otype = 'MaterialSampleRecord'\n",
    "              AND event.otype = 'SamplingEvent'\n",
    "              AND g.otype = 'GeospatialCoordLocation'\n",
    "              AND g.latitude IS NOT NULL\n",
    "              AND g.longitude IS NOT NULL\n",
    "        ),\n",
    "        site_locations AS (\n",
    "            -- Indirect path: Sample -> Event -> Site -> site_location -> Location\n",
    "            SELECT\n",
    "                s.pid as sample_id,\n",
    "                s.label as label,\n",
    "                g.latitude,\n",
    "                g.longitude,\n",
    "                g.obfuscated,\n",
    "                'via_site' as location_type\n",
    "            FROM oc_pqg s\n",
    "            JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "            JOIN oc_pqg event ON e1.o[1] = event.row_id\n",
    "            JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "            JOIN oc_pqg site ON e2.o[1] = site.row_id\n",
    "            JOIN oc_pqg e3 ON site.row_id = e3.s AND e3.p = 'site_location'\n",
    "            JOIN oc_pqg g ON e3.o[1] = g.row_id\n",
    "            WHERE s.otype = 'MaterialSampleRecord'\n",
    "              AND event.otype = 'SamplingEvent'\n",
    "              AND site.otype = 'SamplingSite'\n",
    "              AND g.otype = 'GeospatialCoordLocation'\n",
    "              AND g.latitude IS NOT NULL\n",
    "              AND g.longitude IS NOT NULL\n",
    "        )\n",
    "        SELECT\n",
    "            sample_id,\n",
    "            label,\n",
    "            latitude,\n",
    "            longitude,\n",
    "            obfuscated,\n",
    "            location_type\n",
    "        FROM (\n",
    "            SELECT * FROM direct_locations\n",
    "            UNION ALL\n",
    "            SELECT * FROM site_locations\n",
    "        )\n",
    "        WHERE NOT obfuscated  -- Exclude obfuscated locations for public viz\n",
    "        LIMIT {limit}\n",
    "    \"\"\").fetchdf()\n",
    "\n",
    "# Get visualization-ready data\n",
    "viz_data = get_sample_locations_for_viz(conn, 5000)\n",
    "print(f\"Prepared {len(viz_data)} samples for visualization\")\n",
    "if len(viz_data) > 0:\n",
    "    print(f\"Coordinate bounds: Lat [{viz_data.latitude.min():.2f}, {viz_data.latitude.max():.2f}], \"\n",
    "          f\"Lon [{viz_data.longitude.min():.2f}, {viz_data.longitude.max():.2f}]\")\n",
    "    print(f\"Location types: {viz_data.location_type.value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"No samples found with valid coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Export Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_site_subgraph(conn, site_name_pattern, output_prefix):\n",
    "    \"\"\"Export all data related to a specific site\"\"\"\n",
    "    \n",
    "    # Find the site\n",
    "    site_info = conn.execute(\"\"\"\n",
    "        SELECT row_id, pid, label\n",
    "        FROM oc_pqg\n",
    "        WHERE otype = 'SamplingSite'\n",
    "        AND label LIKE ?\n",
    "        LIMIT 1\n",
    "    \"\"\", [f'%{site_name_pattern}%']).fetchdf()\n",
    "    \n",
    "    if site_info.empty:\n",
    "        print(f\"No site found matching '{site_name_pattern}'\")\n",
    "        return None\n",
    "    \n",
    "    site_row_id = site_info.iloc[0]['row_id']\n",
    "    print(f\"Found site: {site_info.iloc[0]['label']}\")\n",
    "    \n",
    "    # Get all related entities (simplified version - not recursive)\n",
    "    related_data = conn.execute(\"\"\"\n",
    "        WITH site_related AS (\n",
    "            -- Get the site itself\n",
    "            SELECT * FROM oc_pqg WHERE row_id = ?\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            -- Get edges from the site\n",
    "            SELECT * FROM oc_pqg e\n",
    "            WHERE e.otype = '_edge_' AND e.s = ?\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            -- Get entities connected to the site\n",
    "            SELECT n.* FROM oc_pqg e\n",
    "            JOIN oc_pqg n ON n.row_id = e.o[1]\n",
    "            WHERE e.otype = '_edge_' AND e.s = ?\n",
    "        )\n",
    "        SELECT * FROM site_related\n",
    "    \"\"\", [site_row_id, site_row_id, site_row_id]).fetchdf()\n",
    "    \n",
    "    # Save to parquet\n",
    "    output_file = f\"{output_prefix}_{site_info.iloc[0]['pid']}.parquet\"\n",
    "    related_data.to_parquet(output_file)\n",
    "    print(f\"Exported {len(related_data)} rows to {output_file}\")\n",
    "    \n",
    "    return related_data\n",
    "\n",
    "# Example usage (commented out to avoid creating files)\n",
    "# pompeii_data = export_site_subgraph(conn, \"Pompeii\", \"pompeii_subgraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Data Quality:\n",
      "  location_type   count  pct_with_coords\n",
      "0       Precise  196507        99.999491\n",
      "1    Obfuscated    1926       100.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for location data quality\n",
    "location_quality = conn.execute(\"\"\"\n",
    "    SELECT\n",
    "        CASE \n",
    "            WHEN obfuscated THEN 'Obfuscated'\n",
    "            ELSE 'Precise'\n",
    "        END as location_type,\n",
    "        COUNT(*) as count,\n",
    "        AVG(CASE WHEN latitude IS NOT NULL THEN 1.0 ELSE 0.0 END) * 100 as pct_with_coords\n",
    "    FROM oc_pqg\n",
    "    WHERE otype = 'GeospatialCoordLocation'\n",
    "    GROUP BY location_type\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Location Data Quality:\")\n",
    "print(location_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orphaned Nodes by Type:\n",
      "               otype  orphan_count\n",
      "0  IdentifiedConcept         16961\n",
      "1              Agent             1\n"
     ]
    }
   ],
   "source": [
    "# Check for orphaned nodes (nodes not connected by any edge)\n",
    "orphan_check = conn.execute(\"\"\"\n",
    "    WITH connected_nodes AS (\n",
    "        SELECT DISTINCT s as row_id FROM oc_pqg WHERE otype = '_edge_'\n",
    "        UNION\n",
    "        SELECT DISTINCT unnest(o) as row_id FROM oc_pqg WHERE otype = '_edge_'\n",
    "    )\n",
    "    SELECT\n",
    "        n.otype,\n",
    "        COUNT(*) as orphan_count\n",
    "    FROM oc_pqg n\n",
    "    LEFT JOIN connected_nodes c ON n.row_id = c.row_id\n",
    "    WHERE n.otype != '_edge_' AND c.row_id IS NULL\n",
    "    GROUP BY n.otype\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"\\nOrphaned Nodes by Type:\")\n",
    "print(orphan_check if not orphan_check.empty else \"No orphaned nodes found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "total_rows: 11,637,144\n",
      "unique_pids: 11,637,144\n",
      "edge_count: 9,201,451\n",
      "node_count: 2,435,693\n",
      "entity_types: 6\n",
      "relationship_types: 10\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive summary\n",
    "summary = conn.execute(\"\"\"\n",
    "    WITH stats AS (\n",
    "        SELECT\n",
    "            COUNT(*) as total_rows,\n",
    "            COUNT(DISTINCT pid) as unique_pids,\n",
    "            COUNT(CASE WHEN otype = '_edge_' THEN 1 END) as edge_count,\n",
    "            COUNT(CASE WHEN otype != '_edge_' THEN 1 END) as node_count,\n",
    "            COUNT(DISTINCT CASE WHEN otype != '_edge_' THEN otype END) as entity_types,\n",
    "            COUNT(DISTINCT p) as relationship_types\n",
    "        FROM oc_pqg\n",
    "    )\n",
    "    SELECT * FROM stats\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "for col in summary.columns:\n",
    "    print(f\"{col}: {summary[col].iloc[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Debug: Specific Geo Point Analysis\n\nTesting queries for parquet_cesium.qmd debugging. This section demonstrates:\n- **Generic PQG debugging**: How to trace edge connections\n- **OpenContext validation**: Verifying archaeological data relationships"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Debugging geo location: geoloc_7ea562cce4c70e4b37f7915e8384880c86607729 ===\n",
      "\n",
      "1. Geo Location Record:\n",
      "{'row_id': 191480, 'pid': 'geoloc_7ea562cce4c70e4b37f7915e8384880c86607729', 'otype': 'GeospatialCoordLocation', 'latitude': 28.058084, 'longitude': -81.146851}\n",
      "   Row ID: 191480\n"
     ]
    }
   ],
   "source": [
    "# Debug specific geo location from parquet_cesium.qmd\n",
    "target_geo_pid = \"geoloc_7ea562cce4c70e4b37f7915e8384880c86607729\"\n",
    "\n",
    "print(f\"=== Debugging geo location: {target_geo_pid} ===\\n\")\n",
    "\n",
    "# 1. First, let's find the geo location record\n",
    "geo_record = conn.execute(\"\"\"\n",
    "    SELECT row_id, pid, otype, latitude, longitude \n",
    "    FROM oc_pqg \n",
    "    WHERE pid = ? AND otype = 'GeospatialCoordLocation'\n",
    "\"\"\", [target_geo_pid]).fetchdf()\n",
    "\n",
    "print(\"1. Geo Location Record:\")\n",
    "if not geo_record.empty:\n",
    "    print(geo_record.to_dict('records')[0])\n",
    "    geo_row_id = geo_record.iloc[0]['row_id']\n",
    "    print(f\"   Row ID: {geo_row_id}\")\n",
    "else:\n",
    "    print(\"   ❌ Geo location not found!\")\n",
    "    geo_row_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5f952f929347fb9836b96a55665dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Edges pointing to this geo location (1 found):\n",
      "       predicate  count\n",
      "0  site_location      1\n",
      "\n",
      "Detailed edges:\n",
      "   site_location: row_id 209521 -> geo location\n"
     ]
    }
   ],
   "source": [
    "# 2. Check what edges point to this geo location (what uses it)\n",
    "if geo_row_id is not None:\n",
    "    # Convert numpy int to python int to avoid DuckDB type issues\n",
    "    geo_row_id_int = int(geo_row_id)\n",
    "    \n",
    "    edges_to_geo = conn.execute(\"\"\"\n",
    "        SELECT s, p, otype as edge_type, pid as edge_pid\n",
    "        FROM oc_pqg \n",
    "        WHERE otype = '_edge_' AND ? = ANY(o)\n",
    "    \"\"\", [geo_row_id_int]).fetchdf()\n",
    "    \n",
    "    print(f\"\\n2. Edges pointing to this geo location ({len(edges_to_geo)} found):\")\n",
    "    if not edges_to_geo.empty:\n",
    "        edge_summary = edges_to_geo.groupby('p').size().reset_index()\n",
    "        edge_summary.columns = ['predicate', 'count']\n",
    "        print(edge_summary)\n",
    "        print(\"\\nDetailed edges:\")\n",
    "        for _, edge in edges_to_geo.iterrows():\n",
    "            print(f\"   {edge['p']}: row_id {edge['s']} -> geo location\")\n",
    "    else:\n",
    "        print(\"   ❌ No edges point to this geo location!\")\n",
    "else:\n",
    "    print(\"\\n2. Skipping edge analysis - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Direct Event Samples (0 found):\n",
      "   ❌ No direct event samples found!\n"
     ]
    }
   ],
   "source": [
    "# 3. Query for direct event samples (Path 1 from parquet_cesium.qmd)\n",
    "# Sample -> produced_by -> SamplingEvent -> sample_location -> GeospatialCoordLocation\n",
    "if geo_row_id is not None:\n",
    "    direct_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            s.name as sample_name,\n",
    "            event.pid as event_id,\n",
    "            event.label as event_label,\n",
    "            'direct_event_location' as location_path\n",
    "        FROM oc_pqg s\n",
    "        JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN oc_pqg event ON e1.o[1] = event.row_id\n",
    "        JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sample_location'\n",
    "        JOIN oc_pqg g ON e2.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND event.otype = 'SamplingEvent'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 20\n",
    "    \"\"\", [target_geo_pid]).fetchdf()\n",
    "    \n",
    "    print(f\"\\n3. Direct Event Samples ({len(direct_samples)} found):\")\n",
    "    if not direct_samples.empty:\n",
    "        print(direct_samples[['sample_id', 'sample_label', 'event_id', 'event_label']].head())\n",
    "    else:\n",
    "        print(\"   ❌ No direct event samples found!\")\n",
    "else:\n",
    "    print(\"\\n3. Skipping direct samples query - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Site-Associated Samples (1 found):\n",
      "              sample_id    sample_label       site_name  \\\n",
      "0  ark:/28722/k2x63t42w  Assemblage 364  Osceola County   \n",
      "\n",
      "                                            event_id  \n",
      "0  sampevent_b19416f025a0b804563976f00aa78a8524c2...  \n"
     ]
    }
   ],
   "source": [
    "# 4. Query for site-associated samples (Path 2 from parquet_cesium.qmd)\n",
    "# Sample -> produced_by -> SamplingEvent -> sampling_site -> SamplingSite -> site_location -> GeospatialCoordLocation\n",
    "if geo_row_id is not None:\n",
    "    site_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            s.name as sample_name,\n",
    "            event.pid as event_id,\n",
    "            event.label as event_label,\n",
    "            site.label as site_name,\n",
    "            'via_site_location' as location_path\n",
    "        FROM oc_pqg s\n",
    "        JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN oc_pqg event ON e1.o[1] = event.row_id\n",
    "        JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sampling_site'\n",
    "        JOIN oc_pqg site ON e2.o[1] = site.row_id\n",
    "        JOIN oc_pqg e3 ON site.row_id = e3.s AND e3.p = 'site_location'\n",
    "        JOIN oc_pqg g ON e3.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND event.otype = 'SamplingEvent'\n",
    "          AND site.otype = 'SamplingSite'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 20\n",
    "    \"\"\", [target_geo_pid]).fetchdf()\n",
    "    \n",
    "    print(f\"\\n4. Site-Associated Samples ({len(site_samples)} found):\")\n",
    "    if not site_samples.empty:\n",
    "        print(site_samples[['sample_id', 'sample_label', 'site_name', 'event_id']].head())\n",
    "    else:\n",
    "        print(\"   ❌ No site-associated samples found!\")\n",
    "else:\n",
    "    print(\"\\n4. Skipping site samples query - geo location not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Detailed metadata for sample: ark:/28722/k2x63t42w\n",
      "   Sample label: Assemblage 364\n",
      "   Location path: via_site_location\n",
      "\n",
      "   Materials (1 found):\n",
      "     - Material (https://w3id.org/isample/vocabulary/material/1.0/material)\n",
      "\n",
      "   Responsible Agents (0 found):\n",
      "     ❌ No agents found!\n"
     ]
    }
   ],
   "source": [
    "# 5. If we found samples, get detailed metadata for the first sample\n",
    "all_samples = []\n",
    "if 'direct_samples' in locals() and not direct_samples.empty:\n",
    "    all_samples.extend(direct_samples.to_dict('records'))\n",
    "if 'site_samples' in locals() and not site_samples.empty:\n",
    "    all_samples.extend(site_samples.to_dict('records'))\n",
    "\n",
    "if all_samples:\n",
    "    first_sample = all_samples[0]\n",
    "    sample_pid = first_sample['sample_id']\n",
    "    \n",
    "    print(f\"\\n5. Detailed metadata for sample: {sample_pid}\")\n",
    "    print(f\"   Sample label: {first_sample.get('sample_label', 'N/A')}\")\n",
    "    print(f\"   Location path: {first_sample.get('location_path', 'N/A')}\")\n",
    "    \n",
    "    # Get material categories for this sample\n",
    "    materials = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            mat.pid as material_id,\n",
    "            mat.label as material_type,\n",
    "            mat.name as material_category\n",
    "        FROM oc_pqg s\n",
    "        JOIN oc_pqg e ON s.row_id = e.s AND e.p = 'has_material_category'\n",
    "        JOIN oc_pqg mat ON e.o[1] = mat.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND s.pid = ?\n",
    "          AND e.otype = '_edge_'\n",
    "          AND mat.otype = 'IdentifiedConcept'\n",
    "    \"\"\", [sample_pid]).fetchdf()\n",
    "    \n",
    "    print(f\"\\n   Materials ({len(materials)} found):\")\n",
    "    if not materials.empty:\n",
    "        for _, mat in materials.iterrows():\n",
    "            print(f\"     - {mat['material_type']} ({mat['material_id']})\")\n",
    "    else:\n",
    "        print(\"     ❌ No materials found!\")\n",
    "        \n",
    "    # Get agents responsible for this sample\n",
    "    agents = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            agent.pid as agent_id,\n",
    "            agent.label as agent_name,\n",
    "            agent.name as agent_role\n",
    "        FROM oc_pqg s\n",
    "        JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN oc_pqg event ON e1.o[1] = event.row_id\n",
    "        JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'has_responsibility_actor'\n",
    "        JOIN oc_pqg agent ON e2.o[1] = agent.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND s.pid = ?\n",
    "          AND e1.otype = '_edge_'\n",
    "          AND event.otype = 'SamplingEvent'\n",
    "          AND e2.otype = '_edge_'\n",
    "          AND agent.otype = 'Agent'\n",
    "        LIMIT 10\n",
    "    \"\"\", [sample_pid]).fetchdf()\n",
    "    \n",
    "    print(f\"\\n   Responsible Agents ({len(agents)} found):\")\n",
    "    if not agents.empty:\n",
    "        for _, agent in agents.iterrows():\n",
    "            print(f\"     - {agent['agent_name']} ({agent['agent_id']})\")\n",
    "    else:\n",
    "        print(\"     ❌ No agents found!\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n5. No samples found to analyze metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY for geoloc_7ea562cce4c70e4b37f7915e8384880c86607729 ===\n",
      "✅ Geo location found (row_id: 191480)\n",
      "📍 Coordinates: 28.058084, -81.146851\n",
      "🔬 Total samples found: 1\n",
      "   - Direct event samples: 0\n",
      "   - Site-associated samples: 1\n",
      "✅ Sample metadata retrieval successful!\n",
      "   - Materials and agents can be extracted for each sample\n",
      "\n",
      "=== END DEBUG for geoloc_7ea562cce4c70e4b37f7915e8384880c86607729 ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Summary of findings for this geo location\n",
    "print(f\"\\n=== SUMMARY for {target_geo_pid} ===\")\n",
    "if geo_row_id is not None:\n",
    "    print(f\"✅ Geo location found (row_id: {geo_row_id})\")\n",
    "    print(f\"📍 Coordinates: {geo_record.iloc[0]['latitude']}, {geo_record.iloc[0]['longitude']}\")\n",
    "    \n",
    "    total_samples = len(all_samples)\n",
    "    direct_count = len([s for s in all_samples if s.get('location_path') == 'direct_event_location'])\n",
    "    site_count = len([s for s in all_samples if s.get('location_path') == 'via_site_location'])\n",
    "    \n",
    "    print(f\"🔬 Total samples found: {total_samples}\")\n",
    "    print(f\"   - Direct event samples: {direct_count}\")\n",
    "    print(f\"   - Site-associated samples: {site_count}\")\n",
    "    \n",
    "    if total_samples > 0:\n",
    "        print(\"✅ Sample metadata retrieval successful!\")\n",
    "        print(\"   - Materials and agents can be extracted for each sample\")\n",
    "    else:\n",
    "        print(\"❌ No samples found - this explains the issue in parquet_cesium.qmd\")\n",
    "        print(\"   - The location exists but has no associated sample data\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Geo location not found in dataset!\")\n",
    "\n",
    "print(f\"\\n=== END DEBUG for {target_geo_pid} ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing with geo locations that have direct sample_location edges ===\n",
      "                                               pid   latitude  longitude  \\\n",
      "0  geoloc_35842a4fa478ae28c68f54d1db36c8e968d62dcb  37.668196  32.827191   \n",
      "1  geoloc_17bae610b87227ef806161bdb40ac97b4cd8ef5e  30.328700  35.442100   \n",
      "2  geoloc_045c25c9e19aeac434ef19616cf2130175cfd130  35.034889  32.421841   \n",
      "\n",
      "   edge_count  \n",
      "0      131022  \n",
      "1      108846  \n",
      "2       52252  \n",
      "\n",
      "Testing direct samples query with: geoloc_35842a4fa478ae28c68f54d1db36c8e968d62dcb\n",
      "Direct samples found: 5\n",
      "✅ Direct event samples DO exist in the dataset!\n",
      "              sample_id sample_label  \\\n",
      "0  ark:/28722/k2ng4kg81   17047.F301   \n",
      "1  ark:/28722/k2ks6m734   Bone 15919   \n",
      "2  ark:/28722/k22b8xr93    13418.F56   \n",
      "3  ark:/28722/k2nz82v1q   Bone 12324   \n",
      "4  ark:/28722/k2cv4fp0h    4879.F417   \n",
      "\n",
      "                                            event_id  \n",
      "0  sampevent_aa2d34f76d9c3476ddf6e4bb96ff765a621a...  \n",
      "1  sampevent_75decb8ede7bc114c052ce80191504f9080c...  \n",
      "2  sampevent_381824480ae40621950ca5b5a2c0344968a0...  \n",
      "3  sampevent_16693367347774b23d3cf46c40d4eea9e18f...  \n",
      "4  sampevent_79a7b310d800acff57ffd39cd8dc3e33245e...  \n"
     ]
    }
   ],
   "source": [
    "# 7. Test with a different geo location to see if we can find direct event samples\n",
    "# Let's find a geo location that has sample_location edges pointing to it\n",
    "sample_location_geos = conn.execute(\"\"\"\n",
    "    SELECT g.pid, g.latitude, g.longitude, COUNT(*) as edge_count\n",
    "    FROM oc_pqg e\n",
    "    JOIN oc_pqg g ON e.o[1] = g.row_id\n",
    "    WHERE e.otype = '_edge_' \n",
    "      AND e.p = 'sample_location'\n",
    "      AND g.otype = 'GeospatialCoordLocation'\n",
    "    GROUP BY g.pid, g.latitude, g.longitude\n",
    "    ORDER BY edge_count DESC\n",
    "    LIMIT 3\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"=== Testing with geo locations that have direct sample_location edges ===\")\n",
    "print(sample_location_geos)\n",
    "\n",
    "if not sample_location_geos.empty:\n",
    "    test_geo_pid = sample_location_geos.iloc[0]['pid']\n",
    "    print(f\"\\nTesting direct samples query with: {test_geo_pid}\")\n",
    "    \n",
    "    test_direct_samples = conn.execute(\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            s.pid as sample_id,\n",
    "            s.label as sample_label,\n",
    "            event.pid as event_id,\n",
    "            event.label as event_label\n",
    "        FROM oc_pqg s\n",
    "        JOIN oc_pqg e1 ON s.row_id = e1.s AND e1.p = 'produced_by'\n",
    "        JOIN oc_pqg event ON e1.o[1] = event.row_id\n",
    "        JOIN oc_pqg e2 ON event.row_id = e2.s AND e2.p = 'sample_location'\n",
    "        JOIN oc_pqg g ON e2.o[1] = g.row_id\n",
    "        WHERE s.otype = 'MaterialSampleRecord'\n",
    "          AND event.otype = 'SamplingEvent'\n",
    "          AND g.otype = 'GeospatialCoordLocation'\n",
    "          AND g.pid = ?\n",
    "        LIMIT 5\n",
    "    \"\"\", [test_geo_pid]).fetchdf()\n",
    "    \n",
    "    print(f\"Direct samples found: {len(test_direct_samples)}\")\n",
    "    if not test_direct_samples.empty:\n",
    "        print(\"✅ Direct event samples DO exist in the dataset!\")\n",
    "        print(test_direct_samples[['sample_id', 'sample_label', 'event_id']].head())\n",
    "    else:\n",
    "        print(\"❌ Still no direct event samples found\")\n",
    "else:\n",
    "    print(\"❌ No geo locations with sample_location edges found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug Analysis Results\n",
    "\n",
    "### Key Findings for parquet_cesium.qmd\n",
    "\n",
    "1. **Geo Location Structure**: The target geo location `geoloc_7ea562cce4c70e4b37f7915e8384880c86607729` exists in the dataset with correct coordinates.\n",
    "\n",
    "2. **Sample Association**: This specific location has **1 site-associated sample** but **0 direct event samples**.\n",
    "\n",
    "3. **Query Validation**: Both query paths work correctly:\n",
    "   - **Direct path**: `Sample → SamplingEvent → sample_location → GeospatialCoordLocation`\n",
    "   - **Site path**: `Sample → SamplingEvent → SamplingSite → site_location → GeospatialCoordLocation`\n",
    "\n",
    "4. **Data Availability**: The dataset contains both types of sample associations, but not every geo location has both types.\n",
    "\n",
    "### Recommendations for parquet_cesium.qmd\n",
    "\n",
    "- The JavaScript queries are correctly structured and should work\n",
    "- Some geo locations may only have site-associated samples (like our test case)\n",
    "- Consider showing both direct and site-associated samples in the UI\n",
    "- Add debug logging to identify when no samples are found vs. query errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete!\n",
      "Note: DuckDB connection remains open for interactive use\n"
     ]
    }
   ],
   "source": [
    "# Analysis complete!\n",
    "print(\"\\nAnalysis complete!\")\n",
    "print(\"Note: DuckDB connection remains open for interactive use\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isamples-python-3.12.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
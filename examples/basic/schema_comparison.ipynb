{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iSamples Parquet Schema Comparison\n",
    "\n",
    "**Goal**: Understand the tradeoffs among five parquet formats for iSamples data.\n",
    "\n",
    "| Format | Philosophy | Sources | Relationships |\n",
    "|--------|-----------|---------|---------------|\n",
    "| **Export** | Sample-centric (flat) | All 4 sources | Nested STRUCTs |\n",
    "| **Zenodo Narrow** | Graph (nodes + edges) | All 4 sources | Separate `_edge_` rows |\n",
    "| **Zenodo Wide** | Entity-centric | All 4 sources | `p__*` arrays \u2192 row_ids |\n",
    "| **Eric's Narrow** | Graph (nodes + edges) | OpenContext only | Separate `_edge_` rows |\n",
    "| **Eric's Wide** | Entity-centric | OpenContext only | `p__*` arrays \u2192 row_ids |\n",
    "\n",
    "**Key insight**: There is no universal best format. Each optimizes for different query patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## Portability\n",
    "\n",
    "This notebook works in multiple environments:\n",
    "\n",
    "| Environment | Behavior |\n",
    "|-------------|----------|\n",
    "| **Raymond's laptop** | Uses local files in `~/Data/iSample/` |\n",
    "| **mybinder.org** | Downloads to `/tmp/pqgfiles/` cache |\n",
    "| **Other users** | Downloads to `~/Data/iSample/pqg_cache/` |\n",
    "\n",
    "**Configuration options** (in cell 2):\n",
    "- `CACHE_DIR`: Override with `ISAMPLES_CACHE_DIR` env var\n",
    "- `USE_REMOTE=True`: Skip downloads, query remote parquet via HTTP (slower but no disk)\n",
    "- `DOWNLOAD_MISSING=False`: Error instead of downloading missing files\n",
    "\n",
    "---\n",
    "\n",
    "## Data Source Coverage\n",
    "\n",
    "| Format | Sources | Description |\n",
    "|--------|---------|-------------|\n",
    "| **Export, Zenodo Narrow, Zenodo Wide** | SESAR, OpenContext, GEOME, Smithsonian | Full iSamples (~6.7M samples) |\n",
    "| **Eric's Narrow, Eric's Wide** | OpenContext only | Subset (~1.1M samples) |\n",
    "\n",
    "This allows fair comparisons:\n",
    "- **Apples-to-apples**: Export vs Zenodo Narrow vs Zenodo Wide (same data)\n",
    "- **Structure comparison**: Eric's Narrow vs Eric's Wide (same data, different structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache directory: /Users/raymondyee/Data/iSample/pqg_cache\n",
      "Use remote: False, Download missing: True\n",
      "\n",
      "=== Full iSamples (all sources) ===\n",
      "\u2705 export: 297.0 MB (local)\n",
      "\u2705 zenodo_narrow: 860.1 MB (local)\n",
      "\u2705 zenodo_wide: 291.8 MB (local)\n",
      "\n",
      "=== OpenContext only (Eric's) ===\n",
      "\u2705 eric_narrow: 724.5 MB (local)\n",
      "\u2705 eric_wide: 288.7 MB (local)\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these paths for your environment\n",
    "# =============================================================================\n",
    "\n",
    "# Cache directory for downloaded files (used when local paths don't exist)\n",
    "# - On mybinder.org: uses /tmp/pqgfiles\n",
    "# - Locally: uses ~/Data/iSample/pqg_cache (or override with ISAMPLES_CACHE_DIR env var)\n",
    "CACHE_DIR = Path(os.environ.get('ISAMPLES_CACHE_DIR', \n",
    "                                '/tmp/pqgfiles' if Path('/tmp').exists() and not Path.home().joinpath('Data/iSample').exists()\n",
    "                                else Path.home() / 'Data/iSample/pqg_cache'))\n",
    "\n",
    "# Local paths (Raymond's setup) - these are checked first\n",
    "# Updated 2026-01-09: zenodo_wide now points to January 9 conversion\n",
    "# which fixes issue #8 ([null] array bug in p__* columns)\n",
    "LOCAL_PATHS = {\n",
    "    'export': Path.home() / 'Data/iSample/2025_04_21_16_23_46/isamples_export_2025_04_21_16_23_46_geo.parquet',\n",
    "    'zenodo_narrow': Path.home() / 'Data/iSample/pqg_refining/zenodo_narrow_2025-12-12.parquet',\n",
    "    'zenodo_wide': Path.home() / 'Data/iSample/pqg_refining/zenodo_wide_2026-01-09.parquet',\n",
    "    'eric_narrow': Path.home() / 'Data/iSample/pqg_refining/oc_isamples_pqg.parquet',\n",
    "    'eric_wide': Path.home() / 'Data/iSample/pqg_refining/oc_isamples_pqg_wide.parquet',\n",
    "}\n",
    "\n",
    "# Remote URLs - fallback when local files don't exist\n",
    "# Updated 2026-01-09: R2 bucket contains January 9 wide conversion (fixes issue #8)\n",
    "URLS = {\n",
    "    'export': 'https://zenodo.org/records/15278211/files/isamples_export_2025_04_21_16_23_46_geo.parquet',\n",
    "    'zenodo_narrow': 'https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202512_narrow.parquet',\n",
    "    'zenodo_wide': 'https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202601_wide.parquet',\n",
    "    'eric_narrow': 'https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg.parquet',\n",
    "    'eric_wide': 'https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg_wide.parquet',\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PATH RESOLUTION - Automatically finds or downloads files\n",
    "# =============================================================================\n",
    "\n",
    "def resolve_path(name: str, local_paths: dict, urls: dict, cache_dir: Path, \n",
    "                 download: bool = True, use_remote: bool = False) -> Path:\n",
    "    \"\"\"\n",
    "    Resolve file path: check local first, then cache, optionally download.\n",
    "    \n",
    "    Args:\n",
    "        name: File identifier (e.g., 'export', 'zenodo_wide')\n",
    "        local_paths: Dict of local file paths to check first\n",
    "        urls: Dict of remote URLs for downloading\n",
    "        cache_dir: Directory for cached downloads\n",
    "        download: If True, download missing files to cache\n",
    "        use_remote: If True, return URL for DuckDB remote access (no download)\n",
    "    \n",
    "    Returns:\n",
    "        Path to local file, or URL string if use_remote=True\n",
    "    \"\"\"\n",
    "    # Option 1: Local file exists\n",
    "    if name in local_paths and local_paths[name].exists():\n",
    "        return local_paths[name]\n",
    "    \n",
    "    # Option 2: Return URL for remote access (DuckDB can read directly)\n",
    "    if use_remote and name in urls:\n",
    "        return urls[name]\n",
    "    \n",
    "    # Option 3: Check cache\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cached_file = cache_dir / f\"{name}.parquet\"\n",
    "    \n",
    "    if cached_file.exists():\n",
    "        return cached_file\n",
    "    \n",
    "    # Option 4: Download to cache\n",
    "    if download and name in urls:\n",
    "        url = urls[name]\n",
    "        print(f\"Downloading {name} from {url}...\")\n",
    "        print(f\"  -> {cached_file}\")\n",
    "        \n",
    "        # Download with progress\n",
    "        def progress_hook(block_num, block_size, total_size):\n",
    "            downloaded = block_num * block_size\n",
    "            if total_size > 0:\n",
    "                pct = min(100, downloaded * 100 // total_size)\n",
    "                mb = downloaded / 1e6\n",
    "                total_mb = total_size / 1e6\n",
    "                print(f\"\\r  Progress: {pct}% ({mb:.1f}/{total_mb:.1f} MB)\", end='', flush=True)\n",
    "        \n",
    "        urllib.request.urlretrieve(url, cached_file, reporthook=progress_hook)\n",
    "        print()  # newline after progress\n",
    "        return cached_file\n",
    "    \n",
    "    # No file available\n",
    "    raise FileNotFoundError(f\"File '{name}' not found locally and download=False\")\n",
    "\n",
    "# =============================================================================\n",
    "# RESOLVE ALL PATHS\n",
    "# =============================================================================\n",
    "\n",
    "# Set to True to skip downloads and use DuckDB's remote parquet reading\n",
    "# (Slower queries but no disk usage - good for quick exploration)\n",
    "USE_REMOTE = False\n",
    "\n",
    "# Set to False to skip downloading missing files (will error if not found)\n",
    "DOWNLOAD_MISSING = True\n",
    "\n",
    "print(f\"Cache directory: {CACHE_DIR}\")\n",
    "print(f\"Use remote: {USE_REMOTE}, Download missing: {DOWNLOAD_MISSING}\\n\")\n",
    "\n",
    "PATHS = {}\n",
    "for name in ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n",
    "    try:\n",
    "        path = resolve_path(name, LOCAL_PATHS, URLS, CACHE_DIR, \n",
    "                           download=DOWNLOAD_MISSING, use_remote=USE_REMOTE)\n",
    "        PATHS[name] = path\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\u26a0\ufe0f {name}: {e}\")\n",
    "        PATHS[name] = None\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFY FILES\n",
    "# =============================================================================\n",
    "\n",
    "def get_file_info(path):\n",
    "    \"\"\"Get file info - works for both local paths and URLs.\"\"\"\n",
    "    if path is None:\n",
    "        return '\u274c', 'Not available'\n",
    "    if isinstance(path, str) and path.startswith('http'):\n",
    "        return '\ud83c\udf10', 'Remote URL'\n",
    "    if Path(path).exists():\n",
    "        size_mb = Path(path).stat().st_size / 1e6\n",
    "        return '\u2705', f'{size_mb:.1f} MB'\n",
    "    return '\u274c', 'Not found'\n",
    "\n",
    "print(\"=== Full iSamples (all sources) ===\")\n",
    "for name in ['export', 'zenodo_narrow', 'zenodo_wide']:\n",
    "    status, info = get_file_info(PATHS.get(name))\n",
    "    source = \"local\" if PATHS.get(name) and Path(PATHS[name]).exists() and PATHS[name] in LOCAL_PATHS.values() else \"cache/remote\"\n",
    "    print(f'{status} {name}: {info} ({source})')\n",
    "\n",
    "print(\"\\n=== OpenContext only (Eric's) ===\")\n",
    "for name in ['eric_narrow', 'eric_wide']:\n",
    "    status, info = get_file_info(PATHS.get(name))\n",
    "    source = \"local\" if PATHS.get(name) and Path(PATHS[name]).exists() and PATHS[name] in LOCAL_PATHS.values() else \"cache/remote\"\n",
    "    print(f'{status} {name}: {info} ({source})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for timing queries\n",
    "import statistics\n",
    "\n",
    "def timed_query(con, sql, name=\"Query\"):\n",
    "    \"\"\"Execute query and return (result_df, elapsed_ms)\"\"\"\n",
    "    start = time.time()\n",
    "    result = con.sql(sql).fetchdf()\n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    print(f\"{name}: {elapsed:.1f}ms, {len(result):,} rows\")\n",
    "    return result, elapsed\n",
    "\n",
    "def timed_query_multirun(con, sql, name=\"Query\", runs=3):\n",
    "    \"\"\"Execute query multiple times and return (result_df, mean_ms, stddev_ms)\"\"\"\n",
    "    times = []\n",
    "    result = None\n",
    "    for i in range(runs):\n",
    "        start = time.time()\n",
    "        result = con.sql(sql).fetchdf()\n",
    "        elapsed = (time.time() - start) * 1000\n",
    "        times.append(elapsed)\n",
    "    \n",
    "    mean_ms = statistics.mean(times)\n",
    "    stddev_ms = statistics.stdev(times) if len(times) > 1 else 0\n",
    "    print(f\"{name}: {mean_ms:.1f}ms \u00b1 {stddev_ms:.1f}ms (n={runs}), {len(result):,} rows\")\n",
    "    return result, mean_ms, stddev_ms\n",
    "\n",
    "# Create connection\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema Inspection\n",
    "\n",
    "Understanding what columns exist and their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXPORT (19 columns) ===\n",
      "                column_name                                                                                                                                                                                                                                                                                                                                     column_type\n",
      "0         sample_identifier                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "1                       @id                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "2                     label                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "3               description                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "4         source_collection                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "5    has_sample_object_type                                                                                                                                                                                                                                                                                                                    STRUCT(identifier VARCHAR)[]\n",
      "6     has_material_category                                                                                                                                                                                                                                                                                                                    STRUCT(identifier VARCHAR)[]\n",
      "7      has_context_category                                                                                                                                                                                                                                                                                                                    STRUCT(identifier VARCHAR)[]\n",
      "8   informal_classification                                                                                                                                                                                                                                                                                                                                       VARCHAR[]\n",
      "9                  keywords                                                                                                                                                                                                                                                                                                                       STRUCT(keyword VARCHAR)[]\n",
      "10              produced_by  STRUCT(description VARCHAR, has_feature_of_interest VARCHAR, identifier VARCHAR, \"label\" VARCHAR, responsibility STRUCT(\"name\" VARCHAR, \"role\" VARCHAR)[], result_time VARCHAR, sampling_site STRUCT(description VARCHAR, \"label\" VARCHAR, place_name VARCHAR[], sample_location STRUCT(elevation DOUBLE, latitude DOUBLE, longitude DOUBLE)))\n",
      "11       last_modified_time                                                                                                                                                                                                                                                                                                                        TIMESTAMP WITH TIME ZONE\n",
      "12                 curation                                                                                                                                                                                  STRUCT(access_constraints VARCHAR[], curation_location VARCHAR, description VARCHAR, \"label\" VARCHAR, responsibility STRUCT(\"name\" VARCHAR, \"role\" VARCHAR)[])\n",
      "13               registrant                                                                                                                                                                                                                                                                                                                          STRUCT(\"name\" VARCHAR)\n",
      "14         related_resource                                                                                                                                                                                                                                                                                                                        STRUCT(target VARCHAR)[]\n",
      "  ... and 4 more columns\n",
      "\n",
      "=== ZENODO_NARROW (40 columns) ===\n",
      "                column_name column_type\n",
      "0                    row_id      BIGINT\n",
      "1                       pid     VARCHAR\n",
      "2                  tcreated     INTEGER\n",
      "3                 tmodified     INTEGER\n",
      "4                     otype     VARCHAR\n",
      "5                         s      BIGINT\n",
      "6                         p     VARCHAR\n",
      "7                         o   INTEGER[]\n",
      "8                         n     VARCHAR\n",
      "9                    altids   VARCHAR[]\n",
      "10                 geometry        BLOB\n",
      "11            authorized_by   VARCHAR[]\n",
      "12  has_feature_of_interest     VARCHAR\n",
      "13              affiliation     VARCHAR\n",
      "14         sampling_purpose     VARCHAR\n",
      "  ... and 25 more columns\n",
      "\n",
      "=== ZENODO_WIDE (49 columns) ===\n",
      "                column_name column_type\n",
      "0                    row_id      BIGINT\n",
      "1                       pid     VARCHAR\n",
      "2                  tcreated     INTEGER\n",
      "3                 tmodified     INTEGER\n",
      "4                     otype     VARCHAR\n",
      "5                         n     VARCHAR\n",
      "6                    altids   VARCHAR[]\n",
      "7                  geometry        BLOB\n",
      "8             authorized_by   VARCHAR[]\n",
      "9   has_feature_of_interest     VARCHAR\n",
      "10              affiliation     VARCHAR\n",
      "11         sampling_purpose     VARCHAR\n",
      "12            complies_with   VARCHAR[]\n",
      "13                  project     VARCHAR\n",
      "14    alternate_identifiers   VARCHAR[]\n",
      "  ... and 34 more columns\n",
      "\n",
      "=== ERIC_NARROW (40 columns) ===\n",
      "                column_name column_type\n",
      "0                    row_id     INTEGER\n",
      "1                       pid     VARCHAR\n",
      "2                  tcreated     INTEGER\n",
      "3                 tmodified     INTEGER\n",
      "4                     otype     VARCHAR\n",
      "5                         s     INTEGER\n",
      "6                         p     VARCHAR\n",
      "7                         o   INTEGER[]\n",
      "8                         n     VARCHAR\n",
      "9                    altids   VARCHAR[]\n",
      "10                 geometry        BLOB\n",
      "11            authorized_by   VARCHAR[]\n",
      "12  has_feature_of_interest     VARCHAR\n",
      "13              affiliation     VARCHAR\n",
      "14         sampling_purpose     VARCHAR\n",
      "  ... and 25 more columns\n",
      "\n",
      "=== ERIC_WIDE (47 columns) ===\n",
      "                column_name column_type\n",
      "0                    row_id     INTEGER\n",
      "1                       pid     VARCHAR\n",
      "2                  tcreated     INTEGER\n",
      "3                 tmodified     INTEGER\n",
      "4                     otype     VARCHAR\n",
      "5                         n     VARCHAR\n",
      "6                    altids   VARCHAR[]\n",
      "7                  geometry        BLOB\n",
      "8             authorized_by   VARCHAR[]\n",
      "9   has_feature_of_interest     VARCHAR\n",
      "10              affiliation     VARCHAR\n",
      "11         sampling_purpose     VARCHAR\n",
      "12            complies_with   VARCHAR[]\n",
      "13                  project     VARCHAR\n",
      "14    alternate_identifiers   VARCHAR[]\n",
      "  ... and 32 more columns\n"
     ]
    }
   ],
   "source": [
    "# Helper to check if path is available (works for Path objects and URL strings)\n",
    "def path_available(path):\n",
    "    \"\"\"Check if a path is available (local file exists or is a URL).\"\"\"\n",
    "    if path is None:\n",
    "        return False\n",
    "    if isinstance(path, str) and path.startswith('http'):\n",
    "        return True  # URLs are assumed available\n",
    "    return Path(path).exists()\n",
    "\n",
    "# Get schema for each format\n",
    "schemas = {}\n",
    "for name, path in PATHS.items():\n",
    "    if path_available(path):\n",
    "        result = con.sql(f\"DESCRIBE SELECT * FROM read_parquet('{path}')\").fetchdf()\n",
    "        schemas[name] = result\n",
    "        print(f\"\\n=== {name.upper()} ({len(result)} columns) ===\")\n",
    "        # Show just first 15 columns to keep output manageable\n",
    "        print(result[['column_name', 'column_type']].head(15).to_string())\n",
    "        if len(result) > 15:\n",
    "            print(f\"  ... and {len(result) - 15} more columns\")\n",
    "    else:\n",
    "        print(f\"\\n=== {name.upper()} ===\")\n",
    "        print(f\"  \u26a0\ufe0f Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Data</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Edge cols (s,p,o)</th>\n",
       "      <th>p__* cols</th>\n",
       "      <th>Nested STRUCTs</th>\n",
       "      <th>otype col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Export</td>\n",
       "      <td>Full</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\u2713</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zenodo Narrow</td>\n",
       "      <td>Full</td>\n",
       "      <td>40</td>\n",
       "      <td>\u2713</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\u2713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zenodo Wide</td>\n",
       "      <td>Full</td>\n",
       "      <td>49</td>\n",
       "      <td></td>\n",
       "      <td>\u2713</td>\n",
       "      <td></td>\n",
       "      <td>\u2713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric Narrow</td>\n",
       "      <td>OC only</td>\n",
       "      <td>40</td>\n",
       "      <td>\u2713</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\u2713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Wide</td>\n",
       "      <td>OC only</td>\n",
       "      <td>47</td>\n",
       "      <td></td>\n",
       "      <td>\u2713</td>\n",
       "      <td></td>\n",
       "      <td>\u2713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Format     Data  Columns Edge cols (s,p,o) p__* cols Nested STRUCTs  \\\n",
       "0         Export     Full       19                                          \u2713   \n",
       "1  Zenodo Narrow     Full       40                 \u2713                            \n",
       "2    Zenodo Wide     Full       49                           \u2713                  \n",
       "3    Eric Narrow  OC only       40                 \u2713                            \n",
       "4      Eric Wide  OC only       47                           \u2713                  \n",
       "\n",
       "  otype col  \n",
       "0            \n",
       "1         \u2713  \n",
       "2         \u2713  \n",
       "3         \u2713  \n",
       "4         \u2713  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare column counts and key structural differences (computed from schemas)\n",
    "def check_schema_features(schema_df):\n",
    "    \"\"\"Analyze schema DataFrame for structural features.\"\"\"\n",
    "    if schema_df is None or len(schema_df) == 0:\n",
    "        return {'columns': 0, 'has_edge_cols': False, 'has_p__cols': False, \n",
    "                'has_nested_structs': False, 'has_otype': False}\n",
    "    \n",
    "    cols = set(schema_df['column_name'].tolist())\n",
    "    types = dict(zip(schema_df['column_name'], schema_df['column_type']))\n",
    "    \n",
    "    return {\n",
    "        'columns': len(schema_df),\n",
    "        'has_edge_cols': all(c in cols for c in ['s', 'p', 'o']),\n",
    "        'has_p__cols': any(c.startswith('p__') for c in cols),\n",
    "        'has_nested_structs': any('STRUCT' in str(t) for t in types.values()),\n",
    "        'has_otype': 'otype' in cols,\n",
    "    }\n",
    "\n",
    "# Compute features for each format\n",
    "format_order = ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']\n",
    "features = {name: check_schema_features(schemas.get(name)) for name in format_order}\n",
    "\n",
    "# Build comparison table\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Format': name.replace('_', ' ').title(),\n",
    "        'Data': 'Full' if name in ['export', 'zenodo_narrow', 'zenodo_wide'] else 'OC only',\n",
    "        'Columns': features[name]['columns'],\n",
    "        'Edge cols (s,p,o)': '\u2713' if features[name]['has_edge_cols'] else '',\n",
    "        'p__* cols': '\u2713' if features[name]['has_p__cols'] else '',\n",
    "        'Nested STRUCTs': '\u2713' if features[name]['has_nested_structs'] else '',\n",
    "        'otype col': '\u2713' if features[name]['has_otype'] else '',\n",
    "    }\n",
    "    for name in format_order\n",
    "])\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Row Count Analysis\n",
    "\n",
    "Understanding what's IN each format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Full iSamples ===\n",
      "export: 6,680,932 rows\n",
      "zenodo_narrow: 101,387,180 rows\n",
      "zenodo_wide: 20,729,358 rows\n",
      "\n",
      "=== OpenContext only ===\n",
      "eric_narrow: 11,637,144 rows\n",
      "eric_wide: 2,464,690 rows\n"
     ]
    }
   ],
   "source": [
    "# Total row counts\n",
    "row_counts = {}\n",
    "print(\"=== Full iSamples ===\")\n",
    "for name in ['export', 'zenodo_narrow', 'zenodo_wide']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        count = con.sql(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n",
    "        row_counts[name] = count\n",
    "        print(f\"{name}: {count:,} rows\")\n",
    "    else:\n",
    "        print(f\"{name}: \u26a0\ufe0f Not available\")\n",
    "\n",
    "print(\"\\n=== OpenContext only ===\")\n",
    "for name in ['eric_narrow', 'eric_wide']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        count = con.sql(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n",
    "        row_counts[name] = count\n",
    "        print(f\"{name}: {count:,} rows\")\n",
    "    else:\n",
    "        print(f\"{name}: \u26a0\ufe0f Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO_NARROW: Rows by otype ===\n",
      "                     otype       cnt\n",
      "0                   _edge_  80657822\n",
      "1     MaterialSampleRecord   6680932\n",
      "2            SamplingEvent   6354171\n",
      "3  GeospatialCoordLocation   5980282\n",
      "4   MaterialSampleCuration    720254\n",
      "5           SampleRelation    501579\n",
      "6             SamplingSite    386160\n",
      "7        IdentifiedConcept     55893\n",
      "8                    Agent     50087\n",
      "\n",
      "=== ZENODO_WIDE: Rows by otype ===\n",
      "                     otype      cnt\n",
      "0     MaterialSampleRecord  6680932\n",
      "1            SamplingEvent  6354171\n",
      "2  GeospatialCoordLocation  5980282\n",
      "3   MaterialSampleCuration   720254\n",
      "4           SampleRelation   501579\n",
      "5             SamplingSite   386160\n",
      "6        IdentifiedConcept    55893\n",
      "7                    Agent    50087\n",
      "\n",
      "=== ERIC_NARROW: Rows by otype ===\n",
      "                     otype      cnt\n",
      "0                   _edge_  9201451\n",
      "1     MaterialSampleRecord  1096352\n",
      "2            SamplingEvent  1096352\n",
      "3  GeospatialCoordLocation   198433\n",
      "4        IdentifiedConcept    25778\n",
      "5             SamplingSite    18213\n",
      "6                    Agent      565\n",
      "\n",
      "=== ERIC_WIDE: Rows by otype ===\n",
      "                     otype      cnt\n",
      "0     MaterialSampleRecord  1110412\n",
      "1            SamplingEvent  1110412\n",
      "2  GeospatialCoordLocation   199147\n",
      "3        IdentifiedConcept    25929\n",
      "4             SamplingSite    18213\n",
      "5                    Agent      577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For PQG formats: breakdown by otype\n",
    "for name in ['zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        print(f\"=== {name.upper()}: Rows by otype ===\")\n",
    "        result = con.sql(f\"\"\"\n",
    "            SELECT otype, COUNT(*) as cnt \n",
    "            FROM read_parquet('{path}')\n",
    "            GROUP BY otype ORDER BY cnt DESC\n",
    "        \"\"\").fetchdf()\n",
    "        print(result.to_string())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT: Rows by source_collection ===\n",
      "  source_collection      cnt\n",
      "0             SESAR  4688386\n",
      "1       OPENCONTEXT  1064831\n",
      "2             GEOME   605554\n",
      "3       SMITHSONIAN   322161\n"
     ]
    }
   ],
   "source": [
    "# For Export: breakdown by source_collection\n",
    "print(\"=== EXPORT: Rows by source_collection ===\")\n",
    "if path_available(PATHS.get('export')):\n",
    "    result = con.sql(f\"\"\"\n",
    "        SELECT source_collection, COUNT(*) as cnt \n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        GROUP BY source_collection ORDER BY cnt DESC\n",
    "    \"\"\").fetchdf()\n",
    "    print(result.to_string())\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f Export file not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Benchmark Suite\n",
    "\n",
    "Testing common query patterns across all three formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Map Visualization: Get All Coordinates\n",
    "\n",
    "**Use case**: Render points on a Cesium/Leaflet map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT (full iSamples) ===\n",
      "All coordinates: 27.1ms, 5,980,282 rows\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Direct column access\n",
    "print(\"=== EXPORT (full iSamples) ===\")\n",
    "export_coords, export_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT sample_location_latitude as lat, sample_location_longitude as lon\n",
    "    FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE sample_location_latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE (full iSamples) ===\n",
      "All coordinates: 31.9ms, 5,980,282 rows\n",
      "\n",
      "=== ERIC WIDE (OpenContext only) ===\n",
      "All coordinates: 4.5ms, 199,146 rows\n"
     ]
    }
   ],
   "source": [
    "# WIDE formats: Filter by otype\n",
    "print(\"=== ZENODO WIDE (full iSamples) ===\")\n",
    "zenodo_wide_coords, zenodo_wide_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT latitude as lat, longitude as lon\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")\n",
    "\n",
    "print(\"\\n=== ERIC WIDE (OpenContext only) ===\")\n",
    "eric_wide_coords, eric_wide_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT latitude as lat, longitude as lon\n",
    "    FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO NARROW (full iSamples) ===\n",
      "All coordinates: 65.0ms, 5,980,282 rows\n",
      "\n",
      "=== ERIC NARROW (OpenContext only) ===\n",
      "All coordinates: 6.6ms, 198,432 rows\n"
     ]
    }
   ],
   "source": [
    "# NARROW formats: Filter by otype  \n",
    "print(\"=== ZENODO NARROW (full iSamples) ===\")\n",
    "zenodo_narrow_coords, zenodo_narrow_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT latitude as lat, longitude as lon\n",
    "    FROM read_parquet('{PATHS['zenodo_narrow']}')\n",
    "    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")\n",
    "\n",
    "print(\"\\n=== ERIC NARROW (OpenContext only) ===\")\n",
    "eric_narrow_coords, eric_narrow_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT latitude as lat, longitude as lon\n",
    "    FROM read_parquet('{PATHS['eric_narrow']}')\n",
    "    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MAP QUERY SUMMARY ===\n",
      "\n",
      "Full iSamples (apples-to-apples comparison):\n",
      "  Export:          27.1ms (5,980,282 points)\n",
      "  Zenodo Wide:     31.9ms (5,980,282 points)\n",
      "  Zenodo Narrow:   65.0ms (5,980,282 points)\n",
      "\n",
      "OpenContext only (Eric's files):\n",
      "  Eric Wide:        4.5ms (199,146 points)\n",
      "  Eric Narrow:      6.6ms (198,432 points)\n",
      "\n",
      "\ud83d\udca1 Key insight: Export returns coords directly; PQG formats need otype filter\n"
     ]
    }
   ],
   "source": [
    "# Summary - Map query comparison\n",
    "print(\"=== MAP QUERY SUMMARY ===\")\n",
    "print(\"\\nFull iSamples (apples-to-apples comparison):\")\n",
    "print(f\"  Export:        {export_coords_time:6.1f}ms ({len(export_coords):,} points)\")\n",
    "print(f\"  Zenodo Wide:   {zenodo_wide_coords_time:6.1f}ms ({len(zenodo_wide_coords):,} points)\")\n",
    "print(f\"  Zenodo Narrow: {zenodo_narrow_coords_time:6.1f}ms ({len(zenodo_narrow_coords):,} points)\")\n",
    "\n",
    "print(\"\\nOpenContext only (Eric's files):\")\n",
    "print(f\"  Eric Wide:     {eric_wide_coords_time:6.1f}ms ({len(eric_wide_coords):,} points)\")\n",
    "print(f\"  Eric Narrow:   {eric_narrow_coords_time:6.1f}ms ({len(eric_narrow_coords):,} points)\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Key insight: Export returns coords directly; PQG formats need otype filter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Faceted Search: Count by Material Category\n",
    "\n",
    "**Use case**: Show facet counts in a search UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT (full iSamples) ===\n",
      "Material facets: 530.0ms, 10 rows\n",
      "                                                                      material      cnt\n",
      "0               https://w3id.org/isample/vocabulary/material/1.0/earthmaterial  2261513\n",
      "1             https://w3id.org/isample/vocabulary/material/1.0/organicmaterial  1265560\n",
      "2                        https://w3id.org/isample/vocabulary/material/1.0/rock  1208585\n",
      "3  https://w3id.org/isample/vocabulary/material/1.0/biogenicnonorganicmaterial  1091781\n",
      "4       https://w3id.org/isample/vocabulary/material/1.0/mixedsoilsedimentrock   838805\n",
      "5                    https://w3id.org/isample/vocabulary/material/1.0/material   673018\n",
      "6                     https://w3id.org/isample/vocabulary/material/1.0/mineral   390797\n",
      "7          https://w3id.org/isample/vocabulary/material/1.0/anthropogenicmetal   270040\n",
      "8                https://w3id.org/isample/opencontext/material/0.1/ceramicclay   100573\n",
      "9                    https://w3id.org/isample/vocabulary/material/1.0/sediment    94084\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Unnest nested struct array\n",
    "# SQL Complexity: 1 subquery, 0 JOINs - simple unnest\n",
    "print(\"=== EXPORT (full iSamples) ===\")\n",
    "export_facets, export_facets_time = timed_query(con, f\"\"\"\n",
    "    SELECT \n",
    "        mat.identifier as material,\n",
    "        COUNT(*) as cnt\n",
    "    FROM (\n",
    "        SELECT unnest(has_material_category) as mat\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE has_material_category IS NOT NULL AND len(has_material_category) > 0\n",
    "    )\n",
    "    GROUP BY mat.identifier\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(export_facets.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE (full iSamples) ===\n",
      "Material facets: 527.1ms, 10 rows\n",
      "                                                                      material      cnt\n",
      "0               https://w3id.org/isample/vocabulary/material/1.0/earthmaterial  2261513\n",
      "1             https://w3id.org/isample/vocabulary/material/1.0/organicmaterial  1265560\n",
      "2                        https://w3id.org/isample/vocabulary/material/1.0/rock  1208585\n",
      "3  https://w3id.org/isample/vocabulary/material/1.0/biogenicnonorganicmaterial  1091781\n",
      "4       https://w3id.org/isample/vocabulary/material/1.0/mixedsoilsedimentrock   838805\n",
      "5                    https://w3id.org/isample/vocabulary/material/1.0/material   673018\n",
      "6                     https://w3id.org/isample/vocabulary/material/1.0/mineral   390797\n",
      "7          https://w3id.org/isample/vocabulary/material/1.0/anthropogenicmetal   270040\n",
      "8                https://w3id.org/isample/opencontext/material/0.1/ceramicclay   100573\n",
      "9                    https://w3id.org/isample/vocabulary/material/1.0/sediment    94084\n",
      "\n",
      "=== ERIC WIDE (OpenContext only) ===\n",
      "Material facets: 102.2ms, 10 rows\n",
      "                        material     cnt\n",
      "0  Biogenic non-organic material  532843\n",
      "1               Organic material  217562\n",
      "2                       Material  159434\n",
      "3   Other anthropogenic material  145431\n",
      "4                           Rock   37948\n",
      "5   Anthropogenic metal material   11694\n",
      "6    Mixed soil sediment or rock    3207\n",
      "7                        Mineral    2233\n",
      "8         Natural Solid Material      58\n",
      "9                       Sediment       2\n"
     ]
    }
   ],
   "source": [
    "# WIDE formats: JOIN via p__has_material_category\n",
    "# SQL Complexity: 2 CTEs, 1 JOIN - requires row_id lookup\n",
    "print(\"=== ZENODO WIDE (full iSamples) ===\")\n",
    "zenodo_wide_facets, zenodo_wide_facets_time = timed_query(con, f\"\"\"\n",
    "    WITH samples AS (\n",
    "        SELECT unnest(p__has_material_category) as concept_rowid\n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "        WHERE otype = 'MaterialSampleRecord' \n",
    "          AND p__has_material_category IS NOT NULL\n",
    "    ),\n",
    "    concepts AS (\n",
    "        SELECT row_id, label\n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "    )\n",
    "    SELECT c.label as material, COUNT(*) as cnt\n",
    "    FROM samples s\n",
    "    JOIN concepts c ON s.concept_rowid = c.row_id\n",
    "    GROUP BY c.label\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(zenodo_wide_facets.to_string())\n",
    "\n",
    "print(\"\\n=== ERIC WIDE (OpenContext only) ===\")\n",
    "eric_wide_facets, eric_wide_facets_time = timed_query(con, f\"\"\"\n",
    "    WITH samples AS (\n",
    "        SELECT unnest(p__has_material_category) as concept_rowid\n",
    "        FROM read_parquet('{PATHS['eric_wide']}')\n",
    "        WHERE otype = 'MaterialSampleRecord' \n",
    "          AND p__has_material_category IS NOT NULL\n",
    "    ),\n",
    "    concepts AS (\n",
    "        SELECT row_id, label\n",
    "        FROM read_parquet('{PATHS['eric_wide']}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "    )\n",
    "    SELECT c.label as material, COUNT(*) as cnt\n",
    "    FROM samples s\n",
    "    JOIN concepts c ON s.concept_rowid = c.row_id\n",
    "    GROUP BY c.label\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(eric_wide_facets.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO NARROW (full iSamples) ===\n",
      "Material facets: 743.0ms, 10 rows\n",
      "                                                                      material      cnt\n",
      "0               https://w3id.org/isample/vocabulary/material/1.0/earthmaterial  2261513\n",
      "1             https://w3id.org/isample/vocabulary/material/1.0/organicmaterial  1265560\n",
      "2                        https://w3id.org/isample/vocabulary/material/1.0/rock  1208585\n",
      "3  https://w3id.org/isample/vocabulary/material/1.0/biogenicnonorganicmaterial  1091781\n",
      "4       https://w3id.org/isample/vocabulary/material/1.0/mixedsoilsedimentrock   838805\n",
      "5                    https://w3id.org/isample/vocabulary/material/1.0/material   673018\n",
      "6                     https://w3id.org/isample/vocabulary/material/1.0/mineral   390797\n",
      "7          https://w3id.org/isample/vocabulary/material/1.0/anthropogenicmetal   270040\n",
      "8                https://w3id.org/isample/opencontext/material/0.1/ceramicclay   100573\n",
      "9                    https://w3id.org/isample/vocabulary/material/1.0/sediment    94084\n",
      "\n",
      "=== ERIC NARROW (OpenContext only) ===\n",
      "Material facets: 109.9ms, 10 rows\n",
      "                        material     cnt\n",
      "0  Biogenic non-organic material  532675\n",
      "1               Organic material  212584\n",
      "2                       Material  158586\n",
      "3   Other anthropogenic material  145316\n",
      "4                           Rock   30186\n",
      "5   Anthropogenic metal material   11659\n",
      "6    Mixed soil sediment or rock    3207\n",
      "7                        Mineral    2080\n",
      "8         Natural Solid Material      58\n",
      "9                       Sediment       1\n"
     ]
    }
   ],
   "source": [
    "# NARROW formats: Follow edges with predicate='has_material_category'\n",
    "# SQL Complexity: 2 CTEs, 1 JOIN - requires edge traversal\n",
    "print(\"=== ZENODO NARROW (full iSamples) ===\")\n",
    "zenodo_narrow_facets, zenodo_narrow_facets_time = timed_query(con, f\"\"\"\n",
    "    WITH edges AS (\n",
    "        SELECT s as sample_rowid, unnest(o) as concept_rowid\n",
    "        FROM read_parquet('{PATHS['zenodo_narrow']}')\n",
    "        WHERE otype = '_edge_' AND p = 'has_material_category'\n",
    "    ),\n",
    "    concepts AS (\n",
    "        SELECT row_id, label\n",
    "        FROM read_parquet('{PATHS['zenodo_narrow']}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "    )\n",
    "    SELECT c.label as material, COUNT(*) as cnt\n",
    "    FROM edges e\n",
    "    JOIN concepts c ON e.concept_rowid = c.row_id\n",
    "    GROUP BY c.label\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(zenodo_narrow_facets.to_string())\n",
    "\n",
    "print(\"\\n=== ERIC NARROW (OpenContext only) ===\")\n",
    "eric_narrow_facets, eric_narrow_facets_time = timed_query(con, f\"\"\"\n",
    "    WITH edges AS (\n",
    "        SELECT s as sample_rowid, unnest(o) as concept_rowid\n",
    "        FROM read_parquet('{PATHS['eric_narrow']}')\n",
    "        WHERE otype = '_edge_' AND p = 'has_material_category'\n",
    "    ),\n",
    "    concepts AS (\n",
    "        SELECT row_id, label\n",
    "        FROM read_parquet('{PATHS['eric_narrow']}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "    )\n",
    "    SELECT c.label as material, COUNT(*) as cnt\n",
    "    FROM edges e\n",
    "    JOIN concepts c ON e.concept_rowid = c.row_id\n",
    "    GROUP BY c.label\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(eric_narrow_facets.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FACET QUERY SUMMARY ===\n",
      "\n",
      "Full iSamples (apples-to-apples):\n",
      "  Export:         530.0ms (SQL: 1 subquery, 0 JOINs)\n",
      "  Zenodo Wide:    527.1ms (SQL: 2 CTEs, 1 JOIN)\n",
      "  Zenodo Narrow:  743.0ms (SQL: 2 CTEs, 1 JOIN)\n",
      "\n",
      "OpenContext only (Eric's files):\n",
      "  Eric Wide:      102.2ms\n",
      "  Eric Narrow:    109.9ms\n",
      "\n",
      "\ud83d\udca1 Key insight: Export is simplest (no JOINs), but PQG returns human-readable labels\n"
     ]
    }
   ],
   "source": [
    "# Facet query summary\n",
    "print(\"=== FACET QUERY SUMMARY ===\")\n",
    "print(\"\\nFull iSamples (apples-to-apples):\")\n",
    "print(f\"  Export:        {export_facets_time:6.1f}ms (SQL: 1 subquery, 0 JOINs)\")\n",
    "print(f\"  Zenodo Wide:   {zenodo_wide_facets_time:6.1f}ms (SQL: 2 CTEs, 1 JOIN)\")\n",
    "print(f\"  Zenodo Narrow: {zenodo_narrow_facets_time:6.1f}ms (SQL: 2 CTEs, 1 JOIN)\")\n",
    "\n",
    "print(\"\\nOpenContext only (Eric's files):\")\n",
    "print(f\"  Eric Wide:     {eric_wide_facets_time:6.1f}ms\")\n",
    "print(f\"  Eric Narrow:   {eric_narrow_facets_time:6.1f}ms\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Key insight: Export is simplest (no JOINs), but PQG returns human-readable labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Entity Listing: Get All Unique Agents\n",
    "\n",
    "**Use case**: Populate a dropdown, show \"who collected samples\"\n",
    "\n",
    "**Key tradeoff**: Export cannot do this efficiently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE (full iSamples) ===\n",
      "All agents: 20.3ms, 10 rows\n",
      "                       name        role  cnt\n",
      "0                      KUIT     curator    1\n",
      "1               Haddock Lab     curator    1\n",
      "2                      NMNZ     curator    1\n",
      "3                    VNM-ZI     curator    1\n",
      "4  Allegra Hosford Scheirer  registrant    1\n",
      "5             Andra Bobbitt  registrant    1\n",
      "6              Claude Payri  registrant    1\n",
      "7                      UWBM     curator    1\n",
      "8                      NSMT     curator    1\n",
      "9                        AC     curator    1\n",
      "\n",
      "=== ERIC WIDE (OpenContext only) ===\n",
      "All agents: 3.9ms, 10 rows\n",
      "                            name                                                                                                                                 role  cnt\n",
      "0                Arianne Boileau                                                                        Participated in: Household Zooarchaeology of Colonial Lamanai    2\n",
      "1                             LJ                                                                                      Participated in: Petra Great Temple Excavations    1\n",
      "2                   Bekir G\u00fcrdil                                                                                               Participated in: Domuztepe Excavations    1\n",
      "3                   Derek Counts  Participated in: Visualizing Votive Practice: Exploring Limestone and Terracotta Sculpture from Athienou-Malloura through 3D Models    1\n",
      "4                   Justin Walsh                                                                      Participated in: Archaeology of the International Space Station    1\n",
      "5                   Neill Wallis                                                                                              Participated in: Parnell Zooarchaeology    1\n",
      "6                 Lisa Kealhofer            Participated in: Differentiating local from nonlocal ceramic production at Late Bronze Age/Iron Age Kinet H\u00f6y\u00fck using NAA    1\n",
      "7  Guillermo L. Mengoni Go\u00f1alons                                                                     Participated in: Osteometric Database of South American Camelids    1\n",
      "8                  Kevin Garstki  Participated in: Visualizing Votive Practice: Exploring Limestone and Terracotta Sculpture from Athienou-Malloura through 3D Models    1\n",
      "9             Claire Christensen                                                                                           Participated in: \u00c7atalh\u00f6y\u00fck Zooarchaeology    1\n"
     ]
    }
   ],
   "source": [
    "# WIDE formats: Direct query on Agent rows\n",
    "# SQL Complexity: 0 CTEs, 0 JOINs - simple otype filter\n",
    "print(\"=== ZENODO WIDE (full iSamples) ===\")\n",
    "zenodo_wide_agents, zenodo_wide_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT name, role, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'Agent'\n",
    "    GROUP BY name, role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents\")\n",
    "print(zenodo_wide_agents.to_string())\n",
    "\n",
    "print(\"\\n=== ERIC WIDE (OpenContext only) ===\")\n",
    "eric_wide_agents, eric_wide_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT name, role, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    WHERE otype = 'Agent'\n",
    "    GROUP BY name, role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents\")\n",
    "print(eric_wide_agents.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO NARROW (full iSamples) ===\n",
      "All agents: 48.2ms, 10 rows\n",
      "                      name        role  cnt\n",
      "0           Christine Chan  registrant    1\n",
      "1       Alexandra Belinsky  registrant    1\n",
      "2            Nicolas Perez  registrant    1\n",
      "3              Jeffrey Alt  registrant    1\n",
      "4           Susan Brantley  registrant    1\n",
      "5         Sebastian Zapata  registrant    1\n",
      "6            Brady Foreman  registrant    1\n",
      "7            Takeshi Hanyu  registrant    1\n",
      "8  Sarah Penniston-Dorland  registrant    1\n",
      "9         Katherine Kelley  registrant    1\n",
      "\n",
      "=== ERIC NARROW (OpenContext only) ===\n",
      "All agents: 6.5ms, 10 rows\n",
      "                name                                                                            role  cnt\n",
      "0    Arianne Boileau                   Participated in: Household Zooarchaeology of Colonial Lamanai    2\n",
      "1        Peter Grave                                           Participated in: Asian Stoneware Jars    1\n",
      "2       Levent Atici                                Participated in: Zooarchaeology of Karain Cave B    1\n",
      "3  Gabriela Chapparo                      Participated in: Andean Geochemistry Visualization Project    1\n",
      "4    Jessica Pearson                                          Participated in: Domuztepe Excavations    1\n",
      "5    Jared W. Farley                                 Participated in: Petra Great Temple Excavations    1\n",
      "6    Chris Stevenson                      Participated in: Andean Geochemistry Visualization Project    1\n",
      "7      Martin Giesso                      Participated in: Andean Geochemistry Visualization Project    1\n",
      "8        Hakan Kaleh                                          Participated in: Domuztepe Excavations    1\n",
      "9  P. Nick Kardulias  Participated in: Pyla-Koutsopetria Archaeological Project I: Pedestrian Survey    1\n"
     ]
    }
   ],
   "source": [
    "# NARROW formats: Same approach - otype filter\n",
    "# SQL Complexity: 0 CTEs, 0 JOINs - simple otype filter\n",
    "print(\"=== ZENODO NARROW (full iSamples) ===\")\n",
    "zenodo_narrow_agents, zenodo_narrow_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT name, role, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['zenodo_narrow']}')\n",
    "    WHERE otype = 'Agent'\n",
    "    GROUP BY name, role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents\")\n",
    "print(zenodo_narrow_agents.to_string())\n",
    "\n",
    "print(\"\\n=== ERIC NARROW (OpenContext only) ===\")\n",
    "eric_narrow_agents, eric_narrow_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT name, role, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['eric_narrow']}')\n",
    "    WHERE otype = 'Agent'\n",
    "    GROUP BY name, role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents\")\n",
    "print(eric_narrow_agents.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT (full iSamples) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272abefaf79e449988138c8650977af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All agents (from nested): 3082.6ms, 10 rows\n",
      "                                                             name     role      cnt\n",
      "0                                              Curator,,Collector     None  3516917\n",
      "1  Curator Integrated Ocean Drilling Program (TAMU),,Sample Owner     None  3516905\n",
      "2                                       Adam Mansur,,Sample Owner     None   383835\n",
      "3                                    Edward Gilbert,,Sample Owner     None   258790\n",
      "4                                                     Emma Loftus  creator   161623\n",
      "5                                                 Robert L. Kelly  creator   161623\n",
      "6                                                     Lux Miranda  creator   161623\n",
      "7                                                 Eugenia M. Gayo  creator   161623\n",
      "8                                              Judson Byrd Finley  creator   161623\n",
      "9                                            Jade d\u2019Alpoim Guedes  creator   161623\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Must scan all samples and extract from nested structs\n",
    "# SQL Complexity: 1 subquery, 0 JOINs - but FULL TABLE SCAN required\n",
    "# This is MUCH slower because agents are embedded in every sample row\n",
    "print(\"=== EXPORT (full iSamples) ===\")\n",
    "export_agents, export_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT \n",
    "        resp.name as name,\n",
    "        resp.role as role,\n",
    "        COUNT(*) as cnt\n",
    "    FROM (\n",
    "        SELECT unnest(produced_by.responsibility) as resp\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE produced_by IS NOT NULL \n",
    "          AND produced_by.responsibility IS NOT NULL\n",
    "    )\n",
    "    GROUP BY resp.name, resp.role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents (from nested)\")\n",
    "print(export_agents.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTITY LISTING SUMMARY ===\n",
      "\n",
      "Full iSamples (apples-to-apples):\n",
      "  Zenodo Wide:     20.3ms (SQL: 0 JOINs, otype filter)\n",
      "  Zenodo Narrow:   48.2ms (SQL: 0 JOINs, otype filter)\n",
      "  Export:        3082.6ms (SQL: 0 JOINs, FULL SCAN)\n",
      "\n",
      "OpenContext only (Eric's files):\n",
      "  Eric Wide:        3.9ms\n",
      "  Eric Narrow:      6.5ms\n",
      "\n",
      "\u26a0\ufe0f Export is 10-100x SLOWER for entity listing!\n",
      "   Reason: Agents are embedded in every sample row, requiring full scan\n",
      "   PQG: Agents are separate rows, filtered by otype = 'Agent'\n"
     ]
    }
   ],
   "source": [
    "# Agent listing summary\n",
    "print(\"=== ENTITY LISTING SUMMARY ===\")\n",
    "print(\"\\nFull iSamples (apples-to-apples):\")\n",
    "print(f\"  Zenodo Wide:   {zenodo_wide_agents_time:6.1f}ms (SQL: 0 JOINs, otype filter)\")\n",
    "print(f\"  Zenodo Narrow: {zenodo_narrow_agents_time:6.1f}ms (SQL: 0 JOINs, otype filter)\")\n",
    "print(f\"  Export:        {export_agents_time:6.1f}ms (SQL: 0 JOINs, FULL SCAN)\")\n",
    "\n",
    "print(\"\\nOpenContext only (Eric's files):\")\n",
    "print(f\"  Eric Wide:     {eric_wide_agents_time:6.1f}ms\")\n",
    "print(f\"  Eric Narrow:   {eric_narrow_agents_time:6.1f}ms\")\n",
    "\n",
    "print(\"\\n\u26a0\ufe0f Export is 10-100x SLOWER for entity listing!\")\n",
    "print(\"   Reason: Agents are embedded in every sample row, requiring full scan\")\n",
    "print(\"   PQG: Agents are separate rows, filtered by otype = 'Agent'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Reverse Lookup: Samples by Agent\n",
    "\n",
    "**Use case**: \"Show me all samples collected by Agent X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for samples by: Vance Vredenburg\n"
     ]
    }
   ],
   "source": [
    "# First, pick an agent name that exists in all formats\n",
    "# Using a common agent from the data\n",
    "AGENT_NAME = 'Vance Vredenburg'  # Adjust based on your data\n",
    "\n",
    "print(f\"Looking for samples by: {AGENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT ===\n",
      "Samples by Vance Vredenburg: 198.2ms, 10 rows\n",
      "     sample_identifier label\n",
      "0   ark:/21547/DSz2757   757\n",
      "1   ark:/21547/DSz2779   779\n",
      "2   ark:/21547/DSz2806   806\n",
      "3   ark:/21547/DSz2807   807\n",
      "4   ark:/21547/DSz2759   759\n",
      "5   ark:/21547/DSz2761   761\n",
      "6   ark:/21547/DSz2967   967\n",
      "7   ark:/21547/DSz2763   763\n",
      "8   ark:/21547/DSz2979   979\n",
      "9  ark:/21547/DSz21792  1792\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Filter on nested struct\n",
    "print(\"=== EXPORT ===\")\n",
    "export_by_agent, export_time = timed_query(con, f\"\"\"\n",
    "    SELECT sample_identifier, label\n",
    "    FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE list_contains(\n",
    "        [r.name FOR r IN produced_by.responsibility],\n",
    "        '{AGENT_NAME}'\n",
    "    )\n",
    "    LIMIT 10\n",
    "\"\"\", f\"Samples by {AGENT_NAME}\")\n",
    "print(export_by_agent.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE (full iSamples) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb806536b4c144609b05ece2c70a048b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples by Vance Vredenburg: 6105.2ms, 10 rows\n",
      "     sample_identifier label\n",
      "0   ark:/21547/DSz2757   757\n",
      "1   ark:/21547/DSz2779   779\n",
      "2   ark:/21547/DSz2806   806\n",
      "3   ark:/21547/DSz2807   807\n",
      "4   ark:/21547/DSz2759   759\n",
      "5   ark:/21547/DSz2761   761\n",
      "6   ark:/21547/DSz2967   967\n",
      "7   ark:/21547/DSz2763   763\n",
      "8   ark:/21547/DSz2979   979\n",
      "9  ark:/21547/DSz21792  1792\n"
     ]
    }
   ],
   "source": [
    "# WIDE: Find agent row_id, then find samples with that row_id in p__responsibility\n",
    "# Note: Agent may not exist in Eric's OC-only data, so use Zenodo Wide for full coverage\n",
    "print(\"=== ZENODO WIDE (full iSamples) ===\")\n",
    "zenodo_wide_by_agent, zenodo_wide_by_agent_time = timed_query(con, f\"\"\"\n",
    "    WITH agent AS (\n",
    "        SELECT row_id \n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "        WHERE otype = 'Agent' AND name = '{AGENT_NAME}'\n",
    "        LIMIT 1\n",
    "    ),\n",
    "    events AS (\n",
    "        SELECT w.row_id as event_id\n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}') w, agent\n",
    "        WHERE w.otype = 'SamplingEvent' \n",
    "          AND list_contains(w.p__responsibility, agent.row_id)\n",
    "    )\n",
    "    SELECT s.sample_identifier, s.label\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}') s, events\n",
    "    WHERE s.otype = 'MaterialSampleRecord'\n",
    "      AND list_contains(s.p__produced_by, events.event_id)\n",
    "    LIMIT 10\n",
    "\"\"\", f\"Samples by {AGENT_NAME}\")\n",
    "print(zenodo_wide_by_agent.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REVERSE LOOKUP SUMMARY ===\n",
      "Export:      198.2ms (10 rows)\n",
      "Zenodo Wide: 6105.2ms (10 rows)\n",
      "\n",
      "Note: Export's nested list_contains is efficient for this pattern\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n=== REVERSE LOOKUP SUMMARY ===\")\n",
    "print(f\"Export:      {export_time:.1f}ms ({len(export_by_agent)} rows)\")\n",
    "print(f\"Zenodo Wide: {zenodo_wide_by_agent_time:.1f}ms ({len(zenodo_wide_by_agent)} rows)\")\n",
    "print(\"\\nNote: Export's nested list_contains is efficient for this pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Sample Detail: Get Full Info for One Sample\n",
    "\n",
    "**Use case**: User clicks on a sample, show all details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: ark:/21547/DSz2757\n"
     ]
    }
   ],
   "source": [
    "# Pick a sample identifier\n",
    "SAMPLE_ID = con.sql(f\"\"\"\n",
    "    SELECT sample_identifier FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE sample_identifier IS NOT NULL LIMIT 1\n",
    "\"\"\").fetchone()[0]\n",
    "print(f\"Sample: {SAMPLE_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT ===\n",
      "Time: 56.6ms\n",
      "Columns returned: 19\n",
      "                                                                           0\n",
      "sample_identifier                                         ark:/21547/DSz2757\n",
      "@id                                                   metadata/21547/DSz2757\n",
      "label                                                                    757\n",
      "description                                 basisOfRecord: PreservedSpecimen\n",
      "source_collection                                                      GEOME\n",
      "has_sample_object_type     [{'identifier': 'https://w3id.org/isample/voca...\n",
      "has_material_category      [{'identifier': 'https://w3id.org/isample/voca...\n",
      "has_context_category       [{'identifier': 'https://w3id.org/isample/biol...\n",
      "informal_classification                                 [Taricha, granulosa]\n",
      "keywords                     [{'keyword': 'California'}, {'keyword': 'USA'}]\n",
      "produced_by                {'description': 'expeditionCode: newts | proje...\n",
      "last_modified_time                                 1893-12-31 16:07:00-07:53\n",
      "curation                                                                <NA>\n",
      "registrant                                                              <NA>\n",
      "related_resource                                                        <NA>\n",
      "sampling_purpose                                                        <NA>\n",
      "sample_location_longitude                                         -122.57861\n",
      "sample_location_latitude                                           38.578888\n",
      "geometry                   [1, 1, 0, 0, 0, 222, 200, 60, 242, 7, 165, 94,...\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Everything on one row\n",
    "print(\"=== EXPORT ===\")\n",
    "start = time.time()\n",
    "result = con.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE sample_identifier = '{SAMPLE_ID}'\n",
    "\"\"\").fetchdf()\n",
    "export_time = (time.time() - start) * 1000\n",
    "print(f\"Time: {export_time:.1f}ms\")\n",
    "print(f\"Columns returned: {len(result.columns)}\")\n",
    "print(result.T)  # Transpose for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE ===\n",
      "Time: 29.5ms\n",
      "Rows returned: 1\n",
      "Columns returned: 49\n",
      "Note: This only returns the sample row, not related entities\n",
      "                                    0\n",
      "sample_identifier  ark:/21547/DSz2757\n",
      "label                             757\n"
     ]
    }
   ],
   "source": [
    "# ZENODO WIDE: Need to JOIN related entities\n",
    "print(\"=== ZENODO WIDE ===\")\n",
    "start = time.time()\n",
    "# This is more complex - would need multiple JOINs to get full picture\n",
    "result = con.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE sample_identifier = '{SAMPLE_ID}'\n",
    "\"\"\").fetchdf()\n",
    "zenodo_wide_detail_time = (time.time() - start) * 1000\n",
    "print(f\"Time: {zenodo_wide_detail_time:.1f}ms\")\n",
    "print(f\"Rows returned: {len(result)}\")\n",
    "if len(result) > 0:\n",
    "    print(f\"Columns returned: {len(result.columns)}\")\n",
    "    print(\"Note: This only returns the sample row, not related entities\")\n",
    "    print(result[['sample_identifier', 'label']].T)\n",
    "else:\n",
    "    print(\"Note: Sample not found (may be from GEOME source, not in this sample_identifier format)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Storage Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Data</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Bytes/Row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Export</td>\n",
       "      <td>Full</td>\n",
       "      <td>297.0</td>\n",
       "      <td>6,680,932</td>\n",
       "      <td>19</td>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zenodo Narrow</td>\n",
       "      <td>Full</td>\n",
       "      <td>860.1</td>\n",
       "      <td>101,387,180</td>\n",
       "      <td>40</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zenodo Wide</td>\n",
       "      <td>Full</td>\n",
       "      <td>291.8</td>\n",
       "      <td>20,729,358</td>\n",
       "      <td>49</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric Narrow</td>\n",
       "      <td>OC only</td>\n",
       "      <td>724.5</td>\n",
       "      <td>11,637,144</td>\n",
       "      <td>40</td>\n",
       "      <td>62.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Wide</td>\n",
       "      <td>OC only</td>\n",
       "      <td>288.7</td>\n",
       "      <td>2,464,690</td>\n",
       "      <td>47</td>\n",
       "      <td>117.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Format     Data Size (MB)         Rows  Columns Bytes/Row\n",
       "0         Export     Full     297.0    6,680,932       19      44.5\n",
       "1  Zenodo Narrow     Full     860.1  101,387,180       40       8.5\n",
       "2    Zenodo Wide     Full     291.8   20,729,358       49      14.1\n",
       "3    Eric Narrow  OC only     724.5   11,637,144       40      62.3\n",
       "4      Eric Wide  OC only     288.7    2,464,690       47     117.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File sizes and efficiency\n",
    "def get_file_size_mb(path):\n",
    "    \"\"\"Get file size - returns None for URLs (size unknown without HEAD request).\"\"\"\n",
    "    if path is None:\n",
    "        return None\n",
    "    if isinstance(path, str) and path.startswith('http'):\n",
    "        return None  # Can't easily get URL size\n",
    "    p = Path(path)\n",
    "    if p.exists():\n",
    "        return p.stat().st_size / 1e6\n",
    "    return None\n",
    "\n",
    "storage = []\n",
    "for name in ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        size_mb = get_file_size_mb(path)\n",
    "        rows = row_counts.get(name, 0)\n",
    "        cols = len(schemas.get(name, []))\n",
    "        bytes_per_row = (size_mb * 1e6) / rows if (size_mb and rows > 0) else None\n",
    "        data_scope = 'Full' if name in ['export', 'zenodo_narrow', 'zenodo_wide'] else 'OC only'\n",
    "        is_remote = isinstance(path, str) and path.startswith('http')\n",
    "        storage.append({\n",
    "            'Format': name.replace('_', ' ').title(),\n",
    "            'Data': data_scope,\n",
    "            'Size (MB)': f'{size_mb:.1f}' if size_mb else 'Remote',\n",
    "            'Rows': f'{rows:,}',\n",
    "            'Columns': cols,\n",
    "            'Bytes/Row': f'{bytes_per_row:.1f}' if bytes_per_row else 'N/A',\n",
    "        })\n",
    "\n",
    "pd.DataFrame(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Benchmark Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.827621Z",
     "iopub.status.busy": "2025-12-10T23:45:11.827559Z",
     "iopub.status.idle": "2025-12-10T23:45:11.830598Z",
     "shell.execute_reply": "2025-12-10T23:45:11.830215Z"
    }
   },
   "source": [
    "### Benchmark Results Summary\n",
    "\n",
    "**Data Coverage Verification:**\n",
    "- \u2705 Export, Zenodo Narrow, Zenodo Wide all contain **6,680,932 samples** from all 4 sources\n",
    "- \u2705 Eric's Narrow/Wide contain OpenContext subset (~1.1M samples)\n",
    "\n",
    "| Query Pattern | Best For | SQL Complexity | Notes |\n",
    "|--------------|----------|----------------|-------|\n",
    "| **Map (all coords)** | Export \u2248 Zenodo Wide | Simple SELECT | Both ~30ms for 6M points |\n",
    "| **Facets (material counts)** | Export | 1 subquery vs 2 CTEs + JOIN | Export has URIs, PQG has labels |\n",
    "| **Entity listing (agents)** | PQG formats | 0 JOINs (otype filter) | Export requires full scan |\n",
    "| **Reverse lookup by agent** | Export | list_contains() | Only works if agent exists |\n",
    "| **Sample detail (one row)** | Export | Simple WHERE | All data on single row |\n",
    "\n",
    "**Key tradeoffs:**\n",
    "- **Export**: Best for UI (map + facets + detail) but slow for entity listing\n",
    "- **PQG Wide**: Good balance - entities queryable, reasonable JOIN complexity\n",
    "- **PQG Narrow**: Most flexible but slower (92M rows including edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions: When to Use Each Format\n",
    "\n",
    "### Export Format\n",
    "**Best for:**\n",
    "- UI queries (map, search, facets)\n",
    "- Sample-centric analysis\n",
    "- When you don't need to query entities independently\n",
    "\n",
    "**Avoid when:**\n",
    "- You need to list all agents/sites/concepts\n",
    "- You need graph traversal flexibility\n",
    "- You need incremental updates\n",
    "\n",
    "### Wide Format\n",
    "**Best for:**\n",
    "- Entity-centric queries (\"all agents\", \"all sites\")\n",
    "- Analytical dashboards\n",
    "- When you need both samples AND other entity types\n",
    "\n",
    "**Avoid when:**\n",
    "- Pure sample queries (Export is faster)\n",
    "- Complex multi-hop traversals (Narrow is more natural)\n",
    "\n",
    "### Narrow Format\n",
    "**Best for:**\n",
    "- Archival/preservation (full fidelity)\n",
    "- Graph algorithms\n",
    "- Relationship exploration\n",
    "- When you need to traverse in any direction\n",
    "\n",
    "**Avoid when:**\n",
    "- Interactive UI (too slow)\n",
    "- Simple sample queries (overkill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights\n",
    "\n",
    "### What Export Gains\n",
    "1. **No JOINs** - Everything on one row\n",
    "2. **Pre-extracted coords** - `sample_location_latitude/longitude` at top level\n",
    "3. **Fewer rows** - 6.7M vs 19.5M vs 92M\n",
    "\n",
    "### What Export Loses\n",
    "1. **Entity independence** - Can't query agents without scanning all samples\n",
    "2. **Graph flexibility** - Can't traverse in arbitrary directions\n",
    "3. **Incremental updates** - Must regenerate entire file\n",
    "\n",
    "### The `list_contains()` Problem\n",
    "Both Wide (p__* arrays) and Export (nested structs) suffer from O(n) scans when searching within arrays. Neither has index support in DuckDB/Parquet.\n",
    "\n",
    "### Recommendation for Eric's UI\n",
    "For the iSamples Central UI requirements:\n",
    "- **Start with Export format** - fastest for map + facets + click-to-detail\n",
    "- **Pre-compute H3 aggregations** - for initial map render\n",
    "- **Pre-compute facet counts** - avoid runtime aggregation\n",
    "- **Keep Wide/Narrow for advanced queries** - entity exploration, graph traversal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization with Lonboard\n",
    "\n",
    "Now let's visualize the coordinate data we queried earlier using **Lonboard** - a high-performance WebGL-based mapping library for Jupyter.\n",
    "\n",
    "**Key considerations for 6M+ points:**\n",
    "- Use sampling to avoid memory issues\n",
    "- Color by source collection for insight\n",
    "- Compare visualization speed across formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Lonboard available for visualization\n"
     ]
    }
   ],
   "source": [
    "# Import visualization libraries\n",
    "try:\n",
    "    from lonboard import Map, ScatterplotLayer\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    import numpy as np\n",
    "    LONBOARD_AVAILABLE = True\n",
    "    print(\"\u2705 Lonboard available for visualization\")\n",
    "except ImportError as e:\n",
    "    LONBOARD_AVAILABLE = False\n",
    "    print(f\"\u26a0\ufe0f Lonboard not available: {e}\")\n",
    "    print(\"   Install with: pip install lonboard geopandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying 50,000 random samples from Export format...\n",
      "Query time: 56.5ms, 44,872 points\n",
      "\n",
      "Sample distribution by source:\n",
      "source_collection\n",
      "SESAR          31734\n",
      "OPENCONTEXT     8593\n",
      "GEOME           3324\n",
      "SMITHSONIAN     1221\n"
     ]
    }
   ],
   "source": [
    "# Visualize a sample of points from EXPORT format (includes source_collection for coloring)\n",
    "if LONBOARD_AVAILABLE:\n",
    "    SAMPLE_SIZE = 50000  # Adjust based on your system's memory\n",
    "    \n",
    "    print(f\"Querying {SAMPLE_SIZE:,} random samples from Export format...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Export has source_collection and pre-extracted coords - ideal for visualization\n",
    "    viz_data = con.sql(f\"\"\"\n",
    "        SELECT \n",
    "            sample_location_longitude as lon,\n",
    "            sample_location_latitude as lat,\n",
    "            source_collection,\n",
    "            sample_identifier\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE sample_location_latitude IS NOT NULL\n",
    "        USING SAMPLE {SAMPLE_SIZE}\n",
    "    \"\"\").fetchdf()\n",
    "    \n",
    "    query_time = (time.time() - start) * 1000\n",
    "    print(f\"Query time: {query_time:.1f}ms, {len(viz_data):,} points\")\n",
    "    \n",
    "    # Show distribution by source\n",
    "    print(\"\\nSample distribution by source:\")\n",
    "    print(viz_data['source_collection'].value_counts().to_string())\n",
    "else:\n",
    "    print(\"Skipping visualization (Lonboard not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\uddfa\ufe0f Visualizing 44,872 points colored by source:\n",
      "   SESAR: 31,734 points\n",
      "   OPENCONTEXT: 8,593 points\n",
      "   GEOME: 3,324 points\n",
      "   SMITHSONIAN: 1,221 points\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c904a7530e77402bac9284ddab9d042c",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(custom_attribution='', layers=(ScatterplotLayer(get_fill_color=arro3.core.ChunkedArray<FixedSizeList(Field\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the Lonboard visualization with color by source collection\n",
    "if LONBOARD_AVAILABLE and len(viz_data) > 0:\n",
    "    from IPython.display import display\n",
    "    \n",
    "    # Define colors for each source collection\n",
    "    SOURCE_COLORS = {\n",
    "        'SESAR': [255, 99, 71, 200],      # Tomato red\n",
    "        'OPENCONTEXT': [65, 105, 225, 200], # Royal blue  \n",
    "        'GEOME': [50, 205, 50, 200],       # Lime green\n",
    "        'SMITHSONIAN': [255, 215, 0, 200], # Gold\n",
    "    }\n",
    "    DEFAULT_COLOR = [128, 128, 128, 200]  # Gray for unknown\n",
    "    \n",
    "    # Create geometry from coordinates\n",
    "    geometry = gpd.points_from_xy(viz_data['lon'], viz_data['lat'])\n",
    "    gdf = gpd.GeoDataFrame(viz_data, geometry=geometry, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Create color array (RGBA as uint8)\n",
    "    colors = np.array([\n",
    "        SOURCE_COLORS.get(src, DEFAULT_COLOR) \n",
    "        for src in viz_data['source_collection']\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    # Create ScatterplotLayer\n",
    "    layer = ScatterplotLayer.from_geopandas(\n",
    "        gdf,\n",
    "        get_fill_color=colors,\n",
    "        get_radius=3000,  # meters\n",
    "        radius_min_pixels=2,\n",
    "        radius_max_pixels=10,\n",
    "        opacity=0.8,\n",
    "        pickable=True,\n",
    "    )\n",
    "    \n",
    "    # Create map\n",
    "    m = Map(layer)\n",
    "    \n",
    "    print(f\"\ud83d\uddfa\ufe0f Visualizing {len(gdf):,} points colored by source:\")\n",
    "    for src, color in SOURCE_COLORS.items():\n",
    "        count = (viz_data['source_collection'] == src).sum()\n",
    "        if count > 0:\n",
    "            print(f\"   {src}: {count:,} points\")\n",
    "    \n",
    "    # Display the map explicitly\n",
    "    display(m)\n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Visualizing from Wide Format\n",
    "\n",
    "The PQG Wide format stores coordinates in `GeospatialCoordLocation` rows with `otype` filter.\n",
    "The `n` column contains the source collection (named graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying 50,000 samples from Wide format...\n",
      "Query time: 166.9ms, 12,579 points\n",
      "\n",
      "\ud83d\uddfa\ufe0f Wide format: 12,579 points\n",
      "source_collection\n",
      "SESAR          9247\n",
      "OPENCONTEXT    2219\n",
      "GEOME           605\n",
      "SMITHSONIAN     508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1f8af097214f7490d42cc94dfb23fa",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(custom_attribution='', layers=(ScatterplotLayer(get_fill_color=arro3.core.ChunkedArray<FixedSizeList(Field\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize from WIDE format (uses `n` column for source, `otype` for filtering)\n",
    "if LONBOARD_AVAILABLE:\n",
    "    from IPython.display import display\n",
    "    \n",
    "    print(f\"Querying {SAMPLE_SIZE:,} samples from Wide format...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Wide format uses `n` for named graph (source collection) and otype filter\n",
    "    wide_viz_data = con.sql(f\"\"\"\n",
    "        SELECT \n",
    "            longitude as lon,\n",
    "            latitude as lat,\n",
    "            n as source_collection,  -- Named graph contains source\n",
    "            pid as sample_identifier\n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "        WHERE otype = 'GeospatialCoordLocation' \n",
    "          AND latitude IS NOT NULL\n",
    "        USING SAMPLE {SAMPLE_SIZE}\n",
    "    \"\"\").fetchdf()\n",
    "    \n",
    "    query_time = (time.time() - start) * 1000\n",
    "    print(f\"Query time: {query_time:.1f}ms, {len(wide_viz_data):,} points\")\n",
    "    \n",
    "    # Create geometry and colors\n",
    "    geometry = gpd.points_from_xy(wide_viz_data['lon'], wide_viz_data['lat'])\n",
    "    wide_gdf = gpd.GeoDataFrame(wide_viz_data, geometry=geometry, crs=\"EPSG:4326\")\n",
    "    \n",
    "    colors = np.array([\n",
    "        SOURCE_COLORS.get(src, DEFAULT_COLOR) \n",
    "        for src in wide_viz_data['source_collection']\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    # Create layer and map\n",
    "    wide_layer = ScatterplotLayer.from_geopandas(\n",
    "        wide_gdf,\n",
    "        get_fill_color=colors,\n",
    "        get_radius=3000,\n",
    "        radius_min_pixels=2,\n",
    "        radius_max_pixels=10,\n",
    "        opacity=0.8,\n",
    "        pickable=True,\n",
    "    )\n",
    "    \n",
    "    wide_map = Map(wide_layer)\n",
    "    \n",
    "    print(f\"\\n\ud83d\uddfa\ufe0f Wide format: {len(wide_gdf):,} points\")\n",
    "    print(wide_viz_data['source_collection'].value_counts().to_string())\n",
    "    \n",
    "    # Display the map explicitly\n",
    "    display(wide_map)\n",
    "else:\n",
    "    print(\"Skipping (Lonboard not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Visualization Tips\n",
    "\n",
    "**Memory Management for 6M+ Points:**\n",
    "- Use `USING SAMPLE N` to limit points (shown above)\n",
    "- Or use `LIMIT` with `ORDER BY RANDOM()` for reproducible sampling\n",
    "- For full dataset: consider H3 hexbin aggregation first\n",
    "\n",
    "**Format Comparison for Visualization:**\n",
    "\n",
    "| Format | Query | Source Color | Notes |\n",
    "|--------|-------|--------------|-------|\n",
    "| **Export** | Direct `lat/lon` columns | `source_collection` | Fastest, simplest |\n",
    "| **Wide** | Filter `otype='GeospatialCoordLocation'` | `n` (named graph) | Slightly slower |\n",
    "| **Narrow** | Same as Wide | Same as Wide | Slowest (most rows) |\n",
    "\n",
    "**Color Scheme Used:**\n",
    "- \ud83d\udd34 SESAR (geological): Tomato red\n",
    "- \ud83d\udd35 OPENCONTEXT (archaeological): Royal blue  \n",
    "- \ud83d\udfe2 GEOME (biological): Lime green\n",
    "- \ud83d\udfe1 SMITHSONIAN (museum): Gold\n",
    "\n",
    "**Next Steps:**\n",
    "- See `geoparquet.ipynb` for more advanced memory-efficient strategies\n",
    "- See `isample-archive.ipynb` for remote parquet visualization patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Browser Visualization with Cesium\n",
    "\n",
    "For web-based 3D globe visualization, use **CesiumJS** with **DuckDB-WASM**. This enables:\n",
    "- No server required - runs entirely in browser\n",
    "- 3D globe with terrain\n",
    "- Click-to-query sample details\n",
    "- Works with remote parquet files via HTTP range requests\n",
    "\n",
    "**Reference implementations:**\n",
    "- `isamplesorg.github.io/tutorials/parquet_cesium_isamples_wide.qmd` - Quarto tutorial with live demo\n",
    "- Remote parquet URLs work directly in browser:\n",
    "  ```javascript\n",
    "  const db = await AsyncDuckDB.create();\n",
    "  await db.open({path: ':memory:'});\n",
    "  const result = await db.query(`\n",
    "    SELECT latitude, longitude, pid\n",
    "    FROM read_parquet('https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202601_wide.parquet')\n",
    "    WHERE otype = 'GeospatialCoordLocation'\n",
    "    LIMIT 10000\n",
    "  `);\n",
    "  ```\n",
    "\n",
    "**Lonboard vs Cesium:**\n",
    "\n",
    "| Feature | Lonboard (Jupyter) | Cesium (Browser) |\n",
    "|---------|-------------------|------------------|\n",
    "| Environment | Jupyter notebooks | Web pages/Quarto |\n",
    "| Rendering | 2D WebGL | 3D Globe |\n",
    "| Best for | Data exploration | Public demos |\n",
    "| Max points | ~500K comfortable | ~100K with clustering |\n",
    "| Interactivity | Pan/zoom, hover | Click, terrain, 3D |"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Focus Sites: PKAP and Poggio Civitate\n\nTo make the 6M+ sample dataset more tangible, let's explore two well-documented OpenContext archaeological sites:\n\n| Site | Location | Coordinates | Scale |\n|------|----------|-------------|-------|\n| **PKAP** | Pyla-Koutsopetria, Cyprus | 34.99\u00b0N, 33.71\u00b0E | 544 locations, 15K+ events |\n| **Poggio Civitate** | Murlo, Tuscany, Italy | 43.15\u00b0N, 11.40\u00b0E | 11K+ locations, 30K events |\n\nThese sites demonstrate:\n- How coordinates cluster around archaeological excavations\n- The relationship between samples, events, and locations\n- Real-world query patterns for site-specific analysis",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Define focus sites\nFOCUS_SITES = {\n    'PKAP': {\n        'name': 'Pyla-Koutsopetria Archaeological Project',\n        'location': 'Cyprus',\n        'lat': 34.987406,\n        'lon': 33.708047,\n        'radius_deg': 0.05,  # ~5km bounding box\n    },\n    'Poggio': {\n        'name': 'Poggio Civitate',\n        'location': 'Murlo, Tuscany, Italy', \n        'lat': 43.15,\n        'lon': 11.40,\n        'radius_deg': 0.1,  # ~10km bounding box\n    }\n}\n\ndef get_site_bbox(site):\n    \"\"\"Get bounding box for a focus site.\"\"\"\n    return {\n        'min_lat': site['lat'] - site['radius_deg'],\n        'max_lat': site['lat'] + site['radius_deg'],\n        'min_lon': site['lon'] - site['radius_deg'],\n        'max_lon': site['lon'] + site['radius_deg'],\n    }\n\n# Display site info\nfor key, site in FOCUS_SITES.items():\n    bbox = get_site_bbox(site)\n    print(f\"\ud83d\udccd {key}: {site['name']}\")\n    print(f\"   Location: {site['location']}\")\n    print(f\"   Center: {site['lat']:.4f}\u00b0N, {site['lon']:.4f}\u00b0E\")\n    print(f\"   Bbox: [{bbox['min_lat']:.2f}, {bbox['min_lon']:.2f}] to [{bbox['max_lat']:.2f}, {bbox['max_lon']:.2f}]\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 11.1 Query Site Data from Export Format\n\nThe Export format makes spatial queries simple - just filter on lat/lon columns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Query samples from each focus site using Export format\nsite_data = {}\n\nfor key, site in FOCUS_SITES.items():\n    bbox = get_site_bbox(site)\n    \n    print(f\"=== {key}: {site['name']} ===\")\n    start = time.time()\n    \n    df = con.sql(f\"\"\"\n        SELECT \n            sample_identifier,\n            label,\n            sample_location_latitude as lat,\n            sample_location_longitude as lon,\n            source_collection\n        FROM read_parquet('{PATHS['export']}')\n        WHERE sample_location_latitude BETWEEN {bbox['min_lat']} AND {bbox['max_lat']}\n          AND sample_location_longitude BETWEEN {bbox['min_lon']} AND {bbox['max_lon']}\n    \"\"\").fetchdf()\n    \n    elapsed = (time.time() - start) * 1000\n    site_data[key] = df\n    \n    print(f\"Found {len(df):,} samples in {elapsed:.1f}ms\")\n    print(f\"Coordinate range: [{df['lat'].min():.4f}, {df['lon'].min():.4f}] to [{df['lat'].max():.4f}, {df['lon'].max():.4f}]\")\n    print(f\"Unique locations: {df.groupby(['lat', 'lon']).ngroups:,}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 11.2 Visualize PKAP (Cyprus)\n\nZoomed view of the Pyla-Koutsopetria Archaeological Project survey area.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualize PKAP site\nif LONBOARD_AVAILABLE and 'PKAP' in site_data and len(site_data['PKAP']) > 0:\n    from IPython.display import display\n    \n    pkap_df = site_data['PKAP']\n    site = FOCUS_SITES['PKAP']\n    \n    # Create geometry\n    geometry = gpd.points_from_xy(pkap_df['lon'], pkap_df['lat'])\n    pkap_gdf = gpd.GeoDataFrame(pkap_df, geometry=geometry, crs=\"EPSG:4326\")\n    \n    # Single color for site-specific view (blue)\n    colors = np.full((len(pkap_gdf), 4), [65, 105, 225, 200], dtype=np.uint8)\n    \n    # Create layer\n    pkap_layer = ScatterplotLayer.from_geopandas(\n        pkap_gdf,\n        get_fill_color=colors,\n        get_radius=50,  # smaller radius for zoomed view\n        radius_min_pixels=3,\n        radius_max_pixels=8,\n        opacity=0.8,\n        pickable=True,\n    )\n    \n    # Create map centered on site\n    pkap_map = Map(pkap_layer)\n    pkap_map.set_view_state(latitude=site['lat'], longitude=site['lon'], zoom=14)\n    \n    print(f\"\ud83d\uddfa\ufe0f PKAP: {len(pkap_gdf):,} samples at {pkap_gdf.groupby(['lat', 'lon']).ngroups:,} unique locations\")\n    print(f\"   Center: {site['lat']:.4f}\u00b0N, {site['lon']:.4f}\u00b0E\")\n    \n    display(pkap_map)\nelse:\n    print(\"PKAP data not available or Lonboard not installed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 11.3 Visualize Poggio Civitate (Tuscany)\n\nZoomed view of the Poggio Civitate excavation site in Murlo, Italy.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualize Poggio Civitate site\nif LONBOARD_AVAILABLE and 'Poggio' in site_data and len(site_data['Poggio']) > 0:\n    from IPython.display import display\n    \n    poggio_df = site_data['Poggio']\n    site = FOCUS_SITES['Poggio']\n    \n    # Create geometry\n    geometry = gpd.points_from_xy(poggio_df['lon'], poggio_df['lat'])\n    poggio_gdf = gpd.GeoDataFrame(poggio_df, geometry=geometry, crs=\"EPSG:4326\")\n    \n    # Single color for site-specific view (tomato red)\n    colors = np.full((len(poggio_gdf), 4), [255, 99, 71, 200], dtype=np.uint8)\n    \n    # Create layer\n    poggio_layer = ScatterplotLayer.from_geopandas(\n        poggio_gdf,\n        get_fill_color=colors,\n        get_radius=20,  # even smaller for dense site\n        radius_min_pixels=2,\n        radius_max_pixels=6,\n        opacity=0.7,\n        pickable=True,\n    )\n    \n    # Create map centered on site\n    poggio_map = Map(poggio_layer)\n    poggio_map.set_view_state(latitude=site['lat'], longitude=site['lon'], zoom=15)\n    \n    print(f\"\ud83d\uddfa\ufe0f Poggio Civitate: {len(poggio_gdf):,} samples at {poggio_gdf.groupby(['lat', 'lon']).ngroups:,} unique locations\")\n    print(f\"   Center: {site['lat']:.4f}\u00b0N, {site['lon']:.4f}\u00b0E\")\n    \n    display(poggio_map)\nelse:\n    print(\"Poggio Civitate data not available or Lonboard not installed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 11.4 Site-Specific Material Analysis\n\nWhat materials were found at each site? This demonstrates practical site-level queries.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Material categories at each site\n# Load official iSamples vocabulary labels from material_hierarchy.json\n# Source: https://github.com/isamplesorg/isamples_inabox/blob/develop/isb_web/static/controlled_vocabulary/material_hierarchy.json\n\nimport json\nfrom pathlib import Path\n\nVOCAB_PATH = Path.home() / 'C/src/iSamples/isamples_inabox/isb_web/static/controlled_vocabulary/material_hierarchy.json'\n\ndef extract_labels_from_hierarchy(node, result=None):\n    \"\"\"Recursively extract URI -> label mappings from vocabulary hierarchy.\"\"\"\n    if result is None:\n        result = {}\n    \n    for uri, data in node.items():\n        if isinstance(data, dict):\n            if 'label' in data and 'en' in data['label']:\n                # Store both 0.9 and 1.0 versions (data uses 1.0)\n                uri_1_0 = uri.replace('/0.9/', '/1.0/')\n                result[uri_1_0] = data['label']['en']\n                result[uri] = data['label']['en']\n            if 'children' in data:\n                for child in data['children']:\n                    extract_labels_from_hierarchy(child, result)\n    return result\n\n# Load vocabulary and build lookup\nif VOCAB_PATH.exists():\n    with open(VOCAB_PATH) as f:\n        vocab_hierarchy = json.load(f)\n    URI_TO_LABEL = extract_labels_from_hierarchy(vocab_hierarchy)\n    print(f\"Loaded {len(URI_TO_LABEL)} material labels from vocabulary file\")\nelse:\n    print(f\"\u26a0\ufe0f Vocabulary file not found: {VOCAB_PATH}\")\n    URI_TO_LABEL = {}\n\ndef get_material_label(uri):\n    \"\"\"Get human-readable label for a material URI.\"\"\"\n    return URI_TO_LABEL.get(uri, uri.split('/')[-1])\n\n# Query and display materials for each site\nfor key, site in FOCUS_SITES.items():\n    bbox = get_site_bbox(site)\n    \n    print(f\"\\n=== {key}: Material Categories ===\")\n    \n    result = con.sql(f\"\"\"\n        SELECT \n            mat.identifier as uri,\n            COUNT(*) as cnt\n        FROM (\n            SELECT unnest(has_material_category) as mat\n            FROM read_parquet('{PATHS['export']}')\n            WHERE sample_location_latitude BETWEEN {bbox['min_lat']} AND {bbox['max_lat']}\n              AND sample_location_longitude BETWEEN {bbox['min_lon']} AND {bbox['max_lon']}\n              AND has_material_category IS NOT NULL\n        )\n        GROUP BY mat.identifier\n        ORDER BY cnt DESC\n        LIMIT 8\n    \"\"\").fetchdf()\n    \n    # Add friendly label from vocabulary\n    result['material'] = result['uri'].apply(get_material_label)\n    \n    # Display with friendly labels\n    print(result[['material', 'cnt']].to_string())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 11.5 Data Format Question: Should PQG Include Labels?\n\n**Current state:**\n- **Export format**: `has_material_category` only contains `identifier` (URI), no label\n- **Zenodo Wide/Narrow**: `IdentifiedConcept.label` = URI (not human-readable)\n- **Eric's Wide**: `IdentifiedConcept.label` = human-readable (vocabulary lookup applied)\n\n**The question:** Should Zenodo Wide/Narrow `IdentifiedConcept` rows include:\n1. Just the URI (current) - requires external vocabulary lookup\n2. Just the label - loses precise identifier\n3. Both URI and label - redundant but self-contained\n\n**Tradeoffs:**\n\n| Approach | File Size | Query Simplicity | Vocabulary Updates |\n|----------|-----------|------------------|-------------------|\n| URI only | Smaller | Need JOIN to vocab | Easy to re-label |\n| Label only | Smaller | Direct display | Stuck with old labels |\n| Both | Larger | Best of both | Must regenerate |\n\n**Recommendation:** Include both `pid` (URI) and `label` (human-readable) in `IdentifiedConcept` rows. The ~50K concept rows are tiny compared to 6M+ samples, so the size increase is negligible.\n\n**Vocabulary source:** \n- Local: `~/C/src/iSamples/isamples_inabox/isb_web/static/controlled_vocabulary/material_hierarchy.json`\n- GitHub: https://github.com/isamplesorg/isamples_inabox/blob/develop/isb_web/static/controlled_vocabulary/material_hierarchy.json",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isamples-python-3.12.9",
   "language": "python",
   "name": "isamples-python-3.12.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
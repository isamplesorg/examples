{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# iSamples Parquet Schema Comparison\n\n**Goal**: Understand the tradeoffs among five parquet formats for iSamples data.\n\n| Format | Philosophy | Sources | Relationships |\n|--------|-----------|---------|---------------|\n| **Export** | Sample-centric (flat) | All 4 sources | Nested STRUCTs |\n| **Zenodo Narrow** | Graph (nodes + edges) | All 4 sources | Separate `_edge_` rows |\n| **Zenodo Wide** | Entity-centric | All 4 sources | `p__*` arrays ‚Üí row_ids |\n| **Eric's Narrow** | Graph (nodes + edges) | OpenContext only | Separate `_edge_` rows |\n| **Eric's Wide** | Entity-centric | OpenContext only | `p__*` arrays ‚Üí row_ids |\n\n**Key insight**: There is no universal best format. Each optimizes for different query patterns.\n\n---\n\n## Portability\n\nThis notebook works in multiple environments:\n\n| Environment | Behavior |\n|-------------|----------|\n| **Raymond's laptop** | Uses local files in `~/Data/iSample/` |\n| **mybinder.org** | Downloads to `/tmp/pqgfiles/` cache |\n| **Other users** | Downloads to `~/Data/iSample/pqg_cache/` |\n\n**Configuration options** (in cell 2):\n- `CACHE_DIR`: Override with `ISAMPLES_CACHE_DIR` env var\n- `USE_REMOTE=True`: Skip downloads, query remote parquet via HTTP (slower but no disk)\n- `DOWNLOAD_MISSING=False`: Error instead of downloading missing files\n\n---\n\n## Data Source Coverage\n\n| Format | Sources | Description |\n|--------|---------|-------------|\n| **Export, Zenodo Narrow, Zenodo Wide** | SESAR, OpenContext, GEOME, Smithsonian | Full iSamples (~6.7M samples) |\n| **Eric's Narrow, Eric's Wide** | OpenContext only | Subset (~1.1M samples) |\n\nThis allows fair comparisons:\n- **Apples-to-apples**: Export vs Zenodo Narrow vs Zenodo Wide (same data)\n- **Structure comparison**: Eric's Narrow vs Eric's Wide (same data, different structure)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:10.888629Z",
     "iopub.status.busy": "2025-12-10T23:45:10.888344Z",
     "iopub.status.idle": "2025-12-10T23:45:11.133849Z",
     "shell.execute_reply": "2025-12-10T23:45:11.133351Z"
    }
   },
   "outputs": [],
   "source": "import duckdb\nimport pandas as pd\nimport time\nimport os\nimport urllib.request\nfrom pathlib import Path\n\n# =============================================================================\n# CONFIGURATION - Edit these paths for your environment\n# =============================================================================\n\n# Cache directory for downloaded files (used when local paths don't exist)\n# - On mybinder.org: uses /tmp/pqgfiles\n# - Locally: uses ~/Data/iSample/pqg_cache (or override with ISAMPLES_CACHE_DIR env var)\nCACHE_DIR = Path(os.environ.get('ISAMPLES_CACHE_DIR', \n                                '/tmp/pqgfiles' if Path('/tmp').exists() and not Path.home().joinpath('Data/iSample').exists()\n                                else Path.home() / 'Data/iSample/pqg_cache'))\n\n# Local paths (Raymond's setup) - these are checked first\nLOCAL_PATHS = {\n    'export': Path.home() / 'Data/iSample/2025_04_21_16_23_46/isamples_export_2025_04_21_16_23_46_geo.parquet',\n    'zenodo_narrow': Path.home() / 'Data/iSample/pqg_refining/zenodo_narrow_strict.parquet',\n    'zenodo_wide': Path.home() / 'Data/iSample/pqg_refining/zenodo_wide_strict.parquet',\n    'eric_narrow': Path.home() / 'Data/iSample/pqg_refining/oc_isamples_pqg.parquet',\n    'eric_wide': Path.home() / 'Data/iSample/pqg_refining/oc_isamples_pqg_wide.parquet',\n}\n\n# Remote URLs - fallback when local files don't exist\nURLS = {\n    'export': 'https://zenodo.org/records/15278211/files/isamples_export_2025_04_21_16_23_46_geo.parquet',\n    'zenodo_narrow': 'https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202512_narrow.parquet',\n    'zenodo_wide': 'https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202512_wide.parquet',\n    'eric_narrow': 'https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg.parquet',\n    'eric_wide': 'https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg_wide.parquet',\n}\n\n# =============================================================================\n# PATH RESOLUTION - Automatically finds or downloads files\n# =============================================================================\n\ndef resolve_path(name: str, local_paths: dict, urls: dict, cache_dir: Path, \n                 download: bool = True, use_remote: bool = False) -> Path:\n    \"\"\"\n    Resolve file path: check local first, then cache, optionally download.\n    \n    Args:\n        name: File identifier (e.g., 'export', 'zenodo_wide')\n        local_paths: Dict of local file paths to check first\n        urls: Dict of remote URLs for downloading\n        cache_dir: Directory for cached downloads\n        download: If True, download missing files to cache\n        use_remote: If True, return URL for DuckDB remote access (no download)\n    \n    Returns:\n        Path to local file, or URL string if use_remote=True\n    \"\"\"\n    # Option 1: Local file exists\n    if name in local_paths and local_paths[name].exists():\n        return local_paths[name]\n    \n    # Option 2: Return URL for remote access (DuckDB can read directly)\n    if use_remote and name in urls:\n        return urls[name]\n    \n    # Option 3: Check cache\n    cache_dir.mkdir(parents=True, exist_ok=True)\n    cached_file = cache_dir / f\"{name}.parquet\"\n    \n    if cached_file.exists():\n        return cached_file\n    \n    # Option 4: Download to cache\n    if download and name in urls:\n        url = urls[name]\n        print(f\"Downloading {name} from {url}...\")\n        print(f\"  -> {cached_file}\")\n        \n        # Download with progress\n        def progress_hook(block_num, block_size, total_size):\n            downloaded = block_num * block_size\n            if total_size > 0:\n                pct = min(100, downloaded * 100 // total_size)\n                mb = downloaded / 1e6\n                total_mb = total_size / 1e6\n                print(f\"\\r  Progress: {pct}% ({mb:.1f}/{total_mb:.1f} MB)\", end='', flush=True)\n        \n        urllib.request.urlretrieve(url, cached_file, reporthook=progress_hook)\n        print()  # newline after progress\n        return cached_file\n    \n    # No file available\n    raise FileNotFoundError(f\"File '{name}' not found locally and download=False\")\n\n# =============================================================================\n# RESOLVE ALL PATHS\n# =============================================================================\n\n# Set to True to skip downloads and use DuckDB's remote parquet reading\n# (Slower queries but no disk usage - good for quick exploration)\nUSE_REMOTE = False\n\n# Set to False to skip downloading missing files (will error if not found)\nDOWNLOAD_MISSING = True\n\nprint(f\"Cache directory: {CACHE_DIR}\")\nprint(f\"Use remote: {USE_REMOTE}, Download missing: {DOWNLOAD_MISSING}\\n\")\n\nPATHS = {}\nfor name in ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n    try:\n        path = resolve_path(name, LOCAL_PATHS, URLS, CACHE_DIR, \n                           download=DOWNLOAD_MISSING, use_remote=USE_REMOTE)\n        PATHS[name] = path\n    except FileNotFoundError as e:\n        print(f\"‚ö†Ô∏è {name}: {e}\")\n        PATHS[name] = None\n\n# =============================================================================\n# VERIFY FILES\n# =============================================================================\n\ndef get_file_info(path):\n    \"\"\"Get file info - works for both local paths and URLs.\"\"\"\n    if path is None:\n        return '‚ùå', 'Not available'\n    if isinstance(path, str) and path.startswith('http'):\n        return 'üåê', 'Remote URL'\n    if Path(path).exists():\n        size_mb = Path(path).stat().st_size / 1e6\n        return '‚úÖ', f'{size_mb:.1f} MB'\n    return '‚ùå', 'Not found'\n\nprint(\"=== Full iSamples (all sources) ===\")\nfor name in ['export', 'zenodo_narrow', 'zenodo_wide']:\n    status, info = get_file_info(PATHS.get(name))\n    source = \"local\" if PATHS.get(name) and Path(PATHS[name]).exists() and PATHS[name] in LOCAL_PATHS.values() else \"cache/remote\"\n    print(f'{status} {name}: {info} ({source})')\n\nprint(\"\\n=== OpenContext only (Eric's) ===\")\nfor name in ['eric_narrow', 'eric_wide']:\n    status, info = get_file_info(PATHS.get(name))\n    source = \"local\" if PATHS.get(name) and Path(PATHS[name]).exists() and PATHS[name] in LOCAL_PATHS.values() else \"cache/remote\"\n    print(f'{status} {name}: {info} ({source})')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.151015Z",
     "iopub.status.busy": "2025-12-10T23:45:11.150860Z",
     "iopub.status.idle": "2025-12-10T23:45:11.157067Z",
     "shell.execute_reply": "2025-12-10T23:45:11.156589Z"
    }
   },
   "outputs": [],
   "source": "# Helper functions for timing queries\nimport statistics\n\ndef timed_query(con, sql, name=\"Query\"):\n    \"\"\"Execute query and return (result_df, elapsed_ms)\"\"\"\n    start = time.time()\n    result = con.sql(sql).fetchdf()\n    elapsed = (time.time() - start) * 1000\n    print(f\"{name}: {elapsed:.1f}ms, {len(result):,} rows\")\n    return result, elapsed\n\ndef timed_query_multirun(con, sql, name=\"Query\", runs=3):\n    \"\"\"Execute query multiple times and return (result_df, mean_ms, stddev_ms)\"\"\"\n    times = []\n    result = None\n    for i in range(runs):\n        start = time.time()\n        result = con.sql(sql).fetchdf()\n        elapsed = (time.time() - start) * 1000\n        times.append(elapsed)\n    \n    mean_ms = statistics.mean(times)\n    stddev_ms = statistics.stdev(times) if len(times) > 1 else 0\n    print(f\"{name}: {mean_ms:.1f}ms ¬± {stddev_ms:.1f}ms (n={runs}), {len(result):,} rows\")\n    return result, mean_ms, stddev_ms\n\n# Create connection\ncon = duckdb.connect()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema Inspection\n",
    "\n",
    "Understanding what columns exist and their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.158207Z",
     "iopub.status.busy": "2025-12-10T23:45:11.158122Z",
     "iopub.status.idle": "2025-12-10T23:45:11.171153Z",
     "shell.execute_reply": "2025-12-10T23:45:11.170720Z"
    }
   },
   "outputs": [],
   "source": "# Helper to check if path is available (works for Path objects and URL strings)\ndef path_available(path):\n    \"\"\"Check if a path is available (local file exists or is a URL).\"\"\"\n    if path is None:\n        return False\n    if isinstance(path, str) and path.startswith('http'):\n        return True  # URLs are assumed available\n    return Path(path).exists()\n\n# Get schema for each format\nschemas = {}\nfor name, path in PATHS.items():\n    if path_available(path):\n        result = con.sql(f\"DESCRIBE SELECT * FROM read_parquet('{path}')\").fetchdf()\n        schemas[name] = result\n        print(f\"\\n=== {name.upper()} ({len(result)} columns) ===\")\n        # Show just first 15 columns to keep output manageable\n        print(result[['column_name', 'column_type']].head(15).to_string())\n        if len(result) > 15:\n            print(f\"  ... and {len(result) - 15} more columns\")\n    else:\n        print(f\"\\n=== {name.upper()} ===\")\n        print(f\"  ‚ö†Ô∏è Not available\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.172399Z",
     "iopub.status.busy": "2025-12-10T23:45:11.172310Z",
     "iopub.status.idle": "2025-12-10T23:45:11.177814Z",
     "shell.execute_reply": "2025-12-10T23:45:11.177402Z"
    }
   },
   "outputs": [],
   "source": "# Compare column counts and key structural differences (computed from schemas)\ndef check_schema_features(schema_df):\n    \"\"\"Analyze schema DataFrame for structural features.\"\"\"\n    if schema_df is None or len(schema_df) == 0:\n        return {'columns': 0, 'has_edge_cols': False, 'has_p__cols': False, \n                'has_nested_structs': False, 'has_otype': False}\n    \n    cols = set(schema_df['column_name'].tolist())\n    types = dict(zip(schema_df['column_name'], schema_df['column_type']))\n    \n    return {\n        'columns': len(schema_df),\n        'has_edge_cols': all(c in cols for c in ['s', 'p', 'o']),\n        'has_p__cols': any(c.startswith('p__') for c in cols),\n        'has_nested_structs': any('STRUCT' in str(t) for t in types.values()),\n        'has_otype': 'otype' in cols,\n    }\n\n# Compute features for each format\nformat_order = ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']\nfeatures = {name: check_schema_features(schemas.get(name)) for name in format_order}\n\n# Build comparison table\ncomparison = pd.DataFrame([\n    {\n        'Format': name.replace('_', ' ').title(),\n        'Data': 'Full' if name in ['export', 'zenodo_narrow', 'zenodo_wide'] else 'OC only',\n        'Columns': features[name]['columns'],\n        'Edge cols (s,p,o)': '‚úì' if features[name]['has_edge_cols'] else '',\n        'p__* cols': '‚úì' if features[name]['has_p__cols'] else '',\n        'Nested STRUCTs': '‚úì' if features[name]['has_nested_structs'] else '',\n        'otype col': '‚úì' if features[name]['has_otype'] else '',\n    }\n    for name in format_order\n])\ncomparison"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Row Count Analysis\n",
    "\n",
    "Understanding what's IN each format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.179074Z",
     "iopub.status.busy": "2025-12-10T23:45:11.179001Z",
     "iopub.status.idle": "2025-12-10T23:45:11.186249Z",
     "shell.execute_reply": "2025-12-10T23:45:11.185789Z"
    }
   },
   "outputs": [],
   "source": "# Total row counts\nrow_counts = {}\nprint(\"=== Full iSamples ===\")\nfor name in ['export', 'zenodo_narrow', 'zenodo_wide']:\n    path = PATHS.get(name)\n    if path_available(path):\n        count = con.sql(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n        row_counts[name] = count\n        print(f\"{name}: {count:,} rows\")\n    else:\n        print(f\"{name}: ‚ö†Ô∏è Not available\")\n\nprint(\"\\n=== OpenContext only ===\")\nfor name in ['eric_narrow', 'eric_wide']:\n    path = PATHS.get(name)\n    if path_available(path):\n        count = con.sql(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n        row_counts[name] = count\n        print(f\"{name}: {count:,} rows\")\n    else:\n        print(f\"{name}: ‚ö†Ô∏è Not available\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.187296Z",
     "iopub.status.busy": "2025-12-10T23:45:11.187222Z",
     "iopub.status.idle": "2025-12-10T23:45:11.199303Z",
     "shell.execute_reply": "2025-12-10T23:45:11.198885Z"
    }
   },
   "outputs": [],
   "source": "# For PQG formats: breakdown by otype\nfor name in ['zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n    path = PATHS.get(name)\n    if path_available(path):\n        print(f\"=== {name.upper()}: Rows by otype ===\")\n        result = con.sql(f\"\"\"\n            SELECT otype, COUNT(*) as cnt \n            FROM read_parquet('{path}')\n            GROUP BY otype ORDER BY cnt DESC\n        \"\"\").fetchdf()\n        print(result.to_string())\n        print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.200281Z",
     "iopub.status.busy": "2025-12-10T23:45:11.200202Z",
     "iopub.status.idle": "2025-12-10T23:45:11.205691Z",
     "shell.execute_reply": "2025-12-10T23:45:11.205372Z"
    }
   },
   "outputs": [],
   "source": "# For Export: breakdown by source_collection\nprint(\"=== EXPORT: Rows by source_collection ===\")\nif path_available(PATHS.get('export')):\n    result = con.sql(f\"\"\"\n        SELECT source_collection, COUNT(*) as cnt \n        FROM read_parquet('{PATHS['export']}')\n        GROUP BY source_collection ORDER BY cnt DESC\n    \"\"\").fetchdf()\n    print(result.to_string())\nelse:\n    print(\"‚ö†Ô∏è Export file not available\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Benchmark Suite\n",
    "\n",
    "Testing common query patterns across all three formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Map Visualization: Get All Coordinates\n",
    "\n",
    "**Use case**: Render points on a Cesium/Leaflet map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.206860Z",
     "iopub.status.busy": "2025-12-10T23:45:11.206798Z",
     "iopub.status.idle": "2025-12-10T23:45:11.240540Z",
     "shell.execute_reply": "2025-12-10T23:45:11.240132Z"
    }
   },
   "outputs": [],
   "source": "# EXPORT: Direct column access\nprint(\"=== EXPORT (full iSamples) ===\")\nexport_coords, export_coords_time = timed_query(con, f\"\"\"\n    SELECT sample_location_latitude as lat, sample_location_longitude as lon\n    FROM read_parquet('{PATHS['export']}')\n    WHERE sample_location_latitude IS NOT NULL\n\"\"\", \"All coordinates\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.241717Z",
     "iopub.status.busy": "2025-12-10T23:45:11.241637Z",
     "iopub.status.idle": "2025-12-10T23:45:11.248245Z",
     "shell.execute_reply": "2025-12-10T23:45:11.247816Z"
    }
   },
   "outputs": [],
   "source": "# WIDE formats: Filter by otype\nprint(\"=== ZENODO WIDE (full iSamples) ===\")\nzenodo_wide_coords, zenodo_wide_coords_time = timed_query(con, f\"\"\"\n    SELECT latitude as lat, longitude as lon\n    FROM read_parquet('{PATHS['zenodo_wide']}')\n    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n\"\"\", \"All coordinates\")\n\nprint(\"\\n=== ERIC WIDE (OpenContext only) ===\")\neric_wide_coords, eric_wide_coords_time = timed_query(con, f\"\"\"\n    SELECT latitude as lat, longitude as lon\n    FROM read_parquet('{PATHS['eric_wide']}')\n    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n\"\"\", \"All coordinates\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.249433Z",
     "iopub.status.busy": "2025-12-10T23:45:11.249354Z",
     "iopub.status.idle": "2025-12-10T23:45:11.257702Z",
     "shell.execute_reply": "2025-12-10T23:45:11.257186Z"
    }
   },
   "outputs": [],
   "source": "# NARROW formats: Filter by otype  \nprint(\"=== ZENODO NARROW (full iSamples) ===\")\nzenodo_narrow_coords, zenodo_narrow_coords_time = timed_query(con, f\"\"\"\n    SELECT latitude as lat, longitude as lon\n    FROM read_parquet('{PATHS['zenodo_narrow']}')\n    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n\"\"\", \"All coordinates\")\n\nprint(\"\\n=== ERIC NARROW (OpenContext only) ===\")\neric_narrow_coords, eric_narrow_coords_time = timed_query(con, f\"\"\"\n    SELECT latitude as lat, longitude as lon\n    FROM read_parquet('{PATHS['eric_narrow']}')\n    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n\"\"\", \"All coordinates\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.259002Z",
     "iopub.status.busy": "2025-12-10T23:45:11.258921Z",
     "iopub.status.idle": "2025-12-10T23:45:11.261451Z",
     "shell.execute_reply": "2025-12-10T23:45:11.260913Z"
    }
   },
   "outputs": [],
   "source": "# Summary - Map query comparison\nprint(\"=== MAP QUERY SUMMARY ===\")\nprint(\"\\nFull iSamples (apples-to-apples comparison):\")\nprint(f\"  Export:        {export_coords_time:6.1f}ms ({len(export_coords):,} points)\")\nprint(f\"  Zenodo Wide:   {zenodo_wide_coords_time:6.1f}ms ({len(zenodo_wide_coords):,} points)\")\nprint(f\"  Zenodo Narrow: {zenodo_narrow_coords_time:6.1f}ms ({len(zenodo_narrow_coords):,} points)\")\n\nprint(\"\\nOpenContext only (Eric's files):\")\nprint(f\"  Eric Wide:     {eric_wide_coords_time:6.1f}ms ({len(eric_wide_coords):,} points)\")\nprint(f\"  Eric Narrow:   {eric_narrow_coords_time:6.1f}ms ({len(eric_narrow_coords):,} points)\")\n\nprint(\"\\nüí° Key insight: Export returns coords directly; PQG formats need otype filter\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Faceted Search: Count by Material Category\n",
    "\n",
    "**Use case**: Show facet counts in a search UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.262918Z",
     "iopub.status.busy": "2025-12-10T23:45:11.262807Z",
     "iopub.status.idle": "2025-12-10T23:45:11.329272Z",
     "shell.execute_reply": "2025-12-10T23:45:11.328833Z"
    }
   },
   "outputs": [],
   "source": "# EXPORT: Unnest nested struct array\n# SQL Complexity: 1 subquery, 0 JOINs - simple unnest\nprint(\"=== EXPORT (full iSamples) ===\")\nexport_facets, export_facets_time = timed_query(con, f\"\"\"\n    SELECT \n        mat.identifier as material,\n        COUNT(*) as cnt\n    FROM (\n        SELECT unnest(has_material_category) as mat\n        FROM read_parquet('{PATHS['export']}')\n        WHERE has_material_category IS NOT NULL AND len(has_material_category) > 0\n    )\n    GROUP BY mat.identifier\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"Material facets\")\nprint(export_facets.to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.330572Z",
     "iopub.status.busy": "2025-12-10T23:45:11.330487Z",
     "iopub.status.idle": "2025-12-10T23:45:11.363583Z",
     "shell.execute_reply": "2025-12-10T23:45:11.363199Z"
    }
   },
   "outputs": [],
   "source": "# WIDE formats: JOIN via p__has_material_category\n# SQL Complexity: 2 CTEs, 1 JOIN - requires row_id lookup\nprint(\"=== ZENODO WIDE (full iSamples) ===\")\nzenodo_wide_facets, zenodo_wide_facets_time = timed_query(con, f\"\"\"\n    WITH samples AS (\n        SELECT unnest(p__has_material_category) as concept_rowid\n        FROM read_parquet('{PATHS['zenodo_wide']}')\n        WHERE otype = 'MaterialSampleRecord' \n          AND p__has_material_category IS NOT NULL\n    ),\n    concepts AS (\n        SELECT row_id, label\n        FROM read_parquet('{PATHS['zenodo_wide']}')\n        WHERE otype = 'IdentifiedConcept'\n    )\n    SELECT c.label as material, COUNT(*) as cnt\n    FROM samples s\n    JOIN concepts c ON s.concept_rowid = c.row_id\n    GROUP BY c.label\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"Material facets\")\nprint(zenodo_wide_facets.to_string())\n\nprint(\"\\n=== ERIC WIDE (OpenContext only) ===\")\neric_wide_facets, eric_wide_facets_time = timed_query(con, f\"\"\"\n    WITH samples AS (\n        SELECT unnest(p__has_material_category) as concept_rowid\n        FROM read_parquet('{PATHS['eric_wide']}')\n        WHERE otype = 'MaterialSampleRecord' \n          AND p__has_material_category IS NOT NULL\n    ),\n    concepts AS (\n        SELECT row_id, label\n        FROM read_parquet('{PATHS['eric_wide']}')\n        WHERE otype = 'IdentifiedConcept'\n    )\n    SELECT c.label as material, COUNT(*) as cnt\n    FROM samples s\n    JOIN concepts c ON s.concept_rowid = c.row_id\n    GROUP BY c.label\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"Material facets\")\nprint(eric_wide_facets.to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.364866Z",
     "iopub.status.busy": "2025-12-10T23:45:11.364763Z",
     "iopub.status.idle": "2025-12-10T23:45:11.403796Z",
     "shell.execute_reply": "2025-12-10T23:45:11.403278Z"
    }
   },
   "outputs": [],
   "source": "# NARROW formats: Follow edges with predicate='has_material_category'\n# SQL Complexity: 2 CTEs, 1 JOIN - requires edge traversal\nprint(\"=== ZENODO NARROW (full iSamples) ===\")\nzenodo_narrow_facets, zenodo_narrow_facets_time = timed_query(con, f\"\"\"\n    WITH edges AS (\n        SELECT s as sample_rowid, unnest(o) as concept_rowid\n        FROM read_parquet('{PATHS['zenodo_narrow']}')\n        WHERE otype = '_edge_' AND p = 'has_material_category'\n    ),\n    concepts AS (\n        SELECT row_id, label\n        FROM read_parquet('{PATHS['zenodo_narrow']}')\n        WHERE otype = 'IdentifiedConcept'\n    )\n    SELECT c.label as material, COUNT(*) as cnt\n    FROM edges e\n    JOIN concepts c ON e.concept_rowid = c.row_id\n    GROUP BY c.label\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"Material facets\")\nprint(zenodo_narrow_facets.to_string())\n\nprint(\"\\n=== ERIC NARROW (OpenContext only) ===\")\neric_narrow_facets, eric_narrow_facets_time = timed_query(con, f\"\"\"\n    WITH edges AS (\n        SELECT s as sample_rowid, unnest(o) as concept_rowid\n        FROM read_parquet('{PATHS['eric_narrow']}')\n        WHERE otype = '_edge_' AND p = 'has_material_category'\n    ),\n    concepts AS (\n        SELECT row_id, label\n        FROM read_parquet('{PATHS['eric_narrow']}')\n        WHERE otype = 'IdentifiedConcept'\n    )\n    SELECT c.label as material, COUNT(*) as cnt\n    FROM edges e\n    JOIN concepts c ON e.concept_rowid = c.row_id\n    GROUP BY c.label\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"Material facets\")\nprint(eric_narrow_facets.to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.404925Z",
     "iopub.status.busy": "2025-12-10T23:45:11.404833Z",
     "iopub.status.idle": "2025-12-10T23:45:11.406725Z",
     "shell.execute_reply": "2025-12-10T23:45:11.406347Z"
    }
   },
   "outputs": [],
   "source": "# Facet query summary\nprint(\"=== FACET QUERY SUMMARY ===\")\nprint(\"\\nFull iSamples (apples-to-apples):\")\nprint(f\"  Export:        {export_facets_time:6.1f}ms (SQL: 1 subquery, 0 JOINs)\")\nprint(f\"  Zenodo Wide:   {zenodo_wide_facets_time:6.1f}ms (SQL: 2 CTEs, 1 JOIN)\")\nprint(f\"  Zenodo Narrow: {zenodo_narrow_facets_time:6.1f}ms (SQL: 2 CTEs, 1 JOIN)\")\n\nprint(\"\\nOpenContext only (Eric's files):\")\nprint(f\"  Eric Wide:     {eric_wide_facets_time:6.1f}ms\")\nprint(f\"  Eric Narrow:   {eric_narrow_facets_time:6.1f}ms\")\n\nprint(\"\\nüí° Key insight: Export is simplest (no JOINs), but PQG returns human-readable labels\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Entity Listing: Get All Unique Agents\n",
    "\n",
    "**Use case**: Populate a dropdown, show \"who collected samples\"\n",
    "\n",
    "**Key tradeoff**: Export cannot do this efficiently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.407947Z",
     "iopub.status.busy": "2025-12-10T23:45:11.407863Z",
     "iopub.status.idle": "2025-12-10T23:45:11.413783Z",
     "shell.execute_reply": "2025-12-10T23:45:11.413303Z"
    }
   },
   "outputs": [],
   "source": "# WIDE formats: Direct query on Agent rows\n# SQL Complexity: 0 CTEs, 0 JOINs - simple otype filter\nprint(\"=== ZENODO WIDE (full iSamples) ===\")\nzenodo_wide_agents, zenodo_wide_agents_time = timed_query(con, f\"\"\"\n    SELECT name, role, COUNT(*) as cnt\n    FROM read_parquet('{PATHS['zenodo_wide']}')\n    WHERE otype = 'Agent'\n    GROUP BY name, role\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"All agents\")\nprint(zenodo_wide_agents.to_string())\n\nprint(\"\\n=== ERIC WIDE (OpenContext only) ===\")\neric_wide_agents, eric_wide_agents_time = timed_query(con, f\"\"\"\n    SELECT name, role, COUNT(*) as cnt\n    FROM read_parquet('{PATHS['eric_wide']}')\n    WHERE otype = 'Agent'\n    GROUP BY name, role\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"All agents\")\nprint(eric_wide_agents.to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.414826Z",
     "iopub.status.busy": "2025-12-10T23:45:11.414747Z",
     "iopub.status.idle": "2025-12-10T23:45:11.421931Z",
     "shell.execute_reply": "2025-12-10T23:45:11.421512Z"
    }
   },
   "outputs": [],
   "source": "# NARROW formats: Same approach - otype filter\n# SQL Complexity: 0 CTEs, 0 JOINs - simple otype filter\nprint(\"=== ZENODO NARROW (full iSamples) ===\")\nzenodo_narrow_agents, zenodo_narrow_agents_time = timed_query(con, f\"\"\"\n    SELECT name, role, COUNT(*) as cnt\n    FROM read_parquet('{PATHS['zenodo_narrow']}')\n    WHERE otype = 'Agent'\n    GROUP BY name, role\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"All agents\")\nprint(zenodo_narrow_agents.to_string())\n\nprint(\"\\n=== ERIC NARROW (OpenContext only) ===\")\neric_narrow_agents, eric_narrow_agents_time = timed_query(con, f\"\"\"\n    SELECT name, role, COUNT(*) as cnt\n    FROM read_parquet('{PATHS['eric_narrow']}')\n    WHERE otype = 'Agent'\n    GROUP BY name, role\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"All agents\")\nprint(eric_narrow_agents.to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.422884Z",
     "iopub.status.busy": "2025-12-10T23:45:11.422821Z",
     "iopub.status.idle": "2025-12-10T23:45:11.697699Z",
     "shell.execute_reply": "2025-12-10T23:45:11.697230Z"
    }
   },
   "outputs": [],
   "source": "# EXPORT: Must scan all samples and extract from nested structs\n# SQL Complexity: 1 subquery, 0 JOINs - but FULL TABLE SCAN required\n# This is MUCH slower because agents are embedded in every sample row\nprint(\"=== EXPORT (full iSamples) ===\")\nexport_agents, export_agents_time = timed_query(con, f\"\"\"\n    SELECT \n        resp.name as name,\n        resp.role as role,\n        COUNT(*) as cnt\n    FROM (\n        SELECT unnest(produced_by.responsibility) as resp\n        FROM read_parquet('{PATHS['export']}')\n        WHERE produced_by IS NOT NULL \n          AND produced_by.responsibility IS NOT NULL\n    )\n    GROUP BY resp.name, resp.role\n    ORDER BY cnt DESC\n    LIMIT 10\n\"\"\", \"All agents (from nested)\")\nprint(export_agents.to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.698993Z",
     "iopub.status.busy": "2025-12-10T23:45:11.698898Z",
     "iopub.status.idle": "2025-12-10T23:45:11.700794Z",
     "shell.execute_reply": "2025-12-10T23:45:11.700446Z"
    }
   },
   "outputs": [],
   "source": "# Agent listing summary\nprint(\"=== ENTITY LISTING SUMMARY ===\")\nprint(\"\\nFull iSamples (apples-to-apples):\")\nprint(f\"  Zenodo Wide:   {zenodo_wide_agents_time:6.1f}ms (SQL: 0 JOINs, otype filter)\")\nprint(f\"  Zenodo Narrow: {zenodo_narrow_agents_time:6.1f}ms (SQL: 0 JOINs, otype filter)\")\nprint(f\"  Export:        {export_agents_time:6.1f}ms (SQL: 0 JOINs, FULL SCAN)\")\n\nprint(\"\\nOpenContext only (Eric's files):\")\nprint(f\"  Eric Wide:     {eric_wide_agents_time:6.1f}ms\")\nprint(f\"  Eric Narrow:   {eric_narrow_agents_time:6.1f}ms\")\n\nprint(\"\\n‚ö†Ô∏è Export is 10-100x SLOWER for entity listing!\")\nprint(\"   Reason: Agents are embedded in every sample row, requiring full scan\")\nprint(\"   PQG: Agents are separate rows, filtered by otype = 'Agent'\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Reverse Lookup: Samples by Agent\n",
    "\n",
    "**Use case**: \"Show me all samples collected by Agent X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.702007Z",
     "iopub.status.busy": "2025-12-10T23:45:11.701910Z",
     "iopub.status.idle": "2025-12-10T23:45:11.703788Z",
     "shell.execute_reply": "2025-12-10T23:45:11.703373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for samples by: Vance Vredenburg\n"
     ]
    }
   ],
   "source": [
    "# First, pick an agent name that exists in all formats\n",
    "# Using a common agent from the data\n",
    "AGENT_NAME = 'Vance Vredenburg'  # Adjust based on your data\n",
    "\n",
    "print(f\"Looking for samples by: {AGENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.704776Z",
     "iopub.status.busy": "2025-12-10T23:45:11.704686Z",
     "iopub.status.idle": "2025-12-10T23:45:11.712057Z",
     "shell.execute_reply": "2025-12-10T23:45:11.711703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT ===\n",
      "Samples by Vance Vredenburg: 4.9ms, 10 rows\n",
      "     sample_identifier label\n",
      "0   ark:/21547/DSz2757   757\n",
      "1   ark:/21547/DSz2779   779\n",
      "2   ark:/21547/DSz2806   806\n",
      "3   ark:/21547/DSz2807   807\n",
      "4   ark:/21547/DSz2759   759\n",
      "5   ark:/21547/DSz2761   761\n",
      "6   ark:/21547/DSz2967   967\n",
      "7   ark:/21547/DSz2763   763\n",
      "8   ark:/21547/DSz2979   979\n",
      "9  ark:/21547/DSz21792  1792\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Filter on nested struct\n",
    "print(\"=== EXPORT ===\")\n",
    "export_by_agent, export_time = timed_query(con, f\"\"\"\n",
    "    SELECT sample_identifier, label\n",
    "    FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE list_contains(\n",
    "        [r.name FOR r IN produced_by.responsibility],\n",
    "        '{AGENT_NAME}'\n",
    "    )\n",
    "    LIMIT 10\n",
    "\"\"\", f\"Samples by {AGENT_NAME}\")\n",
    "print(export_by_agent.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.713408Z",
     "iopub.status.busy": "2025-12-10T23:45:11.713327Z",
     "iopub.status.idle": "2025-12-10T23:45:11.733963Z",
     "shell.execute_reply": "2025-12-10T23:45:11.733516Z"
    }
   },
   "outputs": [],
   "source": "# WIDE: Find agent row_id, then find samples with that row_id in p__responsibility\n# Note: Agent may not exist in Eric's OC-only data, so use Zenodo Wide for full coverage\nprint(\"=== ZENODO WIDE (full iSamples) ===\")\nzenodo_wide_by_agent, zenodo_wide_by_agent_time = timed_query(con, f\"\"\"\n    WITH agent AS (\n        SELECT row_id \n        FROM read_parquet('{PATHS['zenodo_wide']}')\n        WHERE otype = 'Agent' AND name = '{AGENT_NAME}'\n        LIMIT 1\n    ),\n    events AS (\n        SELECT w.row_id as event_id\n        FROM read_parquet('{PATHS['zenodo_wide']}') w, agent\n        WHERE w.otype = 'SamplingEvent' \n          AND list_contains(w.p__responsibility, agent.row_id)\n    )\n    SELECT s.sample_identifier, s.label\n    FROM read_parquet('{PATHS['zenodo_wide']}') s, events\n    WHERE s.otype = 'MaterialSampleRecord'\n      AND list_contains(s.p__produced_by, events.event_id)\n    LIMIT 10\n\"\"\", f\"Samples by {AGENT_NAME}\")\nprint(zenodo_wide_by_agent.to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.735128Z",
     "iopub.status.busy": "2025-12-10T23:45:11.735045Z",
     "iopub.status.idle": "2025-12-10T23:45:11.736880Z",
     "shell.execute_reply": "2025-12-10T23:45:11.736562Z"
    }
   },
   "outputs": [],
   "source": "# Summary\nprint(\"\\n=== REVERSE LOOKUP SUMMARY ===\")\nprint(f\"Export:      {export_time:.1f}ms ({len(export_by_agent)} rows)\")\nprint(f\"Zenodo Wide: {zenodo_wide_by_agent_time:.1f}ms ({len(zenodo_wide_by_agent)} rows)\")\nprint(\"\\nNote: Export's nested list_contains is efficient for this pattern\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Sample Detail: Get Full Info for One Sample\n",
    "\n",
    "**Use case**: User clicks on a sample, show all details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.737872Z",
     "iopub.status.busy": "2025-12-10T23:45:11.737789Z",
     "iopub.status.idle": "2025-12-10T23:45:11.741371Z",
     "shell.execute_reply": "2025-12-10T23:45:11.741047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: ark:/21547/DSz2757\n"
     ]
    }
   ],
   "source": [
    "# Pick a sample identifier\n",
    "SAMPLE_ID = con.sql(f\"\"\"\n",
    "    SELECT sample_identifier FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE sample_identifier IS NOT NULL LIMIT 1\n",
    "\"\"\").fetchone()[0]\n",
    "print(f\"Sample: {SAMPLE_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.742451Z",
     "iopub.status.busy": "2025-12-10T23:45:11.742381Z",
     "iopub.status.idle": "2025-12-10T23:45:11.809093Z",
     "shell.execute_reply": "2025-12-10T23:45:11.808643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT ===\n",
      "Time: 61.9ms\n",
      "Columns returned: 19\n",
      "                                                                           0\n",
      "sample_identifier                                         ark:/21547/DSz2757\n",
      "@id                                                   metadata/21547/DSz2757\n",
      "label                                                                    757\n",
      "description                                 basisOfRecord: PreservedSpecimen\n",
      "source_collection                                                      GEOME\n",
      "has_sample_object_type     [{'identifier': 'https://w3id.org/isample/voca...\n",
      "has_material_category      [{'identifier': 'https://w3id.org/isample/voca...\n",
      "has_context_category       [{'identifier': 'https://w3id.org/isample/biol...\n",
      "informal_classification                                 [Taricha, granulosa]\n",
      "keywords                     [{'keyword': 'California'}, {'keyword': 'USA'}]\n",
      "produced_by                {'description': 'expeditionCode: newts | proje...\n",
      "last_modified_time                                 1893-12-31 16:07:00-07:53\n",
      "curation                                                                <NA>\n",
      "registrant                                                              <NA>\n",
      "related_resource                                                        <NA>\n",
      "sampling_purpose                                                        <NA>\n",
      "sample_location_longitude                                         -122.57861\n",
      "sample_location_latitude                                           38.578888\n",
      "geometry                   [1, 1, 0, 0, 0, 222, 200, 60, 242, 7, 165, 94,...\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Everything on one row\n",
    "print(\"=== EXPORT ===\")\n",
    "start = time.time()\n",
    "result = con.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE sample_identifier = '{SAMPLE_ID}'\n",
    "\"\"\").fetchdf()\n",
    "export_time = (time.time() - start) * 1000\n",
    "print(f\"Time: {export_time:.1f}ms\")\n",
    "print(f\"Columns returned: {len(result.columns)}\")\n",
    "print(result.T)  # Transpose for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.810427Z",
     "iopub.status.busy": "2025-12-10T23:45:11.810335Z",
     "iopub.status.idle": "2025-12-10T23:45:11.821352Z",
     "shell.execute_reply": "2025-12-10T23:45:11.820926Z"
    }
   },
   "outputs": [],
   "source": "# ZENODO WIDE: Need to JOIN related entities\nprint(\"=== ZENODO WIDE ===\")\nstart = time.time()\n# This is more complex - would need multiple JOINs to get full picture\nresult = con.sql(f\"\"\"\n    SELECT *\n    FROM read_parquet('{PATHS['zenodo_wide']}')\n    WHERE sample_identifier = '{SAMPLE_ID}'\n\"\"\").fetchdf()\nzenodo_wide_detail_time = (time.time() - start) * 1000\nprint(f\"Time: {zenodo_wide_detail_time:.1f}ms\")\nprint(f\"Rows returned: {len(result)}\")\nif len(result) > 0:\n    print(f\"Columns returned: {len(result.columns)}\")\n    print(\"Note: This only returns the sample row, not related entities\")\n    print(result[['sample_identifier', 'label']].T)\nelse:\n    print(\"Note: Sample not found (may be from GEOME source, not in this sample_identifier format)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Storage Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.822451Z",
     "iopub.status.busy": "2025-12-10T23:45:11.822376Z",
     "iopub.status.idle": "2025-12-10T23:45:11.826639Z",
     "shell.execute_reply": "2025-12-10T23:45:11.826318Z"
    }
   },
   "outputs": [],
   "source": "# File sizes and efficiency\ndef get_file_size_mb(path):\n    \"\"\"Get file size - returns None for URLs (size unknown without HEAD request).\"\"\"\n    if path is None:\n        return None\n    if isinstance(path, str) and path.startswith('http'):\n        return None  # Can't easily get URL size\n    p = Path(path)\n    if p.exists():\n        return p.stat().st_size / 1e6\n    return None\n\nstorage = []\nfor name in ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n    path = PATHS.get(name)\n    if path_available(path):\n        size_mb = get_file_size_mb(path)\n        rows = row_counts.get(name, 0)\n        cols = len(schemas.get(name, []))\n        bytes_per_row = (size_mb * 1e6) / rows if (size_mb and rows > 0) else None\n        data_scope = 'Full' if name in ['export', 'zenodo_narrow', 'zenodo_wide'] else 'OC only'\n        is_remote = isinstance(path, str) and path.startswith('http')\n        storage.append({\n            'Format': name.replace('_', ' ').title(),\n            'Data': data_scope,\n            'Size (MB)': f'{size_mb:.1f}' if size_mb else 'Remote',\n            'Rows': f'{rows:,}',\n            'Columns': cols,\n            'Bytes/Row': f'{bytes_per_row:.1f}' if bytes_per_row else 'N/A',\n        })\n\npd.DataFrame(storage)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Benchmark Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.827621Z",
     "iopub.status.busy": "2025-12-10T23:45:11.827559Z",
     "iopub.status.idle": "2025-12-10T23:45:11.830598Z",
     "shell.execute_reply": "2025-12-10T23:45:11.830215Z"
    }
   },
   "outputs": [],
   "source": "### Benchmark Results Summary\n\n**Data Coverage Verification:**\n- ‚úÖ Export, Zenodo Narrow, Zenodo Wide all contain **6,680,932 samples** from all 4 sources\n- ‚úÖ Eric's Narrow/Wide contain OpenContext subset (~1.1M samples)\n\n| Query Pattern | Best For | SQL Complexity | Notes |\n|--------------|----------|----------------|-------|\n| **Map (all coords)** | Export ‚âà Zenodo Wide | Simple SELECT | Both ~30ms for 6M points |\n| **Facets (material counts)** | Export | 1 subquery vs 2 CTEs + JOIN | Export has URIs, PQG has labels |\n| **Entity listing (agents)** | PQG formats | 0 JOINs (otype filter) | Export requires full scan |\n| **Reverse lookup by agent** | Export | list_contains() | Only works if agent exists |\n| **Sample detail (one row)** | Export | Simple WHERE | All data on single row |\n\n**Key tradeoffs:**\n- **Export**: Best for UI (map + facets + detail) but slow for entity listing\n- **PQG Wide**: Good balance - entities queryable, reasonable JOIN complexity\n- **PQG Narrow**: Most flexible but slower (92M rows including edges)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions: When to Use Each Format\n",
    "\n",
    "### Export Format\n",
    "**Best for:**\n",
    "- UI queries (map, search, facets)\n",
    "- Sample-centric analysis\n",
    "- When you don't need to query entities independently\n",
    "\n",
    "**Avoid when:**\n",
    "- You need to list all agents/sites/concepts\n",
    "- You need graph traversal flexibility\n",
    "- You need incremental updates\n",
    "\n",
    "### Wide Format\n",
    "**Best for:**\n",
    "- Entity-centric queries (\"all agents\", \"all sites\")\n",
    "- Analytical dashboards\n",
    "- When you need both samples AND other entity types\n",
    "\n",
    "**Avoid when:**\n",
    "- Pure sample queries (Export is faster)\n",
    "- Complex multi-hop traversals (Narrow is more natural)\n",
    "\n",
    "### Narrow Format\n",
    "**Best for:**\n",
    "- Archival/preservation (full fidelity)\n",
    "- Graph algorithms\n",
    "- Relationship exploration\n",
    "- When you need to traverse in any direction\n",
    "\n",
    "**Avoid when:**\n",
    "- Interactive UI (too slow)\n",
    "- Simple sample queries (overkill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights\n",
    "\n",
    "### What Export Gains\n",
    "1. **No JOINs** - Everything on one row\n",
    "2. **Pre-extracted coords** - `sample_location_latitude/longitude` at top level\n",
    "3. **Fewer rows** - 6.7M vs 19.5M vs 92M\n",
    "\n",
    "### What Export Loses\n",
    "1. **Entity independence** - Can't query agents without scanning all samples\n",
    "2. **Graph flexibility** - Can't traverse in arbitrary directions\n",
    "3. **Incremental updates** - Must regenerate entire file\n",
    "\n",
    "### The `list_contains()` Problem\n",
    "Both Wide (p__* arrays) and Export (nested structs) suffer from O(n) scans when searching within arrays. Neither has index support in DuckDB/Parquet.\n",
    "\n",
    "### Recommendation for Eric's UI\n",
    "For the iSamples Central UI requirements:\n",
    "- **Start with Export format** - fastest for map + facets + click-to-detail\n",
    "- **Pre-compute H3 aggregations** - for initial map render\n",
    "- **Pre-compute facet counts** - avoid runtime aggregation\n",
    "- **Keep Wide/Narrow for advanced queries** - entity exploration, graph traversal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isamples-python-3.12.9",
   "language": "python",
   "name": "isamples-python-3.12.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
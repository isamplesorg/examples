{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iSamples Parquet Schema Comparison\n",
    "\n",
    "**Goal**: Understand the tradeoffs among five parquet formats for iSamples data.\n",
    "\n",
    "| Format | Philosophy | Sources | Relationships |\n",
    "|--------|-----------|---------|---------------|\n",
    "| **Export** | Sample-centric (flat) | All 4 sources | Nested STRUCTs |\n",
    "| **Zenodo Narrow** | Graph (nodes + edges) | All 4 sources | Separate `_edge_` rows |\n",
    "| **Zenodo Wide** | Entity-centric | All 4 sources | `p__*` arrays ‚Üí row_ids |\n",
    "| **Eric's Narrow** | Graph (nodes + edges) | OpenContext only | Separate `_edge_` rows |\n",
    "| **Eric's Wide** | Entity-centric | OpenContext only | `p__*` arrays ‚Üí row_ids |\n",
    "\n",
    "**Key insight**: There is no universal best format. Each optimizes for different query patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## Portability\n",
    "\n",
    "This notebook works in multiple environments:\n",
    "\n",
    "| Environment | Behavior |\n",
    "|-------------|----------|\n",
    "| **Raymond's laptop** | Uses local files in `~/Data/iSample/` |\n",
    "| **mybinder.org** | Downloads to `/tmp/pqgfiles/` cache |\n",
    "| **Other users** | Downloads to `~/Data/iSample/pqg_cache/` |\n",
    "\n",
    "**Configuration options** (in cell 2):\n",
    "- `CACHE_DIR`: Override with `ISAMPLES_CACHE_DIR` env var\n",
    "- `USE_REMOTE=True`: Skip downloads, query remote parquet via HTTP (slower but no disk)\n",
    "- `DOWNLOAD_MISSING=False`: Error instead of downloading missing files\n",
    "\n",
    "---\n",
    "\n",
    "## Data Source Coverage\n",
    "\n",
    "| Format | Sources | Description |\n",
    "|--------|---------|-------------|\n",
    "| **Export, Zenodo Narrow, Zenodo Wide** | SESAR, OpenContext, GEOME, Smithsonian | Full iSamples (~6.7M samples) |\n",
    "| **Eric's Narrow, Eric's Wide** | OpenContext only | Subset (~1.1M samples) |\n",
    "\n",
    "This allows fair comparisons:\n",
    "- **Apples-to-apples**: Export vs Zenodo Narrow vs Zenodo Wide (same data)\n",
    "- **Structure comparison**: Eric's Narrow vs Eric's Wide (same data, different structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache directory: /Users/raymondyee/Data/iSample/pqg_cache\n",
      "Use remote: False, Download missing: True\n",
      "\n",
      "=== Full iSamples (all sources) ===\n",
      "‚úÖ export: 297.0 MB (local)\n",
      "‚úÖ zenodo_narrow: 860.1 MB (local)\n",
      "‚úÖ zenodo_wide: 291.8 MB (local)\n",
      "\n",
      "=== OpenContext only (Eric's) ===\n",
      "‚úÖ eric_narrow: 724.5 MB (local)\n",
      "‚úÖ eric_wide: 288.7 MB (local)\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these paths for your environment\n",
    "# =============================================================================\n",
    "\n",
    "# Cache directory for downloaded files (used when local paths don't exist)\n",
    "# - On mybinder.org: uses /tmp/pqgfiles\n",
    "# - Locally: uses ~/Data/iSample/pqg_cache (or override with ISAMPLES_CACHE_DIR env var)\n",
    "CACHE_DIR = Path(os.environ.get('ISAMPLES_CACHE_DIR', \n",
    "                                '/tmp/pqgfiles' if Path('/tmp').exists() and not Path.home().joinpath('Data/iSample').exists()\n",
    "                                else Path.home() / 'Data/iSample/pqg_cache'))\n",
    "\n",
    "# Local paths (Raymond's setup) - these are checked first\n",
    "# Updated 2026-01-09: zenodo_wide now points to January 9 conversion\n",
    "# which fixes issue #8 ([null] array bug in p__* columns)\n",
    "LOCAL_PATHS = {\n",
    "    'export': Path.home() / 'Data/iSample/2025_04_21_16_23_46/isamples_export_2025_04_21_16_23_46_geo.parquet',\n",
    "    'zenodo_narrow': Path.home() / 'Data/iSample/pqg_refining/zenodo_narrow_2025-12-12.parquet',\n",
    "    'zenodo_wide': Path.home() / 'Data/iSample/pqg_refining/zenodo_wide_2026-01-09.parquet',\n",
    "    'eric_narrow': Path.home() / 'Data/iSample/pqg_refining/oc_isamples_pqg.parquet',\n",
    "    'eric_wide': Path.home() / 'Data/iSample/pqg_refining/oc_isamples_pqg_wide.parquet',\n",
    "}\n",
    "\n",
    "# Remote URLs - fallback when local files don't exist\n",
    "# Updated 2026-01-09: R2 bucket contains January 9 wide conversion (fixes issue #8)\n",
    "URLS = {\n",
    "    'export': 'https://zenodo.org/records/15278211/files/isamples_export_2025_04_21_16_23_46_geo.parquet',\n",
    "    'zenodo_narrow': 'https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202512_narrow.parquet',\n",
    "    'zenodo_wide': 'https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202601_wide.parquet',\n",
    "    'eric_narrow': 'https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg.parquet',\n",
    "    'eric_wide': 'https://storage.googleapis.com/opencontext-parquet/oc_isamples_pqg_wide.parquet',\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# PATH RESOLUTION - Automatically finds or downloads files\n",
    "# =============================================================================\n",
    "\n",
    "def resolve_path(name: str, local_paths: dict, urls: dict, cache_dir: Path, \n",
    "                 download: bool = True, use_remote: bool = False) -> Path:\n",
    "    \"\"\"\n",
    "    Resolve file path: check local first, then cache, optionally download.\n",
    "    \n",
    "    Args:\n",
    "        name: File identifier (e.g., 'export', 'zenodo_wide')\n",
    "        local_paths: Dict of local file paths to check first\n",
    "        urls: Dict of remote URLs for downloading\n",
    "        cache_dir: Directory for cached downloads\n",
    "        download: If True, download missing files to cache\n",
    "        use_remote: If True, return URL for DuckDB remote access (no download)\n",
    "    \n",
    "    Returns:\n",
    "        Path to local file, or URL string if use_remote=True\n",
    "    \"\"\"\n",
    "    # Option 1: Local file exists\n",
    "    if name in local_paths and local_paths[name].exists():\n",
    "        return local_paths[name]\n",
    "    \n",
    "    # Option 2: Return URL for remote access (DuckDB can read directly)\n",
    "    if use_remote and name in urls:\n",
    "        return urls[name]\n",
    "    \n",
    "    # Option 3: Check cache\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cached_file = cache_dir / f\"{name}.parquet\"\n",
    "    \n",
    "    if cached_file.exists():\n",
    "        return cached_file\n",
    "    \n",
    "    # Option 4: Download to cache\n",
    "    if download and name in urls:\n",
    "        url = urls[name]\n",
    "        print(f\"Downloading {name} from {url}...\")\n",
    "        print(f\"  -> {cached_file}\")\n",
    "        \n",
    "        # Download with progress\n",
    "        def progress_hook(block_num, block_size, total_size):\n",
    "            downloaded = block_num * block_size\n",
    "            if total_size > 0:\n",
    "                pct = min(100, downloaded * 100 // total_size)\n",
    "                mb = downloaded / 1e6\n",
    "                total_mb = total_size / 1e6\n",
    "                print(f\"\\r  Progress: {pct}% ({mb:.1f}/{total_mb:.1f} MB)\", end='', flush=True)\n",
    "        \n",
    "        urllib.request.urlretrieve(url, cached_file, reporthook=progress_hook)\n",
    "        print()  # newline after progress\n",
    "        return cached_file\n",
    "    \n",
    "    # No file available\n",
    "    raise FileNotFoundError(f\"File '{name}' not found locally and download=False\")\n",
    "\n",
    "# =============================================================================\n",
    "# RESOLVE ALL PATHS\n",
    "# =============================================================================\n",
    "\n",
    "# Set to True to skip downloads and use DuckDB's remote parquet reading\n",
    "# (Slower queries but no disk usage - good for quick exploration)\n",
    "USE_REMOTE = False\n",
    "\n",
    "# Set to False to skip downloading missing files (will error if not found)\n",
    "DOWNLOAD_MISSING = True\n",
    "\n",
    "print(f\"Cache directory: {CACHE_DIR}\")\n",
    "print(f\"Use remote: {USE_REMOTE}, Download missing: {DOWNLOAD_MISSING}\\n\")\n",
    "\n",
    "PATHS = {}\n",
    "for name in ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n",
    "    try:\n",
    "        path = resolve_path(name, LOCAL_PATHS, URLS, CACHE_DIR, \n",
    "                           download=DOWNLOAD_MISSING, use_remote=USE_REMOTE)\n",
    "        PATHS[name] = path\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ö†Ô∏è {name}: {e}\")\n",
    "        PATHS[name] = None\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFY FILES\n",
    "# =============================================================================\n",
    "\n",
    "def get_file_info(path):\n",
    "    \"\"\"Get file info - works for both local paths and URLs.\"\"\"\n",
    "    if path is None:\n",
    "        return '‚ùå', 'Not available'\n",
    "    if isinstance(path, str) and path.startswith('http'):\n",
    "        return 'üåê', 'Remote URL'\n",
    "    if Path(path).exists():\n",
    "        size_mb = Path(path).stat().st_size / 1e6\n",
    "        return '‚úÖ', f'{size_mb:.1f} MB'\n",
    "    return '‚ùå', 'Not found'\n",
    "\n",
    "print(\"=== Full iSamples (all sources) ===\")\n",
    "for name in ['export', 'zenodo_narrow', 'zenodo_wide']:\n",
    "    status, info = get_file_info(PATHS.get(name))\n",
    "    source = \"local\" if PATHS.get(name) and Path(PATHS[name]).exists() and PATHS[name] in LOCAL_PATHS.values() else \"cache/remote\"\n",
    "    print(f'{status} {name}: {info} ({source})')\n",
    "\n",
    "print(\"\\n=== OpenContext only (Eric's) ===\")\n",
    "for name in ['eric_narrow', 'eric_wide']:\n",
    "    status, info = get_file_info(PATHS.get(name))\n",
    "    source = \"local\" if PATHS.get(name) and Path(PATHS[name]).exists() and PATHS[name] in LOCAL_PATHS.values() else \"cache/remote\"\n",
    "    print(f'{status} {name}: {info} ({source})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for timing queries\n",
    "import statistics\n",
    "\n",
    "def timed_query(con, sql, name=\"Query\"):\n",
    "    \"\"\"Execute query and return (result_df, elapsed_ms)\"\"\"\n",
    "    start = time.time()\n",
    "    result = con.sql(sql).fetchdf()\n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    print(f\"{name}: {elapsed:.1f}ms, {len(result):,} rows\")\n",
    "    return result, elapsed\n",
    "\n",
    "def timed_query_multirun(con, sql, name=\"Query\", runs=3):\n",
    "    \"\"\"Execute query multiple times and return (result_df, mean_ms, stddev_ms)\"\"\"\n",
    "    times = []\n",
    "    result = None\n",
    "    for i in range(runs):\n",
    "        start = time.time()\n",
    "        result = con.sql(sql).fetchdf()\n",
    "        elapsed = (time.time() - start) * 1000\n",
    "        times.append(elapsed)\n",
    "    \n",
    "    mean_ms = statistics.mean(times)\n",
    "    stddev_ms = statistics.stdev(times) if len(times) > 1 else 0\n",
    "    print(f\"{name}: {mean_ms:.1f}ms ¬± {stddev_ms:.1f}ms (n={runs}), {len(result):,} rows\")\n",
    "    return result, mean_ms, stddev_ms\n",
    "\n",
    "# Create connection\n",
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema Inspection\n",
    "\n",
    "Understanding what columns exist and their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXPORT (19 columns) ===\n",
      "                column_name                                                                                                                                                                                                                                                                                                                                     column_type\n",
      "0         sample_identifier                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "1                       @id                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "2                     label                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "3               description                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "4         source_collection                                                                                                                                                                                                                                                                                                                                         VARCHAR\n",
      "5    has_sample_object_type                                                                                                                                                                                                                                                                                                                    STRUCT(identifier VARCHAR)[]\n",
      "6     has_material_category                                                                                                                                                                                                                                                                                                                    STRUCT(identifier VARCHAR)[]\n",
      "7      has_context_category                                                                                                                                                                                                                                                                                                                    STRUCT(identifier VARCHAR)[]\n",
      "8   informal_classification                                                                                                                                                                                                                                                                                                                                       VARCHAR[]\n",
      "9                  keywords                                                                                                                                                                                                                                                                                                                       STRUCT(keyword VARCHAR)[]\n",
      "10              produced_by  STRUCT(description VARCHAR, has_feature_of_interest VARCHAR, identifier VARCHAR, \"label\" VARCHAR, responsibility STRUCT(\"name\" VARCHAR, \"role\" VARCHAR)[], result_time VARCHAR, sampling_site STRUCT(description VARCHAR, \"label\" VARCHAR, place_name VARCHAR[], sample_location STRUCT(elevation DOUBLE, latitude DOUBLE, longitude DOUBLE)))\n",
      "11       last_modified_time                                                                                                                                                                                                                                                                                                                        TIMESTAMP WITH TIME ZONE\n",
      "12                 curation                                                                                                                                                                                  STRUCT(access_constraints VARCHAR[], curation_location VARCHAR, description VARCHAR, \"label\" VARCHAR, responsibility STRUCT(\"name\" VARCHAR, \"role\" VARCHAR)[])\n",
      "13               registrant                                                                                                                                                                                                                                                                                                                          STRUCT(\"name\" VARCHAR)\n",
      "14         related_resource                                                                                                                                                                                                                                                                                                                        STRUCT(target VARCHAR)[]\n",
      "  ... and 4 more columns\n",
      "\n",
      "=== ZENODO_NARROW (40 columns) ===\n",
      "                column_name column_type\n",
      "0                    row_id      BIGINT\n",
      "1                       pid     VARCHAR\n",
      "2                  tcreated     INTEGER\n",
      "3                 tmodified     INTEGER\n",
      "4                     otype     VARCHAR\n",
      "5                         s      BIGINT\n",
      "6                         p     VARCHAR\n",
      "7                         o   INTEGER[]\n",
      "8                         n     VARCHAR\n",
      "9                    altids   VARCHAR[]\n",
      "10                 geometry        BLOB\n",
      "11            authorized_by   VARCHAR[]\n",
      "12  has_feature_of_interest     VARCHAR\n",
      "13              affiliation     VARCHAR\n",
      "14         sampling_purpose     VARCHAR\n",
      "  ... and 25 more columns\n",
      "\n",
      "=== ZENODO_WIDE (49 columns) ===\n",
      "                column_name column_type\n",
      "0                    row_id      BIGINT\n",
      "1                       pid     VARCHAR\n",
      "2                  tcreated     INTEGER\n",
      "3                 tmodified     INTEGER\n",
      "4                     otype     VARCHAR\n",
      "5                         n     VARCHAR\n",
      "6                    altids   VARCHAR[]\n",
      "7                  geometry        BLOB\n",
      "8             authorized_by   VARCHAR[]\n",
      "9   has_feature_of_interest     VARCHAR\n",
      "10              affiliation     VARCHAR\n",
      "11         sampling_purpose     VARCHAR\n",
      "12            complies_with   VARCHAR[]\n",
      "13                  project     VARCHAR\n",
      "14    alternate_identifiers   VARCHAR[]\n",
      "  ... and 34 more columns\n",
      "\n",
      "=== ERIC_NARROW (40 columns) ===\n",
      "                column_name column_type\n",
      "0                    row_id     INTEGER\n",
      "1                       pid     VARCHAR\n",
      "2                  tcreated     INTEGER\n",
      "3                 tmodified     INTEGER\n",
      "4                     otype     VARCHAR\n",
      "5                         s     INTEGER\n",
      "6                         p     VARCHAR\n",
      "7                         o   INTEGER[]\n",
      "8                         n     VARCHAR\n",
      "9                    altids   VARCHAR[]\n",
      "10                 geometry        BLOB\n",
      "11            authorized_by   VARCHAR[]\n",
      "12  has_feature_of_interest     VARCHAR\n",
      "13              affiliation     VARCHAR\n",
      "14         sampling_purpose     VARCHAR\n",
      "  ... and 25 more columns\n",
      "\n",
      "=== ERIC_WIDE (47 columns) ===\n",
      "                column_name column_type\n",
      "0                    row_id     INTEGER\n",
      "1                       pid     VARCHAR\n",
      "2                  tcreated     INTEGER\n",
      "3                 tmodified     INTEGER\n",
      "4                     otype     VARCHAR\n",
      "5                         n     VARCHAR\n",
      "6                    altids   VARCHAR[]\n",
      "7                  geometry        BLOB\n",
      "8             authorized_by   VARCHAR[]\n",
      "9   has_feature_of_interest     VARCHAR\n",
      "10              affiliation     VARCHAR\n",
      "11         sampling_purpose     VARCHAR\n",
      "12            complies_with   VARCHAR[]\n",
      "13                  project     VARCHAR\n",
      "14    alternate_identifiers   VARCHAR[]\n",
      "  ... and 32 more columns\n"
     ]
    }
   ],
   "source": [
    "# Helper to check if path is available (works for Path objects and URL strings)\n",
    "def path_available(path):\n",
    "    \"\"\"Check if a path is available (local file exists or is a URL).\"\"\"\n",
    "    if path is None:\n",
    "        return False\n",
    "    if isinstance(path, str) and path.startswith('http'):\n",
    "        return True  # URLs are assumed available\n",
    "    return Path(path).exists()\n",
    "\n",
    "# Get schema for each format\n",
    "schemas = {}\n",
    "for name, path in PATHS.items():\n",
    "    if path_available(path):\n",
    "        result = con.sql(f\"DESCRIBE SELECT * FROM read_parquet('{path}')\").fetchdf()\n",
    "        schemas[name] = result\n",
    "        print(f\"\\n=== {name.upper()} ({len(result)} columns) ===\")\n",
    "        # Show just first 15 columns to keep output manageable\n",
    "        print(result[['column_name', 'column_type']].head(15).to_string())\n",
    "        if len(result) > 15:\n",
    "            print(f\"  ... and {len(result) - 15} more columns\")\n",
    "    else:\n",
    "        print(f\"\\n=== {name.upper()} ===\")\n",
    "        print(f\"  ‚ö†Ô∏è Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Data</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Edge cols (s,p,o)</th>\n",
       "      <th>p__* cols</th>\n",
       "      <th>Nested STRUCTs</th>\n",
       "      <th>otype col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Export</td>\n",
       "      <td>Full</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zenodo Narrow</td>\n",
       "      <td>Full</td>\n",
       "      <td>40</td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zenodo Wide</td>\n",
       "      <td>Full</td>\n",
       "      <td>49</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric Narrow</td>\n",
       "      <td>OC only</td>\n",
       "      <td>40</td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Wide</td>\n",
       "      <td>OC only</td>\n",
       "      <td>47</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Format     Data  Columns Edge cols (s,p,o) p__* cols Nested STRUCTs  \\\n",
       "0         Export     Full       19                                          ‚úì   \n",
       "1  Zenodo Narrow     Full       40                 ‚úì                            \n",
       "2    Zenodo Wide     Full       49                           ‚úì                  \n",
       "3    Eric Narrow  OC only       40                 ‚úì                            \n",
       "4      Eric Wide  OC only       47                           ‚úì                  \n",
       "\n",
       "  otype col  \n",
       "0            \n",
       "1         ‚úì  \n",
       "2         ‚úì  \n",
       "3         ‚úì  \n",
       "4         ‚úì  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare column counts and key structural differences (computed from schemas)\n",
    "def check_schema_features(schema_df):\n",
    "    \"\"\"Analyze schema DataFrame for structural features.\"\"\"\n",
    "    if schema_df is None or len(schema_df) == 0:\n",
    "        return {'columns': 0, 'has_edge_cols': False, 'has_p__cols': False, \n",
    "                'has_nested_structs': False, 'has_otype': False}\n",
    "    \n",
    "    cols = set(schema_df['column_name'].tolist())\n",
    "    types = dict(zip(schema_df['column_name'], schema_df['column_type']))\n",
    "    \n",
    "    return {\n",
    "        'columns': len(schema_df),\n",
    "        'has_edge_cols': all(c in cols for c in ['s', 'p', 'o']),\n",
    "        'has_p__cols': any(c.startswith('p__') for c in cols),\n",
    "        'has_nested_structs': any('STRUCT' in str(t) for t in types.values()),\n",
    "        'has_otype': 'otype' in cols,\n",
    "    }\n",
    "\n",
    "# Compute features for each format\n",
    "format_order = ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']\n",
    "features = {name: check_schema_features(schemas.get(name)) for name in format_order}\n",
    "\n",
    "# Build comparison table\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Format': name.replace('_', ' ').title(),\n",
    "        'Data': 'Full' if name in ['export', 'zenodo_narrow', 'zenodo_wide'] else 'OC only',\n",
    "        'Columns': features[name]['columns'],\n",
    "        'Edge cols (s,p,o)': '‚úì' if features[name]['has_edge_cols'] else '',\n",
    "        'p__* cols': '‚úì' if features[name]['has_p__cols'] else '',\n",
    "        'Nested STRUCTs': '‚úì' if features[name]['has_nested_structs'] else '',\n",
    "        'otype col': '‚úì' if features[name]['has_otype'] else '',\n",
    "    }\n",
    "    for name in format_order\n",
    "])\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Row Count Analysis\n",
    "\n",
    "Understanding what's IN each format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Full iSamples ===\n",
      "export: 6,680,932 rows\n",
      "zenodo_narrow: 101,387,180 rows\n",
      "zenodo_wide: 20,729,358 rows\n",
      "\n",
      "=== OpenContext only ===\n",
      "eric_narrow: 11,637,144 rows\n",
      "eric_wide: 2,464,690 rows\n"
     ]
    }
   ],
   "source": [
    "# Total row counts\n",
    "row_counts = {}\n",
    "print(\"=== Full iSamples ===\")\n",
    "for name in ['export', 'zenodo_narrow', 'zenodo_wide']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        count = con.sql(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n",
    "        row_counts[name] = count\n",
    "        print(f\"{name}: {count:,} rows\")\n",
    "    else:\n",
    "        print(f\"{name}: ‚ö†Ô∏è Not available\")\n",
    "\n",
    "print(\"\\n=== OpenContext only ===\")\n",
    "for name in ['eric_narrow', 'eric_wide']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        count = con.sql(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n",
    "        row_counts[name] = count\n",
    "        print(f\"{name}: {count:,} rows\")\n",
    "    else:\n",
    "        print(f\"{name}: ‚ö†Ô∏è Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO_NARROW: Rows by otype ===\n",
      "                     otype       cnt\n",
      "0                   _edge_  80657822\n",
      "1     MaterialSampleRecord   6680932\n",
      "2            SamplingEvent   6354171\n",
      "3  GeospatialCoordLocation   5980282\n",
      "4   MaterialSampleCuration    720254\n",
      "5           SampleRelation    501579\n",
      "6             SamplingSite    386160\n",
      "7        IdentifiedConcept     55893\n",
      "8                    Agent     50087\n",
      "\n",
      "=== ZENODO_WIDE: Rows by otype ===\n",
      "                     otype      cnt\n",
      "0     MaterialSampleRecord  6680932\n",
      "1            SamplingEvent  6354171\n",
      "2  GeospatialCoordLocation  5980282\n",
      "3   MaterialSampleCuration   720254\n",
      "4           SampleRelation   501579\n",
      "5             SamplingSite   386160\n",
      "6        IdentifiedConcept    55893\n",
      "7                    Agent    50087\n",
      "\n",
      "=== ERIC_NARROW: Rows by otype ===\n",
      "                     otype      cnt\n",
      "0                   _edge_  9201451\n",
      "1     MaterialSampleRecord  1096352\n",
      "2            SamplingEvent  1096352\n",
      "3  GeospatialCoordLocation   198433\n",
      "4        IdentifiedConcept    25778\n",
      "5             SamplingSite    18213\n",
      "6                    Agent      565\n",
      "\n",
      "=== ERIC_WIDE: Rows by otype ===\n",
      "                     otype      cnt\n",
      "0     MaterialSampleRecord  1110412\n",
      "1            SamplingEvent  1110412\n",
      "2  GeospatialCoordLocation   199147\n",
      "3        IdentifiedConcept    25929\n",
      "4             SamplingSite    18213\n",
      "5                    Agent      577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For PQG formats: breakdown by otype\n",
    "for name in ['zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        print(f\"=== {name.upper()}: Rows by otype ===\")\n",
    "        result = con.sql(f\"\"\"\n",
    "            SELECT otype, COUNT(*) as cnt \n",
    "            FROM read_parquet('{path}')\n",
    "            GROUP BY otype ORDER BY cnt DESC\n",
    "        \"\"\").fetchdf()\n",
    "        print(result.to_string())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT: Rows by source_collection ===\n",
      "  source_collection      cnt\n",
      "0             SESAR  4688386\n",
      "1       OPENCONTEXT  1064831\n",
      "2             GEOME   605554\n",
      "3       SMITHSONIAN   322161\n"
     ]
    }
   ],
   "source": [
    "# For Export: breakdown by source_collection\n",
    "print(\"=== EXPORT: Rows by source_collection ===\")\n",
    "if path_available(PATHS.get('export')):\n",
    "    result = con.sql(f\"\"\"\n",
    "        SELECT source_collection, COUNT(*) as cnt \n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        GROUP BY source_collection ORDER BY cnt DESC\n",
    "    \"\"\").fetchdf()\n",
    "    print(result.to_string())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Export file not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Benchmark Suite\n",
    "\n",
    "Testing common query patterns across all three formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Map Visualization: Get All Coordinates\n",
    "\n",
    "**Use case**: Render points on a Cesium/Leaflet map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT (full iSamples) ===\n",
      "All coordinates: 35.0ms, 5,980,282 rows\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Direct column access\n",
    "print(\"=== EXPORT (full iSamples) ===\")\n",
    "export_coords, export_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT sample_location_latitude as lat, sample_location_longitude as lon\n",
    "    FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE sample_location_latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE (full iSamples) ===\n",
      "All coordinates: 40.5ms, 5,980,282 rows\n",
      "\n",
      "=== ERIC WIDE (OpenContext only) ===\n",
      "All coordinates: 7.6ms, 199,146 rows\n"
     ]
    }
   ],
   "source": [
    "# WIDE formats: Filter by otype\n",
    "print(\"=== ZENODO WIDE (full iSamples) ===\")\n",
    "zenodo_wide_coords, zenodo_wide_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT latitude as lat, longitude as lon\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")\n",
    "\n",
    "print(\"\\n=== ERIC WIDE (OpenContext only) ===\")\n",
    "eric_wide_coords, eric_wide_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT latitude as lat, longitude as lon\n",
    "    FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO NARROW (full iSamples) ===\n",
      "All coordinates: 77.6ms, 5,980,282 rows\n",
      "\n",
      "=== ERIC NARROW (OpenContext only) ===\n",
      "All coordinates: 11.4ms, 198,432 rows\n"
     ]
    }
   ],
   "source": [
    "# NARROW formats: Filter by otype  \n",
    "print(\"=== ZENODO NARROW (full iSamples) ===\")\n",
    "zenodo_narrow_coords, zenodo_narrow_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT latitude as lat, longitude as lon\n",
    "    FROM read_parquet('{PATHS['zenodo_narrow']}')\n",
    "    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")\n",
    "\n",
    "print(\"\\n=== ERIC NARROW (OpenContext only) ===\")\n",
    "eric_narrow_coords, eric_narrow_coords_time = timed_query(con, f\"\"\"\n",
    "    SELECT latitude as lat, longitude as lon\n",
    "    FROM read_parquet('{PATHS['eric_narrow']}')\n",
    "    WHERE otype = 'GeospatialCoordLocation' AND latitude IS NOT NULL\n",
    "\"\"\", \"All coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MAP QUERY SUMMARY ===\n",
      "\n",
      "Full iSamples (apples-to-apples comparison):\n",
      "  Export:          35.0ms (5,980,282 points)\n",
      "  Zenodo Wide:     40.5ms (5,980,282 points)\n",
      "  Zenodo Narrow:   77.6ms (5,980,282 points)\n",
      "\n",
      "OpenContext only (Eric's files):\n",
      "  Eric Wide:        7.6ms (199,146 points)\n",
      "  Eric Narrow:     11.4ms (198,432 points)\n",
      "\n",
      "üí° Key insight: Export returns coords directly; PQG formats need otype filter\n"
     ]
    }
   ],
   "source": [
    "# Summary - Map query comparison\n",
    "print(\"=== MAP QUERY SUMMARY ===\")\n",
    "print(\"\\nFull iSamples (apples-to-apples comparison):\")\n",
    "print(f\"  Export:        {export_coords_time:6.1f}ms ({len(export_coords):,} points)\")\n",
    "print(f\"  Zenodo Wide:   {zenodo_wide_coords_time:6.1f}ms ({len(zenodo_wide_coords):,} points)\")\n",
    "print(f\"  Zenodo Narrow: {zenodo_narrow_coords_time:6.1f}ms ({len(zenodo_narrow_coords):,} points)\")\n",
    "\n",
    "print(\"\\nOpenContext only (Eric's files):\")\n",
    "print(f\"  Eric Wide:     {eric_wide_coords_time:6.1f}ms ({len(eric_wide_coords):,} points)\")\n",
    "print(f\"  Eric Narrow:   {eric_narrow_coords_time:6.1f}ms ({len(eric_narrow_coords):,} points)\")\n",
    "\n",
    "print(\"\\nüí° Key insight: Export returns coords directly; PQG formats need otype filter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Faceted Search: Count by Material Category\n",
    "\n",
    "**Use case**: Show facet counts in a search UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT (full iSamples) ===\n",
      "Material facets: 562.5ms, 10 rows\n",
      "                                                                      material      cnt\n",
      "0               https://w3id.org/isample/vocabulary/material/1.0/earthmaterial  2261513\n",
      "1             https://w3id.org/isample/vocabulary/material/1.0/organicmaterial  1265560\n",
      "2                        https://w3id.org/isample/vocabulary/material/1.0/rock  1208585\n",
      "3  https://w3id.org/isample/vocabulary/material/1.0/biogenicnonorganicmaterial  1091781\n",
      "4       https://w3id.org/isample/vocabulary/material/1.0/mixedsoilsedimentrock   838805\n",
      "5                    https://w3id.org/isample/vocabulary/material/1.0/material   673018\n",
      "6                     https://w3id.org/isample/vocabulary/material/1.0/mineral   390797\n",
      "7          https://w3id.org/isample/vocabulary/material/1.0/anthropogenicmetal   270040\n",
      "8                https://w3id.org/isample/opencontext/material/0.1/ceramicclay   100573\n",
      "9                    https://w3id.org/isample/vocabulary/material/1.0/sediment    94084\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Unnest nested struct array\n",
    "# SQL Complexity: 1 subquery, 0 JOINs - simple unnest\n",
    "print(\"=== EXPORT (full iSamples) ===\")\n",
    "export_facets, export_facets_time = timed_query(con, f\"\"\"\n",
    "    SELECT \n",
    "        mat.identifier as material,\n",
    "        COUNT(*) as cnt\n",
    "    FROM (\n",
    "        SELECT unnest(has_material_category) as mat\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE has_material_category IS NOT NULL AND len(has_material_category) > 0\n",
    "    )\n",
    "    GROUP BY mat.identifier\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(export_facets.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE (full iSamples) ===\n",
      "Material facets: 542.9ms, 10 rows\n",
      "                                                                      material      cnt\n",
      "0               https://w3id.org/isample/vocabulary/material/1.0/earthmaterial  2261513\n",
      "1             https://w3id.org/isample/vocabulary/material/1.0/organicmaterial  1265560\n",
      "2                        https://w3id.org/isample/vocabulary/material/1.0/rock  1208585\n",
      "3  https://w3id.org/isample/vocabulary/material/1.0/biogenicnonorganicmaterial  1091781\n",
      "4       https://w3id.org/isample/vocabulary/material/1.0/mixedsoilsedimentrock   838805\n",
      "5                    https://w3id.org/isample/vocabulary/material/1.0/material   673018\n",
      "6                     https://w3id.org/isample/vocabulary/material/1.0/mineral   390797\n",
      "7          https://w3id.org/isample/vocabulary/material/1.0/anthropogenicmetal   270040\n",
      "8                https://w3id.org/isample/opencontext/material/0.1/ceramicclay   100573\n",
      "9                    https://w3id.org/isample/vocabulary/material/1.0/sediment    94084\n",
      "\n",
      "=== ERIC WIDE (OpenContext only) ===\n",
      "Material facets: 107.7ms, 10 rows\n",
      "                        material     cnt\n",
      "0  Biogenic non-organic material  532843\n",
      "1               Organic material  217562\n",
      "2                       Material  159434\n",
      "3   Other anthropogenic material  145431\n",
      "4                           Rock   37948\n",
      "5   Anthropogenic metal material   11694\n",
      "6    Mixed soil sediment or rock    3207\n",
      "7                        Mineral    2233\n",
      "8         Natural Solid Material      58\n",
      "9                       Sediment       2\n"
     ]
    }
   ],
   "source": [
    "# WIDE formats: JOIN via p__has_material_category\n",
    "# SQL Complexity: 2 CTEs, 1 JOIN - requires row_id lookup\n",
    "print(\"=== ZENODO WIDE (full iSamples) ===\")\n",
    "zenodo_wide_facets, zenodo_wide_facets_time = timed_query(con, f\"\"\"\n",
    "    WITH samples AS (\n",
    "        SELECT unnest(p__has_material_category) as concept_rowid\n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "        WHERE otype = 'MaterialSampleRecord' \n",
    "          AND p__has_material_category IS NOT NULL\n",
    "    ),\n",
    "    concepts AS (\n",
    "        SELECT row_id, label\n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "    )\n",
    "    SELECT c.label as material, COUNT(*) as cnt\n",
    "    FROM samples s\n",
    "    JOIN concepts c ON s.concept_rowid = c.row_id\n",
    "    GROUP BY c.label\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(zenodo_wide_facets.to_string())\n",
    "\n",
    "print(\"\\n=== ERIC WIDE (OpenContext only) ===\")\n",
    "eric_wide_facets, eric_wide_facets_time = timed_query(con, f\"\"\"\n",
    "    WITH samples AS (\n",
    "        SELECT unnest(p__has_material_category) as concept_rowid\n",
    "        FROM read_parquet('{PATHS['eric_wide']}')\n",
    "        WHERE otype = 'MaterialSampleRecord' \n",
    "          AND p__has_material_category IS NOT NULL\n",
    "    ),\n",
    "    concepts AS (\n",
    "        SELECT row_id, label\n",
    "        FROM read_parquet('{PATHS['eric_wide']}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "    )\n",
    "    SELECT c.label as material, COUNT(*) as cnt\n",
    "    FROM samples s\n",
    "    JOIN concepts c ON s.concept_rowid = c.row_id\n",
    "    GROUP BY c.label\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(eric_wide_facets.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO NARROW (full iSamples) ===\n",
      "Material facets: 757.9ms, 10 rows\n",
      "                                                                      material      cnt\n",
      "0               https://w3id.org/isample/vocabulary/material/1.0/earthmaterial  2261513\n",
      "1             https://w3id.org/isample/vocabulary/material/1.0/organicmaterial  1265560\n",
      "2                        https://w3id.org/isample/vocabulary/material/1.0/rock  1208585\n",
      "3  https://w3id.org/isample/vocabulary/material/1.0/biogenicnonorganicmaterial  1091781\n",
      "4       https://w3id.org/isample/vocabulary/material/1.0/mixedsoilsedimentrock   838805\n",
      "5                    https://w3id.org/isample/vocabulary/material/1.0/material   673018\n",
      "6                     https://w3id.org/isample/vocabulary/material/1.0/mineral   390797\n",
      "7          https://w3id.org/isample/vocabulary/material/1.0/anthropogenicmetal   270040\n",
      "8                https://w3id.org/isample/opencontext/material/0.1/ceramicclay   100573\n",
      "9                    https://w3id.org/isample/vocabulary/material/1.0/sediment    94084\n",
      "\n",
      "=== ERIC NARROW (OpenContext only) ===\n",
      "Material facets: 124.0ms, 10 rows\n",
      "                        material     cnt\n",
      "0  Biogenic non-organic material  532675\n",
      "1               Organic material  212584\n",
      "2                       Material  158586\n",
      "3   Other anthropogenic material  145316\n",
      "4                           Rock   30186\n",
      "5   Anthropogenic metal material   11659\n",
      "6    Mixed soil sediment or rock    3207\n",
      "7                        Mineral    2080\n",
      "8         Natural Solid Material      58\n",
      "9                       Sediment       1\n"
     ]
    }
   ],
   "source": [
    "# NARROW formats: Follow edges with predicate='has_material_category'\n",
    "# SQL Complexity: 2 CTEs, 1 JOIN - requires edge traversal\n",
    "print(\"=== ZENODO NARROW (full iSamples) ===\")\n",
    "zenodo_narrow_facets, zenodo_narrow_facets_time = timed_query(con, f\"\"\"\n",
    "    WITH edges AS (\n",
    "        SELECT s as sample_rowid, unnest(o) as concept_rowid\n",
    "        FROM read_parquet('{PATHS['zenodo_narrow']}')\n",
    "        WHERE otype = '_edge_' AND p = 'has_material_category'\n",
    "    ),\n",
    "    concepts AS (\n",
    "        SELECT row_id, label\n",
    "        FROM read_parquet('{PATHS['zenodo_narrow']}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "    )\n",
    "    SELECT c.label as material, COUNT(*) as cnt\n",
    "    FROM edges e\n",
    "    JOIN concepts c ON e.concept_rowid = c.row_id\n",
    "    GROUP BY c.label\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(zenodo_narrow_facets.to_string())\n",
    "\n",
    "print(\"\\n=== ERIC NARROW (OpenContext only) ===\")\n",
    "eric_narrow_facets, eric_narrow_facets_time = timed_query(con, f\"\"\"\n",
    "    WITH edges AS (\n",
    "        SELECT s as sample_rowid, unnest(o) as concept_rowid\n",
    "        FROM read_parquet('{PATHS['eric_narrow']}')\n",
    "        WHERE otype = '_edge_' AND p = 'has_material_category'\n",
    "    ),\n",
    "    concepts AS (\n",
    "        SELECT row_id, label\n",
    "        FROM read_parquet('{PATHS['eric_narrow']}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "    )\n",
    "    SELECT c.label as material, COUNT(*) as cnt\n",
    "    FROM edges e\n",
    "    JOIN concepts c ON e.concept_rowid = c.row_id\n",
    "    GROUP BY c.label\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"Material facets\")\n",
    "print(eric_narrow_facets.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FACET QUERY SUMMARY ===\n",
      "\n",
      "Full iSamples (apples-to-apples):\n",
      "  Export:         562.5ms (SQL: 1 subquery, 0 JOINs)\n",
      "  Zenodo Wide:    542.9ms (SQL: 2 CTEs, 1 JOIN)\n",
      "  Zenodo Narrow:  757.9ms (SQL: 2 CTEs, 1 JOIN)\n",
      "\n",
      "OpenContext only (Eric's files):\n",
      "  Eric Wide:      107.7ms\n",
      "  Eric Narrow:    124.0ms\n",
      "\n",
      "üí° Key insight: Export is simplest (no JOINs), but PQG returns human-readable labels\n"
     ]
    }
   ],
   "source": [
    "# Facet query summary\n",
    "print(\"=== FACET QUERY SUMMARY ===\")\n",
    "print(\"\\nFull iSamples (apples-to-apples):\")\n",
    "print(f\"  Export:        {export_facets_time:6.1f}ms (SQL: 1 subquery, 0 JOINs)\")\n",
    "print(f\"  Zenodo Wide:   {zenodo_wide_facets_time:6.1f}ms (SQL: 2 CTEs, 1 JOIN)\")\n",
    "print(f\"  Zenodo Narrow: {zenodo_narrow_facets_time:6.1f}ms (SQL: 2 CTEs, 1 JOIN)\")\n",
    "\n",
    "print(\"\\nOpenContext only (Eric's files):\")\n",
    "print(f\"  Eric Wide:     {eric_wide_facets_time:6.1f}ms\")\n",
    "print(f\"  Eric Narrow:   {eric_narrow_facets_time:6.1f}ms\")\n",
    "\n",
    "print(\"\\nüí° Key insight: Export is simplest (no JOINs), but PQG returns human-readable labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Entity Listing: Get All Unique Agents\n",
    "\n",
    "**Use case**: Populate a dropdown, show \"who collected samples\"\n",
    "\n",
    "**Key tradeoff**: Export cannot do this efficiently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE (full iSamples) ===\n",
      "All agents: 24.2ms, 10 rows\n",
      "                                                             name     role  cnt\n",
      "0                                                    Phialdelphia  curator    1\n",
      "1  Laboratoire Biom√©trie et Biologie Evolutive, University Lyon 1  curator    1\n",
      "2                                                            NYBG  curator    1\n",
      "3                                                              DU  curator    1\n",
      "4                                              Pohe Environmental  curator    1\n",
      "5           Institut de Recherche pour le D√©veloppement Herbarium  curator    1\n",
      "6                                                            USNM  curator    1\n",
      "7                                          University of Auckland  curator    1\n",
      "8                                                            SERC  curator    1\n",
      "9                                                    Planes's Lab  curator    1\n",
      "\n",
      "=== ERIC WIDE (OpenContext only) ===\n",
      "All agents: 4.8ms, 10 rows\n",
      "                name                                                                                                                role  cnt\n",
      "0    Arianne Boileau                                                       Participated in: Household Zooarchaeology of Colonial Lamanai    2\n",
      "1  Andrew C. Sneadon                                                                              Participated in: Domuztepe Excavations    1\n",
      "2     Catarina Ginja                                                 Participated in: Cattle husbandry in the Iron Age and Roman Britain    1\n",
      "3       Nobs Symmons                                                                          Participated in: √áatalh√∂y√ºk Zooarchaeology    1\n",
      "4   Pavlo Yashchenko  Participated in: 3D History for Ukraine: Archaeological Museum of the Taras Shevchenko National University of Kyiv    1\n",
      "5     Melissa Cradic                                                                                        Participated in: Bade Museum    1\n",
      "6     Vanessa Davies                      Participated in: The Phoebe A. Hearst Expedition to Naga ed-Deir, Cemeteries N 2000 and N 2500    1\n",
      "7  Hijlke Buitenhuis                                                                          Participated in: √áatalh√∂y√ºk Zooarchaeology    1\n",
      "8     Gordon Hillman                                                                   Participated in: Abu Hureyra Digital Data Archive    1\n",
      "9      Jacob Freeman                                                                            Participated in: Cross-referenced p3k14c    1\n"
     ]
    }
   ],
   "source": [
    "# WIDE formats: Direct query on Agent rows\n",
    "# SQL Complexity: 0 CTEs, 0 JOINs - simple otype filter\n",
    "print(\"=== ZENODO WIDE (full iSamples) ===\")\n",
    "zenodo_wide_agents, zenodo_wide_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT name, role, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'Agent'\n",
    "    GROUP BY name, role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents\")\n",
    "print(zenodo_wide_agents.to_string())\n",
    "\n",
    "print(\"\\n=== ERIC WIDE (OpenContext only) ===\")\n",
    "eric_wide_agents, eric_wide_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT name, role, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    WHERE otype = 'Agent'\n",
    "    GROUP BY name, role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents\")\n",
    "print(eric_wide_agents.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO NARROW (full iSamples) ===\n",
      "All agents: 57.5ms, 10 rows\n",
      "                                              name        role  cnt\n",
      "0          Indonesian Biodiversity Research Center     curator    1\n",
      "1                                         NZP-SCBI     curator    1\n",
      "2         Pacific Islands Fisheries Science Center     curator    1\n",
      "3                                             HIMB     curator    1\n",
      "4                                      BSCIT Staff  registrant    1\n",
      "5                                    Benoit Espiau  registrant    1\n",
      "6  University of California Museum of Paleontology     curator    1\n",
      "7                                              CAS     curator    1\n",
      "8                                Australian Museum     curator    1\n",
      "9                                             LACM     curator    1\n",
      "\n",
      "=== ERIC NARROW (OpenContext only) ===\n",
      "All agents: 7.6ms, 10 rows\n",
      "                   name                                                           role  cnt\n",
      "0       Arianne Boileau  Participated in: Household Zooarchaeology of Colonial Lamanai    2\n",
      "1       Jeanne Nijhowne                                    Participated in: Kenan Tepe    1\n",
      "2  Sarah Whitcher Kansa                         Participated in: Domuztepe Excavations    1\n",
      "3          Alfred Galik                   Participated in: Bar√ßƒ±n H√∂y√ºk Zooarchaeology    1\n",
      "4     Marshall C. Agnew                Participated in: Petra Great Temple Excavations    1\n",
      "5   Anna Eleanor Soifer                                         Participated in: Murlo    1\n",
      "6          Chuck Easton                                    Participated in: Kenan Tepe    1\n",
      "7                   MSC                Participated in: Petra Great Temple Excavations    1\n",
      "8                   CJA                Participated in: Petra Great Temple Excavations    1\n",
      "9        Arek Marciniak             Participated in: √áatalh√∂y√ºk Area TP Zooarchaeology    1\n"
     ]
    }
   ],
   "source": [
    "# NARROW formats: Same approach - otype filter\n",
    "# SQL Complexity: 0 CTEs, 0 JOINs - simple otype filter\n",
    "print(\"=== ZENODO NARROW (full iSamples) ===\")\n",
    "zenodo_narrow_agents, zenodo_narrow_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT name, role, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['zenodo_narrow']}')\n",
    "    WHERE otype = 'Agent'\n",
    "    GROUP BY name, role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents\")\n",
    "print(zenodo_narrow_agents.to_string())\n",
    "\n",
    "print(\"\\n=== ERIC NARROW (OpenContext only) ===\")\n",
    "eric_narrow_agents, eric_narrow_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT name, role, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['eric_narrow']}')\n",
    "    WHERE otype = 'Agent'\n",
    "    GROUP BY name, role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents\")\n",
    "print(eric_narrow_agents.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT (full iSamples) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f827ab887d4e41b809849e7be4415e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All agents (from nested): 4438.3ms, 10 rows\n",
      "                                                             name     role      cnt\n",
      "0                                              Curator,,Collector     None  3516917\n",
      "1  Curator Integrated Ocean Drilling Program (TAMU),,Sample Owner     None  3516905\n",
      "2                                       Adam Mansur,,Sample Owner     None   383835\n",
      "3                                    Edward Gilbert,,Sample Owner     None   258790\n",
      "4                                               Julie A. Hoggarth  creator   161623\n",
      "5                                                      Andrea Kay  creator   161623\n",
      "6                                              Marc Vander Linden  creator   161623\n",
      "7                                                   Jose Capriles  creator   161623\n",
      "8                                                 Steinar Solheim  creator   161623\n",
      "9                                                R. Kyle Bocinsky  creator   161623\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Must scan all samples and extract from nested structs\n",
    "# SQL Complexity: 1 subquery, 0 JOINs - but FULL TABLE SCAN required\n",
    "# This is MUCH slower because agents are embedded in every sample row\n",
    "print(\"=== EXPORT (full iSamples) ===\")\n",
    "export_agents, export_agents_time = timed_query(con, f\"\"\"\n",
    "    SELECT \n",
    "        resp.name as name,\n",
    "        resp.role as role,\n",
    "        COUNT(*) as cnt\n",
    "    FROM (\n",
    "        SELECT unnest(produced_by.responsibility) as resp\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE produced_by IS NOT NULL \n",
    "          AND produced_by.responsibility IS NOT NULL\n",
    "    )\n",
    "    GROUP BY resp.name, resp.role\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\", \"All agents (from nested)\")\n",
    "print(export_agents.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTITY LISTING SUMMARY ===\n",
      "\n",
      "Full iSamples (apples-to-apples):\n",
      "  Zenodo Wide:     24.2ms (SQL: 0 JOINs, otype filter)\n",
      "  Zenodo Narrow:   57.5ms (SQL: 0 JOINs, otype filter)\n",
      "  Export:        4438.3ms (SQL: 0 JOINs, FULL SCAN)\n",
      "\n",
      "OpenContext only (Eric's files):\n",
      "  Eric Wide:        4.8ms\n",
      "  Eric Narrow:      7.6ms\n",
      "\n",
      "‚ö†Ô∏è Export is 10-100x SLOWER for entity listing!\n",
      "   Reason: Agents are embedded in every sample row, requiring full scan\n",
      "   PQG: Agents are separate rows, filtered by otype = 'Agent'\n"
     ]
    }
   ],
   "source": [
    "# Agent listing summary\n",
    "print(\"=== ENTITY LISTING SUMMARY ===\")\n",
    "print(\"\\nFull iSamples (apples-to-apples):\")\n",
    "print(f\"  Zenodo Wide:   {zenodo_wide_agents_time:6.1f}ms (SQL: 0 JOINs, otype filter)\")\n",
    "print(f\"  Zenodo Narrow: {zenodo_narrow_agents_time:6.1f}ms (SQL: 0 JOINs, otype filter)\")\n",
    "print(f\"  Export:        {export_agents_time:6.1f}ms (SQL: 0 JOINs, FULL SCAN)\")\n",
    "\n",
    "print(\"\\nOpenContext only (Eric's files):\")\n",
    "print(f\"  Eric Wide:     {eric_wide_agents_time:6.1f}ms\")\n",
    "print(f\"  Eric Narrow:   {eric_narrow_agents_time:6.1f}ms\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Export is 10-100x SLOWER for entity listing!\")\n",
    "print(\"   Reason: Agents are embedded in every sample row, requiring full scan\")\n",
    "print(\"   PQG: Agents are separate rows, filtered by otype = 'Agent'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Reverse Lookup: Samples by Agent\n",
    "\n",
    "**Use case**: \"Show me all samples collected by Agent X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for samples by: Vance Vredenburg\n"
     ]
    }
   ],
   "source": [
    "# First, pick an agent name that exists in all formats\n",
    "# Using a common agent from the data\n",
    "AGENT_NAME = 'Vance Vredenburg'  # Adjust based on your data\n",
    "\n",
    "print(f\"Looking for samples by: {AGENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT ===\n",
      "Samples by Vance Vredenburg: 260.6ms, 10 rows\n",
      "     sample_identifier label\n",
      "0   ark:/21547/DSz2757   757\n",
      "1   ark:/21547/DSz2779   779\n",
      "2   ark:/21547/DSz2806   806\n",
      "3   ark:/21547/DSz2807   807\n",
      "4   ark:/21547/DSz2759   759\n",
      "5   ark:/21547/DSz2761   761\n",
      "6   ark:/21547/DSz2967   967\n",
      "7   ark:/21547/DSz2763   763\n",
      "8   ark:/21547/DSz2979   979\n",
      "9  ark:/21547/DSz21792  1792\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Filter on nested struct\n",
    "print(\"=== EXPORT ===\")\n",
    "export_by_agent, export_time = timed_query(con, f\"\"\"\n",
    "    SELECT sample_identifier, label\n",
    "    FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE list_contains(\n",
    "        [r.name FOR r IN produced_by.responsibility],\n",
    "        '{AGENT_NAME}'\n",
    "    )\n",
    "    LIMIT 10\n",
    "\"\"\", f\"Samples by {AGENT_NAME}\")\n",
    "print(export_by_agent.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE (full iSamples) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b2be66feab406790bd82b2bd9e5567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples by Vance Vredenburg: 6769.7ms, 10 rows\n",
      "     sample_identifier label\n",
      "0   ark:/21547/DSz2757   757\n",
      "1   ark:/21547/DSz2779   779\n",
      "2   ark:/21547/DSz2806   806\n",
      "3   ark:/21547/DSz2807   807\n",
      "4   ark:/21547/DSz2759   759\n",
      "5   ark:/21547/DSz2761   761\n",
      "6   ark:/21547/DSz2967   967\n",
      "7   ark:/21547/DSz2763   763\n",
      "8   ark:/21547/DSz2979   979\n",
      "9  ark:/21547/DSz21792  1792\n"
     ]
    }
   ],
   "source": [
    "# WIDE: Find agent row_id, then find samples with that row_id in p__responsibility\n",
    "# Note: Agent may not exist in Eric's OC-only data, so use Zenodo Wide for full coverage\n",
    "print(\"=== ZENODO WIDE (full iSamples) ===\")\n",
    "zenodo_wide_by_agent, zenodo_wide_by_agent_time = timed_query(con, f\"\"\"\n",
    "    WITH agent AS (\n",
    "        SELECT row_id \n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "        WHERE otype = 'Agent' AND name = '{AGENT_NAME}'\n",
    "        LIMIT 1\n",
    "    ),\n",
    "    events AS (\n",
    "        SELECT w.row_id as event_id\n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}') w, agent\n",
    "        WHERE w.otype = 'SamplingEvent' \n",
    "          AND list_contains(w.p__responsibility, agent.row_id)\n",
    "    )\n",
    "    SELECT s.sample_identifier, s.label\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}') s, events\n",
    "    WHERE s.otype = 'MaterialSampleRecord'\n",
    "      AND list_contains(s.p__produced_by, events.event_id)\n",
    "    LIMIT 10\n",
    "\"\"\", f\"Samples by {AGENT_NAME}\")\n",
    "print(zenodo_wide_by_agent.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REVERSE LOOKUP SUMMARY ===\n",
      "Export:      260.6ms (10 rows)\n",
      "Zenodo Wide: 6769.7ms (10 rows)\n",
      "\n",
      "Note: Export's nested list_contains is efficient for this pattern\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n=== REVERSE LOOKUP SUMMARY ===\")\n",
    "print(f\"Export:      {export_time:.1f}ms ({len(export_by_agent)} rows)\")\n",
    "print(f\"Zenodo Wide: {zenodo_wide_by_agent_time:.1f}ms ({len(zenodo_wide_by_agent)} rows)\")\n",
    "print(\"\\nNote: Export's nested list_contains is efficient for this pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Sample Detail: Get Full Info for One Sample\n",
    "\n",
    "**Use case**: User clicks on a sample, show all details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: ark:/21547/DSz2757\n"
     ]
    }
   ],
   "source": [
    "# Pick a sample identifier\n",
    "SAMPLE_ID = con.sql(f\"\"\"\n",
    "    SELECT sample_identifier FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE sample_identifier IS NOT NULL LIMIT 1\n",
    "\"\"\").fetchone()[0]\n",
    "print(f\"Sample: {SAMPLE_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORT ===\n",
      "Time: 93.7ms\n",
      "Columns returned: 19\n",
      "                                                                           0\n",
      "sample_identifier                                         ark:/21547/DSz2757\n",
      "@id                                                   metadata/21547/DSz2757\n",
      "label                                                                    757\n",
      "description                                 basisOfRecord: PreservedSpecimen\n",
      "source_collection                                                      GEOME\n",
      "has_sample_object_type     [{'identifier': 'https://w3id.org/isample/voca...\n",
      "has_material_category      [{'identifier': 'https://w3id.org/isample/voca...\n",
      "has_context_category       [{'identifier': 'https://w3id.org/isample/biol...\n",
      "informal_classification                                 [Taricha, granulosa]\n",
      "keywords                     [{'keyword': 'California'}, {'keyword': 'USA'}]\n",
      "produced_by                {'description': 'expeditionCode: newts | proje...\n",
      "last_modified_time                                 1893-12-31 16:07:00-07:53\n",
      "curation                                                                <NA>\n",
      "registrant                                                              <NA>\n",
      "related_resource                                                        <NA>\n",
      "sampling_purpose                                                        <NA>\n",
      "sample_location_longitude                                         -122.57861\n",
      "sample_location_latitude                                           38.578888\n",
      "geometry                   [1, 1, 0, 0, 0, 222, 200, 60, 242, 7, 165, 94,...\n"
     ]
    }
   ],
   "source": [
    "# EXPORT: Everything on one row\n",
    "print(\"=== EXPORT ===\")\n",
    "start = time.time()\n",
    "result = con.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('{PATHS['export']}')\n",
    "    WHERE sample_identifier = '{SAMPLE_ID}'\n",
    "\"\"\").fetchdf()\n",
    "export_time = (time.time() - start) * 1000\n",
    "print(f\"Time: {export_time:.1f}ms\")\n",
    "print(f\"Columns returned: {len(result.columns)}\")\n",
    "print(result.T)  # Transpose for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ZENODO WIDE ===\n",
      "Time: 49.2ms\n",
      "Rows returned: 1\n",
      "Columns returned: 49\n",
      "Note: This only returns the sample row, not related entities\n",
      "                                    0\n",
      "sample_identifier  ark:/21547/DSz2757\n",
      "label                             757\n"
     ]
    }
   ],
   "source": [
    "# ZENODO WIDE: Need to JOIN related entities\n",
    "print(\"=== ZENODO WIDE ===\")\n",
    "start = time.time()\n",
    "# This is more complex - would need multiple JOINs to get full picture\n",
    "result = con.sql(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE sample_identifier = '{SAMPLE_ID}'\n",
    "\"\"\").fetchdf()\n",
    "zenodo_wide_detail_time = (time.time() - start) * 1000\n",
    "print(f\"Time: {zenodo_wide_detail_time:.1f}ms\")\n",
    "print(f\"Rows returned: {len(result)}\")\n",
    "if len(result) > 0:\n",
    "    print(f\"Columns returned: {len(result.columns)}\")\n",
    "    print(\"Note: This only returns the sample row, not related entities\")\n",
    "    print(result[['sample_identifier', 'label']].T)\n",
    "else:\n",
    "    print(\"Note: Sample not found (may be from GEOME source, not in this sample_identifier format)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Storage Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Data</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>Bytes/Row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Export</td>\n",
       "      <td>Full</td>\n",
       "      <td>297.0</td>\n",
       "      <td>6,680,932</td>\n",
       "      <td>19</td>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zenodo Narrow</td>\n",
       "      <td>Full</td>\n",
       "      <td>860.1</td>\n",
       "      <td>101,387,180</td>\n",
       "      <td>40</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zenodo Wide</td>\n",
       "      <td>Full</td>\n",
       "      <td>291.8</td>\n",
       "      <td>20,729,358</td>\n",
       "      <td>49</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric Narrow</td>\n",
       "      <td>OC only</td>\n",
       "      <td>724.5</td>\n",
       "      <td>11,637,144</td>\n",
       "      <td>40</td>\n",
       "      <td>62.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Wide</td>\n",
       "      <td>OC only</td>\n",
       "      <td>288.7</td>\n",
       "      <td>2,464,690</td>\n",
       "      <td>47</td>\n",
       "      <td>117.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Format     Data Size (MB)         Rows  Columns Bytes/Row\n",
       "0         Export     Full     297.0    6,680,932       19      44.5\n",
       "1  Zenodo Narrow     Full     860.1  101,387,180       40       8.5\n",
       "2    Zenodo Wide     Full     291.8   20,729,358       49      14.1\n",
       "3    Eric Narrow  OC only     724.5   11,637,144       40      62.3\n",
       "4      Eric Wide  OC only     288.7    2,464,690       47     117.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File sizes and efficiency\n",
    "def get_file_size_mb(path):\n",
    "    \"\"\"Get file size - returns None for URLs (size unknown without HEAD request).\"\"\"\n",
    "    if path is None:\n",
    "        return None\n",
    "    if isinstance(path, str) and path.startswith('http'):\n",
    "        return None  # Can't easily get URL size\n",
    "    p = Path(path)\n",
    "    if p.exists():\n",
    "        return p.stat().st_size / 1e6\n",
    "    return None\n",
    "\n",
    "storage = []\n",
    "for name in ['export', 'zenodo_narrow', 'zenodo_wide', 'eric_narrow', 'eric_wide']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        size_mb = get_file_size_mb(path)\n",
    "        rows = row_counts.get(name, 0)\n",
    "        cols = len(schemas.get(name, []))\n",
    "        bytes_per_row = (size_mb * 1e6) / rows if (size_mb and rows > 0) else None\n",
    "        data_scope = 'Full' if name in ['export', 'zenodo_narrow', 'zenodo_wide'] else 'OC only'\n",
    "        is_remote = isinstance(path, str) and path.startswith('http')\n",
    "        storage.append({\n",
    "            'Format': name.replace('_', ' ').title(),\n",
    "            'Data': data_scope,\n",
    "            'Size (MB)': f'{size_mb:.1f}' if size_mb else 'Remote',\n",
    "            'Rows': f'{rows:,}',\n",
    "            'Columns': cols,\n",
    "            'Bytes/Row': f'{bytes_per_row:.1f}' if bytes_per_row else 'N/A',\n",
    "        })\n",
    "\n",
    "pd.DataFrame(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Benchmark Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T23:45:11.827621Z",
     "iopub.status.busy": "2025-12-10T23:45:11.827559Z",
     "iopub.status.idle": "2025-12-10T23:45:11.830598Z",
     "shell.execute_reply": "2025-12-10T23:45:11.830215Z"
    }
   },
   "source": [
    "### Benchmark Results Summary\n",
    "\n",
    "**Data Coverage Verification:**\n",
    "- ‚úÖ Export, Zenodo Narrow, Zenodo Wide all contain **6,680,932 samples** from all 4 sources\n",
    "- ‚úÖ Eric's Narrow/Wide contain OpenContext subset (~1.1M samples)\n",
    "\n",
    "| Query Pattern | Best For | SQL Complexity | Notes |\n",
    "|--------------|----------|----------------|-------|\n",
    "| **Map (all coords)** | Export ‚âà Zenodo Wide | Simple SELECT | Both ~30ms for 6M points |\n",
    "| **Facets (material counts)** | Export | 1 subquery vs 2 CTEs + JOIN | Export has URIs, PQG has labels |\n",
    "| **Entity listing (agents)** | PQG formats | 0 JOINs (otype filter) | Export requires full scan |\n",
    "| **Reverse lookup by agent** | Export | list_contains() | Only works if agent exists |\n",
    "| **Sample detail (one row)** | Export | Simple WHERE | All data on single row |\n",
    "\n",
    "**Key tradeoffs:**\n",
    "- **Export**: Best for UI (map + facets + detail) but slow for entity listing\n",
    "- **PQG Wide**: Good balance - entities queryable, reasonable JOIN complexity\n",
    "- **PQG Narrow**: Most flexible but slower (92M rows including edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions: When to Use Each Format\n",
    "\n",
    "### Export Format\n",
    "**Best for:**\n",
    "- UI queries (map, search, facets)\n",
    "- Sample-centric analysis\n",
    "- When you don't need to query entities independently\n",
    "\n",
    "**Avoid when:**\n",
    "- You need to list all agents/sites/concepts\n",
    "- You need graph traversal flexibility\n",
    "- You need incremental updates\n",
    "\n",
    "### Wide Format\n",
    "**Best for:**\n",
    "- Entity-centric queries (\"all agents\", \"all sites\")\n",
    "- Analytical dashboards\n",
    "- When you need both samples AND other entity types\n",
    "\n",
    "**Avoid when:**\n",
    "- Pure sample queries (Export is faster)\n",
    "- Complex multi-hop traversals (Narrow is more natural)\n",
    "\n",
    "### Narrow Format\n",
    "**Best for:**\n",
    "- Archival/preservation (full fidelity)\n",
    "- Graph algorithms\n",
    "- Relationship exploration\n",
    "- When you need to traverse in any direction\n",
    "\n",
    "**Avoid when:**\n",
    "- Interactive UI (too slow)\n",
    "- Simple sample queries (overkill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights\n",
    "\n",
    "### What Export Gains\n",
    "1. **No JOINs** - Everything on one row\n",
    "2. **Pre-extracted coords** - `sample_location_latitude/longitude` at top level\n",
    "3. **Fewer rows** - 6.7M vs 19.5M vs 92M\n",
    "\n",
    "### What Export Loses\n",
    "1. **Entity independence** - Can't query agents without scanning all samples\n",
    "2. **Graph flexibility** - Can't traverse in arbitrary directions\n",
    "3. **Incremental updates** - Must regenerate entire file\n",
    "\n",
    "### The `list_contains()` Problem\n",
    "Both Wide (p__* arrays) and Export (nested structs) suffer from O(n) scans when searching within arrays. Neither has index support in DuckDB/Parquet.\n",
    "\n",
    "### Recommendation for Eric's UI\n",
    "For the iSamples Central UI requirements:\n",
    "- **Start with Export format** - fastest for map + facets + click-to-detail\n",
    "- **Pre-compute H3 aggregations** - for initial map render\n",
    "- **Pre-compute facet counts** - avoid runtime aggregation\n",
    "- **Keep Wide/Narrow for advanced queries** - entity exploration, graph traversal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization with Lonboard\n",
    "\n",
    "Now let's visualize the coordinate data we queried earlier using **Lonboard** - a high-performance WebGL-based mapping library for Jupyter.\n",
    "\n",
    "**Key considerations for 6M+ points:**\n",
    "- Use sampling to avoid memory issues\n",
    "- Color by source collection for insight\n",
    "- Compare visualization speed across formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Lonboard available for visualization\n"
     ]
    }
   ],
   "source": [
    "# Import visualization libraries\n",
    "try:\n",
    "    from lonboard import Map, ScatterplotLayer\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    import numpy as np\n",
    "    LONBOARD_AVAILABLE = True\n",
    "    print(\"‚úÖ Lonboard available for visualization\")\n",
    "except ImportError as e:\n",
    "    LONBOARD_AVAILABLE = False\n",
    "    print(f\"‚ö†Ô∏è Lonboard not available: {e}\")\n",
    "    print(\"   Install with: pip install lonboard geopandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying 50,000 random samples from Export format...\n",
      "Query time: 70.9ms, 45,123 points\n",
      "\n",
      "Sample distribution by source:\n",
      "source_collection\n",
      "SESAR          32711\n",
      "OPENCONTEXT     8138\n",
      "GEOME           3057\n",
      "SMITHSONIAN     1217\n"
     ]
    }
   ],
   "source": [
    "# Visualize a sample of points from EXPORT format (includes source_collection for coloring)\n",
    "if LONBOARD_AVAILABLE:\n",
    "    SAMPLE_SIZE = 50000  # Adjust based on your system's memory\n",
    "    \n",
    "    print(f\"Querying {SAMPLE_SIZE:,} random samples from Export format...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Export has source_collection and pre-extracted coords - ideal for visualization\n",
    "    viz_data = con.sql(f\"\"\"\n",
    "        SELECT \n",
    "            sample_location_longitude as lon,\n",
    "            sample_location_latitude as lat,\n",
    "            source_collection,\n",
    "            sample_identifier\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE sample_location_latitude IS NOT NULL\n",
    "        USING SAMPLE {SAMPLE_SIZE}\n",
    "    \"\"\").fetchdf()\n",
    "    \n",
    "    query_time = (time.time() - start) * 1000\n",
    "    print(f\"Query time: {query_time:.1f}ms, {len(viz_data):,} points\")\n",
    "    \n",
    "    # Show distribution by source\n",
    "    print(\"\\nSample distribution by source:\")\n",
    "    print(viz_data['source_collection'].value_counts().to_string())\n",
    "else:\n",
    "    print(\"Skipping visualization (Lonboard not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è Visualizing 45,123 points colored by source:\n",
      "   SESAR: 32,711 points\n",
      "   OPENCONTEXT: 8,138 points\n",
      "   GEOME: 3,057 points\n",
      "   SMITHSONIAN: 1,217 points\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ab48e1ac7643fe9f08b5c4ff04311a",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(custom_attribution='', layers=(ScatterplotLayer(get_fill_color=arro3.core.ChunkedArray<FixedSizeList(Field‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the Lonboard visualization with color by source collection\n",
    "if LONBOARD_AVAILABLE and len(viz_data) > 0:\n",
    "    from IPython.display import display\n",
    "    \n",
    "    # Define colors for each source collection\n",
    "    SOURCE_COLORS = {\n",
    "        'SESAR': [255, 99, 71, 200],      # Tomato red\n",
    "        'OPENCONTEXT': [65, 105, 225, 200], # Royal blue  \n",
    "        'GEOME': [50, 205, 50, 200],       # Lime green\n",
    "        'SMITHSONIAN': [255, 215, 0, 200], # Gold\n",
    "    }\n",
    "    DEFAULT_COLOR = [128, 128, 128, 200]  # Gray for unknown\n",
    "    \n",
    "    # Create geometry from coordinates\n",
    "    geometry = gpd.points_from_xy(viz_data['lon'], viz_data['lat'])\n",
    "    gdf = gpd.GeoDataFrame(viz_data, geometry=geometry, crs=\"EPSG:4326\")\n",
    "    \n",
    "    # Create color array (RGBA as uint8)\n",
    "    colors = np.array([\n",
    "        SOURCE_COLORS.get(src, DEFAULT_COLOR) \n",
    "        for src in viz_data['source_collection']\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    # Create ScatterplotLayer\n",
    "    layer = ScatterplotLayer.from_geopandas(\n",
    "        gdf,\n",
    "        get_fill_color=colors,\n",
    "        get_radius=3000,  # meters\n",
    "        radius_min_pixels=2,\n",
    "        radius_max_pixels=10,\n",
    "        opacity=0.8,\n",
    "        pickable=True,\n",
    "    )\n",
    "    \n",
    "    # Create map\n",
    "    m = Map(layer)\n",
    "    \n",
    "    print(f\"üó∫Ô∏è Visualizing {len(gdf):,} points colored by source:\")\n",
    "    for src, color in SOURCE_COLORS.items():\n",
    "        count = (viz_data['source_collection'] == src).sum()\n",
    "        if count > 0:\n",
    "            print(f\"   {src}: {count:,} points\")\n",
    "    \n",
    "    # Display the map explicitly\n",
    "    display(m)\n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Enhanced Popup with Sample Details\n",
    "\n",
    "The basic visualization only shows `sample_identifier` and `source_collection`. This enhanced version extracts nested fields so clicking a point shows:\n",
    "- **materials**: Material categories (anthropogenicmetal, rock, etc.)\n",
    "- **context**: Sampled feature context (pasthumanoccupationsite, etc.)\n",
    "- **object_type**: Sample object type\n",
    "- **site_name**: Sampling site name\n",
    "- **keywords**: Associated keywords\n",
    "- **description**: Full sample description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying 10,000 samples with full details...\n",
      "Got 8,937 samples with full details\n",
      "Columns available in popup: ['sample_identifier', 'label', 'description', 'source_collection', 'lat', 'lon', 'materials', 'context', 'object_type', 'site_name', 'keywords', 'curation', 'registrant']\n",
      "\n",
      "üó∫Ô∏è Click any point to see full sample details!\n",
      "   Properties shown: label, materials, context, site_name, keywords, etc.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a9aa4ac4e1490199f996526b7df335",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(custom_attribution='', layers=(ScatterplotLayer(get_fill_color=arro3.core.ChunkedArray<FixedSizeList(Field‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enhanced visualization with full sample details in popup\n",
    "if LONBOARD_AVAILABLE:\n",
    "    from IPython.display import display\n",
    "    \n",
    "    SAMPLE_SIZE = 10000  # Smaller sample for richer data\n",
    "    \n",
    "    print(f'Querying {SAMPLE_SIZE:,} samples with full details...')\n",
    "    \n",
    "    # Enhanced query extracting nested fields for popup display\n",
    "    enhanced_data = con.sql(f\"\"\"\n",
    "        SELECT \n",
    "            sample_identifier,\n",
    "            label,\n",
    "            LEFT(description, 150) as description,\n",
    "            source_collection,\n",
    "            sample_location_latitude as lat,\n",
    "            sample_location_longitude as lon,\n",
    "            -- Extract and join material categories\n",
    "            array_to_string(\n",
    "                list_transform(has_material_category, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as materials,\n",
    "            -- Extract context categories\n",
    "            array_to_string(\n",
    "                list_transform(has_context_category, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as context,\n",
    "            -- Extract object types\n",
    "            array_to_string(\n",
    "                list_transform(has_sample_object_type, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as object_type,\n",
    "            -- Sampling site info\n",
    "            produced_by.sampling_site.label as site_name,\n",
    "            -- Keywords\n",
    "            array_to_string(\n",
    "                list_transform(keywords, x -> x.keyword),\n",
    "                ', '\n",
    "            ) as keywords,\n",
    "            -- Curation\n",
    "            curation.label as curation,\n",
    "            -- Registrant\n",
    "            registrant.name as registrant\n",
    "        FROM read_parquet('{PATHS[\"export\"]}')\n",
    "        WHERE sample_location_latitude IS NOT NULL\n",
    "        USING SAMPLE {SAMPLE_SIZE}\n",
    "    \"\"\").fetchdf()\n",
    "    \n",
    "    print(f'Got {len(enhanced_data):,} samples with full details')\n",
    "    print(f'Columns available in popup: {list(enhanced_data.columns)}')\n",
    "    \n",
    "    # Create geometry\n",
    "    geometry = gpd.points_from_xy(enhanced_data['lon'], enhanced_data['lat'])\n",
    "    enhanced_gdf = gpd.GeoDataFrame(enhanced_data, geometry=geometry, crs='EPSG:4326')\n",
    "    \n",
    "    # Color by source\n",
    "    colors = np.array([\n",
    "        SOURCE_COLORS.get(src, DEFAULT_COLOR) \n",
    "        for src in enhanced_data['source_collection']\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    # Create layer with pickable=True for click popups\n",
    "    enhanced_layer = ScatterplotLayer.from_geopandas(\n",
    "        enhanced_gdf,\n",
    "        get_fill_color=colors,\n",
    "        get_radius=3000,\n",
    "        radius_min_pixels=2,\n",
    "        radius_max_pixels=10,\n",
    "        opacity=0.8,\n",
    "        pickable=True,  # Enable click to see all properties\n",
    "    )\n",
    "    \n",
    "    enhanced_map = Map(enhanced_layer)\n",
    "    \n",
    "    print('\\nüó∫Ô∏è Click any point to see full sample details!')\n",
    "    print('   Properties shown: label, materials, context, site_name, keywords, etc.')\n",
    "    \n",
    "    display(enhanced_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Visualizing from Wide Format\n",
    "\n",
    "The PQG Wide format stores coordinates in `GeospatialCoordLocation` rows with `otype` filter.\n",
    "The `n` column contains the source collection (named graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying 10,000 samples from Wide format...\n",
      "Query time: 140.7ms, 2,846 points\n",
      "\n",
      "üó∫Ô∏è Wide format: 2,846 points\n",
      "source_collection\n",
      "SESAR          2065\n",
      "OPENCONTEXT     505\n",
      "GEOME           151\n",
      "SMITHSONIAN     125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f919fd866e7d4d209d55bc07ce960da7",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(custom_attribution='', layers=(ScatterplotLayer(get_fill_color=arro3.core.ChunkedArray<FixedSizeList(Field‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize from WIDE format (uses `n` column for source, `otype` for filtering)\n",
    "if LONBOARD_AVAILABLE:\n",
    "    from IPython.display import display\n",
    "    \n",
    "    print(f\"Querying {SAMPLE_SIZE:,} samples from Wide format...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    # Wide format uses `n` for named graph (source collection) and otype filter\n",
    "    wide_viz_data = con.sql(f\"\"\"\n",
    "        SELECT \n",
    "            longitude as lon,\n",
    "            latitude as lat,\n",
    "            n as source_collection,  -- Named graph contains source\n",
    "            pid as sample_identifier\n",
    "        FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "        WHERE otype = 'GeospatialCoordLocation' \n",
    "          AND latitude IS NOT NULL\n",
    "        USING SAMPLE {SAMPLE_SIZE}\n",
    "    \"\"\").fetchdf()\n",
    "    \n",
    "    query_time = (time.time() - start) * 1000\n",
    "    print(f\"Query time: {query_time:.1f}ms, {len(wide_viz_data):,} points\")\n",
    "    \n",
    "    # Create geometry and colors\n",
    "    geometry = gpd.points_from_xy(wide_viz_data['lon'], wide_viz_data['lat'])\n",
    "    wide_gdf = gpd.GeoDataFrame(wide_viz_data, geometry=geometry, crs=\"EPSG:4326\")\n",
    "    \n",
    "    colors = np.array([\n",
    "        SOURCE_COLORS.get(src, DEFAULT_COLOR) \n",
    "        for src in wide_viz_data['source_collection']\n",
    "    ], dtype=np.uint8)\n",
    "    \n",
    "    # Create layer and map\n",
    "    wide_layer = ScatterplotLayer.from_geopandas(\n",
    "        wide_gdf,\n",
    "        get_fill_color=colors,\n",
    "        get_radius=3000,\n",
    "        radius_min_pixels=2,\n",
    "        radius_max_pixels=10,\n",
    "        opacity=0.8,\n",
    "        pickable=True,\n",
    "    )\n",
    "    \n",
    "    wide_map = Map(wide_layer)\n",
    "    \n",
    "    print(f\"\\nüó∫Ô∏è Wide format: {len(wide_gdf):,} points\")\n",
    "    print(wide_viz_data['source_collection'].value_counts().to_string())\n",
    "    \n",
    "    # Display the map explicitly\n",
    "    display(wide_map)\n",
    "else:\n",
    "    print(\"Skipping (Lonboard not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Visualization Tips\n",
    "\n",
    "**Memory Management for 6M+ Points:**\n",
    "- Use `USING SAMPLE N` to limit points (shown above)\n",
    "- Or use `LIMIT` with `ORDER BY RANDOM()` for reproducible sampling\n",
    "- For full dataset: consider H3 hexbin aggregation first\n",
    "\n",
    "**Format Comparison for Visualization:**\n",
    "\n",
    "| Format | Query | Source Color | Notes |\n",
    "|--------|-------|--------------|-------|\n",
    "| **Export** | Direct `lat/lon` columns | `source_collection` | Fastest, simplest |\n",
    "| **Wide** | Filter `otype='GeospatialCoordLocation'` | `n` (named graph) | Slightly slower |\n",
    "| **Narrow** | Same as Wide | Same as Wide | Slowest (most rows) |\n",
    "\n",
    "**Color Scheme Used:**\n",
    "- üî¥ SESAR (geological): Tomato red\n",
    "- üîµ OPENCONTEXT (archaeological): Royal blue  \n",
    "- üü¢ GEOME (biological): Lime green\n",
    "- üü° SMITHSONIAN (museum): Gold\n",
    "\n",
    "**Next Steps:**\n",
    "- See `geoparquet.ipynb` for more advanced memory-efficient strategies\n",
    "- See `isample-archive.ipynb` for remote parquet visualization patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Browser Visualization with Cesium\n",
    "\n",
    "For web-based 3D globe visualization, use **CesiumJS** with **DuckDB-WASM**. This enables:\n",
    "- No server required - runs entirely in browser\n",
    "- 3D globe with terrain\n",
    "- Click-to-query sample details\n",
    "- Works with remote parquet files via HTTP range requests\n",
    "\n",
    "**Reference implementations:**\n",
    "- `isamplesorg.github.io/tutorials/parquet_cesium_isamples_wide.qmd` - Quarto tutorial with live demo\n",
    "- Remote parquet URLs work directly in browser:\n",
    "  ```javascript\n",
    "  const db = await AsyncDuckDB.create();\n",
    "  await db.open({path: ':memory:'});\n",
    "  const result = await db.query(`\n",
    "    SELECT latitude, longitude, pid\n",
    "    FROM read_parquet('https://pub-a18234d962364c22a50c787b7ca09fa5.r2.dev/isamples_202601_wide.parquet')\n",
    "    WHERE otype = 'GeospatialCoordLocation'\n",
    "    LIMIT 10000\n",
    "  `);\n",
    "  ```\n",
    "\n",
    "**Lonboard vs Cesium:**\n",
    "\n",
    "| Feature | Lonboard (Jupyter) | Cesium (Browser) |\n",
    "|---------|-------------------|------------------|\n",
    "| Environment | Jupyter notebooks | Web pages/Quarto |\n",
    "| Rendering | 2D WebGL | 3D Globe |\n",
    "| Best for | Data exploration | Public demos |\n",
    "| Max points | ~500K comfortable | ~100K with clustering |\n",
    "| Interactivity | Pan/zoom, hover | Click, terrain, 3D |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Focus Sites: PKAP and Poggio Civitate\n",
    "\n",
    "To make the 6M+ sample dataset more tangible, let's explore two well-documented OpenContext archaeological sites:\n",
    "\n",
    "| Site | Location | Coordinates | Scale |\n",
    "|------|----------|-------------|-------|\n",
    "| **PKAP** | Pyla-Koutsopetria, Cyprus | 34.99¬∞N, 33.71¬∞E | 544 locations, 15K+ events |\n",
    "| **Poggio Civitate** | Murlo, Tuscany, Italy | 43.15¬∞N, 11.40¬∞E | 11K+ locations, 30K events |\n",
    "\n",
    "These sites demonstrate:\n",
    "- How coordinates cluster around archaeological excavations\n",
    "- The relationship between samples, events, and locations\n",
    "- Real-world query patterns for site-specific analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç PKAP: Pyla-Koutsopetria Archaeological Project\n",
      "   Location: Cyprus\n",
      "   Center: 34.9874¬∞N, 33.7080¬∞E\n",
      "   Bbox: [34.94, 33.66] to [35.04, 33.76]\n",
      "\n",
      "üìç Poggio: Poggio Civitate\n",
      "   Location: Murlo, Tuscany, Italy\n",
      "   Center: 43.1500¬∞N, 11.4000¬∞E\n",
      "   Bbox: [43.05, 11.30] to [43.25, 11.50]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define focus sites\n",
    "FOCUS_SITES = {\n",
    "    'PKAP': {\n",
    "        'name': 'Pyla-Koutsopetria Archaeological Project',\n",
    "        'location': 'Cyprus',\n",
    "        'lat': 34.987406,\n",
    "        'lon': 33.708047,\n",
    "        'radius_deg': 0.05,  # ~5km bounding box\n",
    "    },\n",
    "    'Poggio': {\n",
    "        'name': 'Poggio Civitate',\n",
    "        'location': 'Murlo, Tuscany, Italy', \n",
    "        'lat': 43.15,\n",
    "        'lon': 11.40,\n",
    "        'radius_deg': 0.1,  # ~10km bounding box\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_site_bbox(site):\n",
    "    \"\"\"Get bounding box for a focus site.\"\"\"\n",
    "    return {\n",
    "        'min_lat': site['lat'] - site['radius_deg'],\n",
    "        'max_lat': site['lat'] + site['radius_deg'],\n",
    "        'min_lon': site['lon'] - site['radius_deg'],\n",
    "        'max_lon': site['lon'] + site['radius_deg'],\n",
    "    }\n",
    "\n",
    "# Display site info\n",
    "for key, site in FOCUS_SITES.items():\n",
    "    bbox = get_site_bbox(site)\n",
    "    print(f\"üìç {key}: {site['name']}\")\n",
    "    print(f\"   Location: {site['location']}\")\n",
    "    print(f\"   Center: {site['lat']:.4f}¬∞N, {site['lon']:.4f}¬∞E\")\n",
    "    print(f\"   Bbox: [{bbox['min_lat']:.2f}, {bbox['min_lon']:.2f}] to [{bbox['max_lat']:.2f}, {bbox['max_lon']:.2f}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Query Site Data from Export Format\n",
    "\n",
    "The Export format makes spatial queries simple - just filter on lat/lon columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PKAP: Pyla-Koutsopetria Archaeological Project ===\n",
      "Found 23,313 samples in 39.3ms\n",
      "Coordinate range: [34.9802, 33.7007] to [34.9974, 33.7183]\n",
      "Unique locations: 492\n",
      "\n",
      "=== Poggio: Poggio Civitate ===\n",
      "Found 43,439 samples in 41.1ms\n",
      "Coordinate range: [43.0600, 11.3009] to [43.1931, 11.4533]\n",
      "Unique locations: 6,453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query samples from each focus site using Export format\n",
    "site_data = {}\n",
    "\n",
    "for key, site in FOCUS_SITES.items():\n",
    "    bbox = get_site_bbox(site)\n",
    "    \n",
    "    print(f\"=== {key}: {site['name']} ===\")\n",
    "    start = time.time()\n",
    "    \n",
    "    df = con.sql(f\"\"\"\n",
    "        SELECT \n",
    "            sample_identifier,\n",
    "            label,\n",
    "            sample_location_latitude as lat,\n",
    "            sample_location_longitude as lon,\n",
    "            source_collection\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE sample_location_latitude BETWEEN {bbox['min_lat']} AND {bbox['max_lat']}\n",
    "          AND sample_location_longitude BETWEEN {bbox['min_lon']} AND {bbox['max_lon']}\n",
    "    \"\"\").fetchdf()\n",
    "    \n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    site_data[key] = df\n",
    "    \n",
    "    print(f\"Found {len(df):,} samples in {elapsed:.1f}ms\")\n",
    "    print(f\"Coordinate range: [{df['lat'].min():.4f}, {df['lon'].min():.4f}] to [{df['lat'].max():.4f}, {df['lon'].max():.4f}]\")\n",
    "    print(f\"Unique locations: {df.groupby(['lat', 'lon']).ngroups:,}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Visualize PKAP (Cyprus)\n",
    "\n",
    "Zoomed view of the Pyla-Koutsopetria Archaeological Project survey area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è PKAP: 23,313 samples at 492 unique locations\n",
      "   Center: 34.9874¬∞N, 33.7080¬∞E\n",
      "   Click any point to see: materials, context, object_type, site_name, keywords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bacfe1a24d460a8ac59d95971659c9",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(custom_attribution='', layers=(ScatterplotLayer(get_fill_color=arro3.core.ChunkedArray<FixedSizeList(Field‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize PKAP site with ENHANCED popup data\n",
    "if LONBOARD_AVAILABLE and 'PKAP' in FOCUS_SITES:\n",
    "    from IPython.display import display\n",
    "\n",
    "    site = FOCUS_SITES['PKAP']\n",
    "    bbox = get_site_bbox(site)\n",
    "\n",
    "    # Query with enhanced fields for rich popup\n",
    "    pkap_enhanced = con.sql(f\"\"\"\n",
    "        SELECT\n",
    "            sample_identifier,\n",
    "            label,\n",
    "            LEFT(description, 150) as description,\n",
    "            source_collection,\n",
    "            sample_location_latitude as lat,\n",
    "            sample_location_longitude as lon,\n",
    "            -- Extract material categories\n",
    "            array_to_string(\n",
    "                list_transform(has_material_category, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as materials,\n",
    "            -- Extract context categories\n",
    "            array_to_string(\n",
    "                list_transform(has_context_category, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as context,\n",
    "            -- Extract object types\n",
    "            array_to_string(\n",
    "                list_transform(has_sample_object_type, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as object_type,\n",
    "            -- Sampling site info\n",
    "            produced_by.sampling_site.label as site_name,\n",
    "            -- Keywords\n",
    "            array_to_string(\n",
    "                list_transform(keywords, x -> x.keyword),\n",
    "                ', '\n",
    "            ) as keywords\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE sample_location_latitude BETWEEN {bbox['min_lat']} AND {bbox['max_lat']}\n",
    "          AND sample_location_longitude BETWEEN {bbox['min_lon']} AND {bbox['max_lon']}\n",
    "    \"\"\").fetchdf()\n",
    "\n",
    "    # Create geometry\n",
    "    geometry = gpd.points_from_xy(pkap_enhanced['lon'], pkap_enhanced['lat'])\n",
    "    pkap_gdf = gpd.GeoDataFrame(pkap_enhanced, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Single color for site-specific view (blue)\n",
    "    colors = np.full((len(pkap_gdf), 4), [65, 105, 225, 200], dtype=np.uint8)\n",
    "\n",
    "    # Create layer with pickable=True for enhanced popup\n",
    "    pkap_layer = ScatterplotLayer.from_geopandas(\n",
    "        pkap_gdf,\n",
    "        get_fill_color=colors,\n",
    "        get_radius=50,  # smaller radius for zoomed view\n",
    "        radius_min_pixels=3,\n",
    "        radius_max_pixels=8,\n",
    "        opacity=0.8,\n",
    "        pickable=True,\n",
    "    )\n",
    "\n",
    "    # Create map centered on site\n",
    "    pkap_map = Map(pkap_layer)\n",
    "    pkap_map.set_view_state(latitude=site['lat'], longitude=site['lon'], zoom=14)\n",
    "\n",
    "    print(f\"üó∫Ô∏è PKAP: {len(pkap_gdf):,} samples at {pkap_gdf.groupby(['lat', 'lon']).ngroups:,} unique locations\")\n",
    "    print(f\"   Center: {site['lat']:.4f}¬∞N, {site['lon']:.4f}¬∞E\")\n",
    "    print(f\"   Click any point to see: materials, context, object_type, site_name, keywords\")\n",
    "\n",
    "    display(pkap_map)\n",
    "else:\n",
    "    print(\"PKAP data not available or Lonboard not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Visualize Poggio Civitate (Tuscany)\n",
    "\n",
    "Zoomed view of the Poggio Civitate excavation site in Murlo, Italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è Poggio Civitate: 43,439 samples at 6,453 unique locations\n",
      "   Center: 43.1500¬∞N, 11.4000¬∞E\n",
      "   Click any point to see: materials, context, object_type, site_name, keywords\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9efb91154974228acbd5f4d1ea7d34f",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Map(custom_attribution='', layers=(ScatterplotLayer(get_fill_color=arro3.core.ChunkedArray<FixedSizeList(Field‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Poggio Civitate site with ENHANCED popup data\n",
    "if LONBOARD_AVAILABLE and 'Poggio' in FOCUS_SITES:\n",
    "    from IPython.display import display\n",
    "\n",
    "    site = FOCUS_SITES['Poggio']\n",
    "    bbox = get_site_bbox(site)\n",
    "\n",
    "    # Query with enhanced fields for rich popup\n",
    "    poggio_enhanced = con.sql(f\"\"\"\n",
    "        SELECT\n",
    "            sample_identifier,\n",
    "            label,\n",
    "            LEFT(description, 150) as description,\n",
    "            source_collection,\n",
    "            sample_location_latitude as lat,\n",
    "            sample_location_longitude as lon,\n",
    "            -- Extract material categories\n",
    "            array_to_string(\n",
    "                list_transform(has_material_category, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as materials,\n",
    "            -- Extract context categories\n",
    "            array_to_string(\n",
    "                list_transform(has_context_category, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as context,\n",
    "            -- Extract object types\n",
    "            array_to_string(\n",
    "                list_transform(has_sample_object_type, x -> split_part(x.identifier, '/', -1)),\n",
    "                ', '\n",
    "            ) as object_type,\n",
    "            -- Sampling site info\n",
    "            produced_by.sampling_site.label as site_name,\n",
    "            -- Keywords\n",
    "            array_to_string(\n",
    "                list_transform(keywords, x -> x.keyword),\n",
    "                ', '\n",
    "            ) as keywords\n",
    "        FROM read_parquet('{PATHS['export']}')\n",
    "        WHERE sample_location_latitude BETWEEN {bbox['min_lat']} AND {bbox['max_lat']}\n",
    "          AND sample_location_longitude BETWEEN {bbox['min_lon']} AND {bbox['max_lon']}\n",
    "    \"\"\").fetchdf()\n",
    "\n",
    "    # Create geometry\n",
    "    geometry = gpd.points_from_xy(poggio_enhanced['lon'], poggio_enhanced['lat'])\n",
    "    poggio_gdf = gpd.GeoDataFrame(poggio_enhanced, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Single color for site-specific view (tomato red)\n",
    "    colors = np.full((len(poggio_gdf), 4), [255, 99, 71, 200], dtype=np.uint8)\n",
    "\n",
    "    # Create layer with pickable=True for enhanced popup\n",
    "    poggio_layer = ScatterplotLayer.from_geopandas(\n",
    "        poggio_gdf,\n",
    "        get_fill_color=colors,\n",
    "        get_radius=20,  # even smaller for dense site\n",
    "        radius_min_pixels=2,\n",
    "        radius_max_pixels=6,\n",
    "        opacity=0.7,\n",
    "        pickable=True,\n",
    "    )\n",
    "\n",
    "    # Create map centered on site\n",
    "    poggio_map = Map(poggio_layer)\n",
    "    poggio_map.set_view_state(latitude=site['lat'], longitude=site['lon'], zoom=15)\n",
    "\n",
    "    print(f\"üó∫Ô∏è Poggio Civitate: {len(poggio_gdf):,} samples at {poggio_gdf.groupby(['lat', 'lon']).ngroups:,} unique locations\")\n",
    "    print(f\"   Center: {site['lat']:.4f}¬∞N, {site['lon']:.4f}¬∞E\")\n",
    "    print(f\"   Click any point to see: materials, context, object_type, site_name, keywords\")\n",
    "\n",
    "    display(poggio_map)\n",
    "else:\n",
    "    print(\"Poggio Civitate data not available or Lonboard not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 Site-Specific Material Analysis\n",
    "\n",
    "What materials were found at each site? This demonstrates practical site-level queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40 material labels from vocabulary file\n",
      "\n",
      "=== PKAP: Material Categories ===\n",
      "                        material    cnt\n",
      "0   Anthropogenic metal material  22576\n",
      "1                           Rock  22114\n",
      "2  Biogenic non-organic material  21889\n",
      "3         Natural Solid Material   1199\n",
      "4                    ceramicclay   1013\n",
      "5               Organic material    737\n",
      "6     Any anthropogenic material    411\n",
      "\n",
      "=== Poggio: Material Categories ===\n",
      "                        material    cnt\n",
      "0   Anthropogenic metal material  19745\n",
      "1  Biogenic non-organic material  17208\n",
      "2     Any anthropogenic material  11891\n",
      "3                           Rock  10818\n",
      "4         Natural Solid Material   9116\n",
      "5                    ceramicclay   5926\n",
      "6               Organic material   5250\n",
      "7                       Material   1732\n"
     ]
    }
   ],
   "source": [
    "# Material categories at each site\n",
    "# Load official iSamples vocabulary labels from material_hierarchy.json\n",
    "# Source: https://github.com/isamplesorg/isamples_inabox/blob/develop/isb_web/static/controlled_vocabulary/material_hierarchy.json\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "VOCAB_PATH = Path.home() / 'C/src/iSamples/isamples_inabox/isb_web/static/controlled_vocabulary/material_hierarchy.json'\n",
    "\n",
    "def extract_labels_from_hierarchy(node, result=None):\n",
    "    \"\"\"Recursively extract URI -> label mappings from vocabulary hierarchy.\"\"\"\n",
    "    if result is None:\n",
    "        result = {}\n",
    "    \n",
    "    for uri, data in node.items():\n",
    "        if isinstance(data, dict):\n",
    "            if 'label' in data and 'en' in data['label']:\n",
    "                # Store both 0.9 and 1.0 versions (data uses 1.0)\n",
    "                uri_1_0 = uri.replace('/0.9/', '/1.0/')\n",
    "                result[uri_1_0] = data['label']['en']\n",
    "                result[uri] = data['label']['en']\n",
    "            if 'children' in data:\n",
    "                for child in data['children']:\n",
    "                    extract_labels_from_hierarchy(child, result)\n",
    "    return result\n",
    "\n",
    "# Load vocabulary and build lookup\n",
    "if VOCAB_PATH.exists():\n",
    "    with open(VOCAB_PATH) as f:\n",
    "        vocab_hierarchy = json.load(f)\n",
    "    URI_TO_LABEL = extract_labels_from_hierarchy(vocab_hierarchy)\n",
    "    print(f\"Loaded {len(URI_TO_LABEL)} material labels from vocabulary file\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Vocabulary file not found: {VOCAB_PATH}\")\n",
    "    URI_TO_LABEL = {}\n",
    "\n",
    "def get_material_label(uri):\n",
    "    \"\"\"Get human-readable label for a material URI.\"\"\"\n",
    "    return URI_TO_LABEL.get(uri, uri.split('/')[-1])\n",
    "\n",
    "# Query and display materials for each site\n",
    "for key, site in FOCUS_SITES.items():\n",
    "    bbox = get_site_bbox(site)\n",
    "    \n",
    "    print(f\"\\n=== {key}: Material Categories ===\")\n",
    "    \n",
    "    result = con.sql(f\"\"\"\n",
    "        SELECT \n",
    "            mat.identifier as uri,\n",
    "            COUNT(*) as cnt\n",
    "        FROM (\n",
    "            SELECT unnest(has_material_category) as mat\n",
    "            FROM read_parquet('{PATHS['export']}')\n",
    "            WHERE sample_location_latitude BETWEEN {bbox['min_lat']} AND {bbox['max_lat']}\n",
    "              AND sample_location_longitude BETWEEN {bbox['min_lon']} AND {bbox['max_lon']}\n",
    "              AND has_material_category IS NOT NULL\n",
    "        )\n",
    "        GROUP BY mat.identifier\n",
    "        ORDER BY cnt DESC\n",
    "        LIMIT 8\n",
    "    \"\"\").fetchdf()\n",
    "    \n",
    "    # Add friendly label from vocabulary\n",
    "    result['material'] = result['uri'].apply(get_material_label)\n",
    "    \n",
    "    # Display with friendly labels\n",
    "    print(result[['material', 'cnt']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 Data Format Question: Should PQG Include Labels?\n",
    "\n",
    "**Current state:**\n",
    "- **Export format**: `has_material_category` only contains `identifier` (URI), no label\n",
    "- **Zenodo Wide/Narrow**: `IdentifiedConcept.label` = URI (not human-readable)\n",
    "- **Eric's Wide**: `IdentifiedConcept.label` = human-readable (vocabulary lookup applied)\n",
    "\n",
    "**The question:** Should Zenodo Wide/Narrow `IdentifiedConcept` rows include:\n",
    "1. Just the URI (current) - requires external vocabulary lookup\n",
    "2. Just the label - loses precise identifier\n",
    "3. Both URI and label - redundant but self-contained\n",
    "\n",
    "**Tradeoffs:**\n",
    "\n",
    "| Approach | File Size | Query Simplicity | Vocabulary Updates |\n",
    "|----------|-----------|------------------|-------------------|\n",
    "| URI only | Smaller | Need JOIN to vocab | Easy to re-label |\n",
    "| Label only | Smaller | Direct display | Stuck with old labels |\n",
    "| Both | Larger | Best of both | Must regenerate |\n",
    "\n",
    "**Recommendation:** Include both `pid` (URI) and `label` (human-readable) in `IdentifiedConcept` rows. The ~50K concept rows are tiny compared to 6M+ samples, so the size increase is negligible.\n",
    "\n",
    "**Vocabulary source:** \n",
    "- Local: `~/C/src/iSamples/isamples_inabox/isb_web/static/controlled_vocabulary/material_hierarchy.json`\n",
    "- GitHub: https://github.com/isamplesorg/isamples_inabox/blob/develop/isb_web/static/controlled_vocabulary/material_hierarchy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Eric's OpenContext vs Zenodo: Data Quality Analysis\n",
    "\n",
    "Eric's OpenContext parquet files were generated directly from OpenContext data, while Zenodo files were exported via the iSamples Central API. This section compares the two to understand what data was lost or gained in each conversion pipeline.\n",
    "\n",
    "**Key question**: Can we merge the best of both sources?\n",
    "\n",
    "See [pqg issue #13](https://github.com/isamplesorg/pqg/issues/13) for the full analysis and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ERIC vs ZENODO: Row Counts (Zenodo filtered to n='OPENCONTEXT')\n",
      "======================================================================\n",
      "eric_wide: 2,464,690 rows\n",
      "zenodo_wide: 3,302,952 rows\n",
      "eric_narrow: 11,637,144 rows\n",
      "zenodo_narrow: 22,437,356 rows\n",
      "\n",
      "======================================================================\n",
      "ENTITY TYPE COMPARISON (Wide Format)\n",
      "======================================================================\n",
      "                  otype  eric_cnt  zenodo_cnt    diff\n",
      "   MaterialSampleRecord   1110412     1064831   45581\n",
      "          SamplingEvent   1110412     1059103   51309\n",
      "GeospatialCoordLocation    199147     1059025 -859878\n",
      "      IdentifiedConcept     25929           0   25929\n",
      "           SamplingSite     18213      119993 -101780\n",
      "                  Agent       577           0     577\n"
     ]
    }
   ],
   "source": [
    "# Compare Eric's OpenContext files with Zenodo (filtered to OpenContext)\n",
    "print(\"=\" * 70)\n",
    "print(\"ERIC vs ZENODO: Row Counts (Zenodo filtered to n='OPENCONTEXT')\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_data = []\n",
    "for name in ['eric_wide', 'zenodo_wide', 'eric_narrow', 'zenodo_narrow']:\n",
    "    path = PATHS.get(name)\n",
    "    if path_available(path):\n",
    "        if 'zenodo' in name:\n",
    "            # Filter to OpenContext only for fair comparison\n",
    "            count = con.sql(f\"\"\"\n",
    "                SELECT COUNT(*) FROM read_parquet('{path}')\n",
    "                WHERE n = 'OPENCONTEXT'\n",
    "            \"\"\").fetchone()[0]\n",
    "        else:\n",
    "            count = con.sql(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n",
    "        comparison_data.append({'Format': name, 'Rows': count})\n",
    "        print(f\"{name}: {count:,} rows\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ENTITY TYPE COMPARISON (Wide Format)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Compare otypes between Eric and Zenodo\n",
    "eric_otypes = con.sql(f\"\"\"\n",
    "    SELECT otype, COUNT(*) as eric_cnt\n",
    "    FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    GROUP BY otype\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "zenodo_otypes = con.sql(f\"\"\"\n",
    "    SELECT otype, COUNT(*) as zenodo_cnt\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE n = 'OPENCONTEXT'\n",
    "    GROUP BY otype\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Merge and compare\n",
    "otype_comparison = eric_otypes.merge(zenodo_otypes, on='otype', how='outer').fillna(0)\n",
    "otype_comparison['eric_cnt'] = otype_comparison['eric_cnt'].astype(int)\n",
    "otype_comparison['zenodo_cnt'] = otype_comparison['zenodo_cnt'].astype(int)\n",
    "otype_comparison['diff'] = otype_comparison['eric_cnt'] - otype_comparison['zenodo_cnt']\n",
    "otype_comparison = otype_comparison.sort_values('eric_cnt', ascending=False)\n",
    "print(otype_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "KEY FIELD POPULATION: Eric vs Zenodo (OpenContext)\n",
      "======================================================================\n",
      "\n",
      "--- Project field (SamplingEvent) ---\n",
      "Eric (top 5 projects):\n",
      "                       project    cnt\n",
      "       Cross-referenced p3k14c 166959\n",
      "     √áatalh√∂y√ºk Zooarchaeology 126116\n",
      "Petra Great Temple Excavations 108846\n",
      "          Excavations at Polis  52252\n",
      "  Avkat Archaeological Project  43448\n",
      "\n",
      "Zenodo: 1,059,103 / 1,059,103 have NULL project (100%)\n",
      "\n",
      "--- Coordinates on MaterialSampleRecord ---\n",
      "Eric: 0 / 1,110,412 have coordinates (0.0%)\n",
      "Zenodo: 1,059,025 / 1,064,831 have coordinates (99.5%)\n",
      "\n",
      "--- IdentifiedConcept labels ---\n",
      "Eric (domain-specific labels):\n",
      "             label  cnt\n",
      "     Side :: Right   27\n",
      "      Side :: Left   26\n",
      "Element :: Scapula   22\n",
      "Element :: Humerus   22\n",
      "  Element :: Femur   21\n",
      "\n",
      "Zenodo (URI-based labels):\n",
      "                                                                      label  cnt\n",
      "                  https://w3id.org/isample/vocabulary/material/1.0/material    1\n",
      "https://w3id.org/isample/vocabulary/sampledfeature/1.0/terrestrialwaterbody    1\n",
      "             https://w3id.org/isample/biology/biosampledfeature/1.0/Plantae    1\n",
      "                      https://w3id.org/isample/vocabulary/material/1.0/rock    1\n",
      "                       https://w3id.org/isample/vocabulary/material/1.0/gas    1\n"
     ]
    }
   ],
   "source": [
    "# Key field population comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"KEY FIELD POPULATION: Eric vs Zenodo (OpenContext)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Project field (SamplingEvent)\n",
    "print(\"\\n--- Project field (SamplingEvent) ---\")\n",
    "eric_projects = con.sql(f\"\"\"\n",
    "    SELECT project, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    WHERE otype = 'SamplingEvent' AND project IS NOT NULL\n",
    "    GROUP BY project ORDER BY cnt DESC LIMIT 5\n",
    "\"\"\").fetchdf()\n",
    "print(\"Eric (top 5 projects):\")\n",
    "print(eric_projects.to_string(index=False))\n",
    "\n",
    "zenodo_project_null = con.sql(f\"\"\"\n",
    "    SELECT COUNT(*) FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'SamplingEvent' AND n = 'OPENCONTEXT' AND project IS NULL\n",
    "\"\"\").fetchone()[0]\n",
    "zenodo_project_total = con.sql(f\"\"\"\n",
    "    SELECT COUNT(*) FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'SamplingEvent' AND n = 'OPENCONTEXT'\n",
    "\"\"\").fetchone()[0]\n",
    "print(f\"\\nZenodo: {zenodo_project_null:,} / {zenodo_project_total:,} have NULL project ({100*zenodo_project_null/zenodo_project_total:.0f}%)\")\n",
    "\n",
    "# Coordinates on MaterialSampleRecord\n",
    "print(\"\\n--- Coordinates on MaterialSampleRecord ---\")\n",
    "eric_coords = con.sql(f\"\"\"\n",
    "    SELECT COUNT(*) FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    WHERE otype = 'MaterialSampleRecord' AND latitude IS NOT NULL \n",
    "      AND CAST(latitude AS VARCHAR) != 'nan'\n",
    "\"\"\").fetchone()[0]\n",
    "eric_total = con.sql(f\"\"\"\n",
    "    SELECT COUNT(*) FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    WHERE otype = 'MaterialSampleRecord'\n",
    "\"\"\").fetchone()[0]\n",
    "print(f\"Eric: {eric_coords:,} / {eric_total:,} have coordinates ({100*eric_coords/eric_total:.1f}%)\")\n",
    "\n",
    "zenodo_coords = con.sql(f\"\"\"\n",
    "    SELECT COUNT(*) FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'MaterialSampleRecord' AND n = 'OPENCONTEXT' \n",
    "      AND latitude IS NOT NULL\n",
    "\"\"\").fetchone()[0]\n",
    "zenodo_total = con.sql(f\"\"\"\n",
    "    SELECT COUNT(*) FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'MaterialSampleRecord' AND n = 'OPENCONTEXT'\n",
    "\"\"\").fetchone()[0]\n",
    "print(f\"Zenodo: {zenodo_coords:,} / {zenodo_total:,} have coordinates ({100*zenodo_coords/zenodo_total:.1f}%)\")\n",
    "\n",
    "# IdentifiedConcept comparison\n",
    "print(\"\\n--- IdentifiedConcept labels ---\")\n",
    "print(\"Eric (domain-specific labels):\")\n",
    "eric_concepts = con.sql(f\"\"\"\n",
    "    SELECT label, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['eric_wide']}')\n",
    "    WHERE otype = 'IdentifiedConcept'\n",
    "    GROUP BY label ORDER BY cnt DESC LIMIT 5\n",
    "\"\"\").fetchdf()\n",
    "print(eric_concepts.to_string(index=False))\n",
    "\n",
    "print(\"\\nZenodo (URI-based labels):\")\n",
    "zenodo_concepts = con.sql(f\"\"\"\n",
    "    SELECT label, COUNT(*) as cnt\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE otype = 'IdentifiedConcept'\n",
    "    GROUP BY label ORDER BY cnt DESC LIMIT 5\n",
    "\"\"\").fetchdf()\n",
    "print(zenodo_concepts.to_string(index=False) if len(zenodo_concepts) > 0 else \"(no OC-specific concepts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 Summary: Eric vs Zenodo\n",
    "\n",
    "| Aspect | Eric's Files | Zenodo Files |\n",
    "|--------|--------------|--------------|\n",
    "| **MaterialSampleRecord** | 1,110,412 | 1,064,831 |\n",
    "| **SamplingEvent** | 1,110,412 | 1,059,103 |\n",
    "| **GeospatialCoordLocation** | 199,147 | 1,059,025 |\n",
    "| **IdentifiedConcept** | 25,929 | 0 (OC-specific) |\n",
    "| **Agent** | 577 | 0 |\n",
    "\n",
    "**Field Population:**\n",
    "\n",
    "| Field | Eric | Zenodo |\n",
    "|-------|------|--------|\n",
    "| `project` (SamplingEvent) | 100% populated | 0% (all NULL) |\n",
    "| Coords on MaterialSampleRecord | 0% | 99.5% |\n",
    "| `last_modified_time` | 100% | 0% |\n",
    "| `alternate_identifiers` | 100% | 0% |\n",
    "\n",
    "**Key Differences:**\n",
    "\n",
    "1. **Coordinate Strategy**: Eric stores coords only on GeospatialCoordLocation (~5.8 samples share each location). Zenodo propagates coords to MaterialSampleRecord (1:1 mapping).\n",
    "\n",
    "2. **Project Data**: Eric preserves project names (\"√áatalh√∂y√ºk Zooarchaeology\", \"Petra Great Temple\"). Zenodo lost this during Central API export.\n",
    "\n",
    "3. **IdentifiedConcept**: Eric has domain-specific labels (\"Element :: Scapula\"). Zenodo has URI strings.\n",
    "\n",
    "**Recommendation**: Merge the best of both - use Eric's project/concept/agent data with Zenodo's coordinate propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. PQG Library: Querying with Narrow Format\n",
    "\n",
    "The pqg library provides **full query support for narrow format** files:\n",
    "- `PQG` class: Load graph, traverse relations, get nodes\n",
    "- `TypedEdgeQueries`: Query edges by the 14 edge types\n",
    "- Edge type utilities: Inference, discovery, validation\n",
    "\n",
    "**Narrow vs Wide Format**:\n",
    "| Feature | Narrow | Wide |\n",
    "|---------|--------|------|\n",
    "| Edge storage | Explicit `_edge_` rows | `p__*` columns |\n",
    "| File size | ~844 MB | ~282 MB |\n",
    "| PQG query support | Full | Validation only |\n",
    "| Best for | Graph traversal | Entity analytics |\n",
    "\n",
    "See [pqg issue #11](https://github.com/isamplesorg/pqg/issues/11) for unified API proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pqg with 14 edge types\n"
     ]
    }
   ],
   "source": [
    "# Add pqg library to path\n",
    "# NOTE: pqg requires linkml-runtime. Install with: pip install -e ~/C/src/iSamples/pqg\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.home() / 'C/src/iSamples/pqg'))\n",
    "\n",
    "try:\n",
    "    from pqg import PQG, ISamplesEdgeType, EDGE_TYPE_CONSTRAINTS\n",
    "    from pqg import get_edge_types_by_subject, get_edge_types_by_object, infer_edge_type\n",
    "    from pqg.typed_edges import TypedEdgeQueries\n",
    "    from pqg.schemas import get_schema_from_parquet, SchemaFormat\n",
    "    PQG_AVAILABLE = True\n",
    "    print(f'Loaded pqg with {len(list(ISamplesEdgeType))} edge types')\n",
    "except ImportError as e:\n",
    "    PQG_AVAILABLE = False\n",
    "    print(f'pqg library not available: {e}')\n",
    "    print('To fix: pip install -e ~/C/src/iSamples/pqg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Source version of None different to current of 0.2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: zenodo_narrow_2025-12-12.parquet\n",
      "Detected format: narrow\n",
      "\n",
      "Graph loaded!\n",
      "Entity types: (loaded from parquet metadata)\n"
     ]
    }
   ],
   "source": [
    "# Load the NARROW format parquet file into PQG\n",
    "if not PQG_AVAILABLE:\n",
    "    print('PQG not available; install pqg first')\n",
    "else:\n",
    "    import duckdb\n",
    "    from pathlib import Path\n",
    "    \n",
    "    narrow_path = PATHS.get('zenodo_narrow')\n",
    "    narrow_path = Path(narrow_path) if narrow_path else None\n",
    "    if narrow_path and narrow_path.exists():\n",
    "        # Detect format first (pqg expects a string path/URL)\n",
    "        schema, detected_format = get_schema_from_parquet(str(narrow_path))\n",
    "        print(f'File: {narrow_path.name}')\n",
    "        print(f'Detected format: {detected_format.value}')\n",
    "        \n",
    "        # Load into PQG (requires connection + source path)\n",
    "        pqg_con = duckdb.connect()\n",
    "        graph = PQG(pqg_con, str(narrow_path))\n",
    "        \n",
    "        if hasattr(graph, 'loadMetadata'):\n",
    "            graph.loadMetadata()\n",
    "        elif hasattr(graph, 'load_metadata'):\n",
    "            graph.load_metadata()\n",
    "        \n",
    "        print('\\nGraph loaded!')\n",
    "        types = getattr(graph, '_types', {})\n",
    "        print(f\"Entity types: {list(types.keys()) or '(loaded from parquet metadata)'}\")\n",
    "    else:\n",
    "        print(f'Narrow format file not found locally: {narrow_path}')\n",
    "        print('Download from:', URLS.get('zenodo_narrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE 14 ISAMPLES EDGE TYPES\n",
      "============================================================\n",
      "\n",
      "MaterialSampleCuration:\n",
      "   1. --responsibility-->[*] Agent\n",
      "\n",
      "MaterialSampleRecord:\n",
      "   2. --curation-->[1] MaterialSampleCuration\n",
      "   3. --has_context_category-->[*] IdentifiedConcept\n",
      "   4. --has_material_category-->[*] IdentifiedConcept\n",
      "   5. --has_sample_object_type-->[*] IdentifiedConcept\n",
      "   6. --keywords-->[*] IdentifiedConcept\n",
      "   7. --produced_by-->[1] SamplingEvent\n",
      "   8. --registrant-->[1] Agent\n",
      "   9. --related_resource-->[*] SampleRelation\n",
      "\n",
      "SamplingEvent:\n",
      "  10. --has_context_category-->[*] IdentifiedConcept\n",
      "  11. --responsibility-->[*] Agent\n",
      "  12. --sample_location-->[1] GeospatialCoordLocation\n",
      "  13. --sampling_site-->[1] SamplingSite\n",
      "\n",
      "SamplingSite:\n",
      "  14. --site_location-->[1] GeospatialCoordLocation\n"
     ]
    }
   ],
   "source": [
    "# The 14 edge types in iSamples schema\n",
    "if PQG_AVAILABLE:\n",
    "    print('THE 14 ISAMPLES EDGE TYPES')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    current_subject = None\n",
    "    for i, et in enumerate(ISamplesEdgeType, 1):\n",
    "        if et.subject_type != current_subject:\n",
    "            current_subject = et.subject_type\n",
    "            print(f'\\n{current_subject}:')\n",
    "        \n",
    "        constraints = EDGE_TYPE_CONSTRAINTS.get(et.value, {})\n",
    "        multivalued = '*' if constraints.get('multivalued', False) else '1'\n",
    "        print(f'  {i:2d}. --{et.predicate}-->[{multivalued}] {et.object_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDGE TYPE INFERENCE\n",
      "--------------------------------------------------\n",
      "(MaterialSampleRecord, produced_by, SamplingEvent)\n",
      "  -> MSR_PRODUCED_BY\n",
      "(SamplingEvent, sample_location, GeospatialCoordLocation)\n",
      "  -> EVENT_SAMPLE_LOCATION\n",
      "(SamplingEvent, responsibility, Agent)\n",
      "  -> EVENT_RESPONSIBILITY\n",
      "(MaterialSampleCuration, responsibility, Agent)\n",
      "  -> CURATION_RESPONSIBILITY\n"
     ]
    }
   ],
   "source": [
    "# Infer edge type from subject-predicate-object triple\n",
    "if PQG_AVAILABLE:\n",
    "    print('EDGE TYPE INFERENCE')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    test_cases = [\n",
    "        ('MaterialSampleRecord', 'produced_by', 'SamplingEvent'),\n",
    "        ('SamplingEvent', 'sample_location', 'GeospatialCoordLocation'),\n",
    "        ('SamplingEvent', 'responsibility', 'Agent'),\n",
    "        ('MaterialSampleCuration', 'responsibility', 'Agent'),  # Same predicate!\n",
    "    ]\n",
    "    \n",
    "    for s, p, o in test_cases:\n",
    "        edge_type = infer_edge_type(s, p, o)\n",
    "        print(f'({s}, {p}, {o})')\n",
    "        print(f'  -> {edge_type.name if edge_type else \"None\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDGE TYPES BY SUBJECT\n",
      "--------------------------------------------------\n",
      "\n",
      "MaterialSampleRecord (8 edges):\n",
      "  -> curation -> MaterialSampleCuration\n",
      "  -> has_context_category -> IdentifiedConcept\n",
      "  -> has_material_category -> IdentifiedConcept\n",
      "  -> has_sample_object_type -> IdentifiedConcept\n",
      "  -> keywords -> IdentifiedConcept\n",
      "  -> produced_by -> SamplingEvent\n",
      "  -> registrant -> Agent\n",
      "  -> related_resource -> SampleRelation\n",
      "\n",
      "SamplingEvent (4 edges):\n",
      "  -> has_context_category -> IdentifiedConcept\n",
      "  -> responsibility -> Agent\n",
      "  -> sample_location -> GeospatialCoordLocation\n",
      "  -> sampling_site -> SamplingSite\n",
      "\n",
      "==================================================\n",
      "EDGE TYPES BY OBJECT\n",
      "--------------------------------------------------\n",
      "\n",
      "Agent (3 incoming edges):\n",
      "  <- MaterialSampleCuration via responsibility\n",
      "  <- MaterialSampleRecord via registrant\n",
      "  <- SamplingEvent via responsibility\n",
      "\n",
      "GeospatialCoordLocation (2 incoming edges):\n",
      "  <- SamplingEvent via sample_location\n",
      "  <- SamplingSite via site_location\n"
     ]
    }
   ],
   "source": [
    "# Find edge types by subject or object type\n",
    "if PQG_AVAILABLE:\n",
    "    print('EDGE TYPES BY SUBJECT')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    for subject in ['MaterialSampleRecord', 'SamplingEvent']:\n",
    "        types = get_edge_types_by_subject(subject)\n",
    "        print(f'\\n{subject} ({len(types)} edges):')\n",
    "        for et in types:\n",
    "            print(f'  -> {et.predicate} -> {et.object_type}')\n",
    "    \n",
    "    print('\\n' + '=' * 50)\n",
    "    print('EDGE TYPES BY OBJECT')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    for obj in ['Agent', 'GeospatialCoordLocation']:\n",
    "        types = get_edge_types_by_object(obj)\n",
    "        print(f'\\n{obj} ({len(types)} incoming edges):')\n",
    "        for et in types:\n",
    "            print(f'  <- {et.subject_type} via {et.predicate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRAPH TRAVERSAL (PQG.getRelations)\n",
      "============================================================\n",
      "\n",
      "Sample relations (first 10):\n",
      "  ark:/21547/DSz2757... --produced_by-> ark:/21547/DSz2757_event...\n",
      "  ark:/21547/DSz2779... --produced_by-> ark:/21547/DSz2779_event...\n",
      "  ark:/21547/DSz2806... --produced_by-> ark:/21547/DSz2806_event...\n",
      "  ark:/21547/DSz2807... --produced_by-> ark:/21547/DSz2807_event...\n",
      "  ark:/21547/DSz2759... --produced_by-> ark:/21547/DSz2759_event...\n",
      "  ark:/21547/DSz2761... --produced_by-> ark:/21547/DSz2761_event...\n",
      "  ark:/21547/DSz2967... --produced_by-> ark:/21547/DSz2967_event...\n",
      "  ark:/21547/DSz2763... --produced_by-> ark:/21547/DSz2763_event...\n",
      "  ark:/21547/DSz2979... --produced_by-> ark:/21547/DSz2979_event...\n",
      "  ark:/21547/DSz21792... --produced_by-> ark:/21547/DSz21792_event...\n",
      "\n",
      "Relations with predicate \"produced_by\" (first 5):\n",
      "  ark:/21547/DSz2757 -> ark:/21547/DSz2757_event\n",
      "  ark:/21547/DSz2779 -> ark:/21547/DSz2779_event\n",
      "  ark:/21547/DSz2806 -> ark:/21547/DSz2806_event\n",
      "  ark:/21547/DSz2807 -> ark:/21547/DSz2807_event\n",
      "  ark:/21547/DSz2759 -> ark:/21547/DSz2759_event\n"
     ]
    }
   ],
   "source": [
    "# Use PQG.getRelations() to traverse the graph\n",
    "if PQG_AVAILABLE and 'graph' in dir():\n",
    "    print('GRAPH TRAVERSAL (PQG.getRelations)')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Sample relations\n",
    "    print('\\nSample relations (first 10):')\n",
    "    for i, (s, p, o) in enumerate(graph.getRelations(maxrows=10)):\n",
    "        print(f'  {s[:35]}... --{p}-> {o[:35]}...')\n",
    "    \n",
    "    # Filter by predicate\n",
    "    print('\\nRelations with predicate \"produced_by\" (first 5):')\n",
    "    for i, (s, p, o) in enumerate(graph.getRelations(predicate='produced_by', maxrows=5)):\n",
    "        print(f'  {s[:40]} -> {o[:40]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPED EDGE QUERIES\n",
      "============================================================\n",
      "\n",
      "MSR_PRODUCED_BY:\n",
      "  ark:/21547/EDS2BOMAN_11071 -> ark:/21547/EDS2BOMAN_11071_eve...\n",
      "  ark:/21547/EDS2BOMAN_11076 -> ark:/21547/EDS2BOMAN_11076_eve...\n",
      "  ark:/21547/EDS2BOMAN_11068 -> ark:/21547/EDS2BOMAN_11068_eve...\n",
      "  (showing 3 of many)\n",
      "\n",
      "EVENT_SAMPLE_LOCATION:\n",
      "  IGSN:ODP01HGJI_event -> IGSN:ODP01HGJI_location...\n",
      "  IGSN:ODP01HGJJ_event -> IGSN:ODP01HGJJ_location...\n",
      "  IGSN:ODP01HGJH_event -> IGSN:ODP01HGJH_location...\n",
      "  (showing 3 of many)\n"
     ]
    }
   ],
   "source": [
    "# Use TypedEdgeQueries to query by edge type\n",
    "if PQG_AVAILABLE and 'graph' in dir():\n",
    "    print('TYPED EDGE QUERIES')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    typed = TypedEdgeQueries(graph)\n",
    "    \n",
    "    # Sample edges of specific types\n",
    "    for edge_type in [ISamplesEdgeType.MSR_PRODUCED_BY, \n",
    "                      ISamplesEdgeType.EVENT_SAMPLE_LOCATION]:\n",
    "        print(f'\\n{edge_type.name}:')\n",
    "        count = 0\n",
    "        for s_pid, p, o_pids, n, et in typed.get_edges_by_type(edge_type, limit=3):\n",
    "            print(f'  {s_pid[:40]} -> {o_pids[0][:30] if o_pids else \"?\"}...')\n",
    "            count += 1\n",
    "        print(f'  (showing {count} of many)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQG LIBRARY SUMMARY\n",
      "============================================================\n",
      "\n",
      "Format Detection:\n",
      "  get_schema_from_parquet(path) -> (schema, format)\n",
      "\n",
      "Narrow Format Query APIs:\n",
      "  PQG class:\n",
      "    - getNode(pid) -> dict\n",
      "    - getRelations(predicate=None, maxrows=0) -> Iterator\n",
      "    - getNodeIds(pid) -> Set[str]\n",
      "  \n",
      "  TypedEdgeQueries:\n",
      "    - get_edges_by_type(edge_type, limit) -> Iterator\n",
      "    - get_typed_relations() -> Iterator\n",
      "    - get_edge_type_statistics() -> List[(EdgeType, count)]\n",
      "\n",
      "Edge Type Utilities (format-independent):\n",
      "  - ISamplesEdgeType enum: 14 edge types\n",
      "  - infer_edge_type(s, p, o) -> EdgeType\n",
      "  - get_edge_types_by_subject(otype) -> List[EdgeType]\n",
      "  - get_edge_types_by_object(otype) -> List[EdgeType]\n",
      "\n",
      "Wide Format: Validation only (see issue #11 for unified API)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary: pqg API capabilities\n",
    "if PQG_AVAILABLE:\n",
    "    print('PQG LIBRARY SUMMARY')\n",
    "    print('=' * 60)\n",
    "    print('''\n",
    "Format Detection:\n",
    "  get_schema_from_parquet(path) -> (schema, format)\n",
    "\n",
    "Narrow Format Query APIs:\n",
    "  PQG class:\n",
    "    - getNode(pid) -> dict\n",
    "    - getRelations(predicate=None, maxrows=0) -> Iterator\n",
    "    - getNodeIds(pid) -> Set[str]\n",
    "  \n",
    "  TypedEdgeQueries:\n",
    "    - get_edges_by_type(edge_type, limit) -> Iterator\n",
    "    - get_typed_relations() -> Iterator\n",
    "    - get_edge_type_statistics() -> List[(EdgeType, count)]\n",
    "\n",
    "Edge Type Utilities (format-independent):\n",
    "  - ISamplesEdgeType enum: 14 edge types\n",
    "  - infer_edge_type(s, p, o) -> EdgeType\n",
    "  - get_edge_types_by_subject(otype) -> List[EdgeType]\n",
    "  - get_edge_types_by_object(otype) -> List[EdgeType]\n",
    "\n",
    "Wide Format: Validation only (see issue #11 for unified API)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Stephen Richard's SESAR Parquet Comparison\n",
    "\n",
    "Stephen Richard created a new SESAR parquet file using the wide schema for his web app at https://isamples-sesar.onrender.com/. This section compares his file with our Zenodo wide format to identify any serialization differences.\n",
    "\n",
    "**Data Sources:**\n",
    "- **Stephen's SESAR**: `https://sesar-parquet.s3.amazonaws.com/sesar_samples.parquet` (~300MB, SESAR only)\n",
    "- **Zenodo Wide**: Our reference wide format (all 4 sources)\n",
    "\n",
    "**Key Questions:**\n",
    "1. Are the schemas structurally aligned?\n",
    "2. Are there serialization differences in how entities are stored?\n",
    "3. Can we identify data quality issues in either file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "14.1 SCHEMA COMPARISON: Stephen's SESAR vs Zenodo Wide\n",
      "======================================================================\n",
      "\n",
      "--- Stephen's SESAR schema ---\n",
      "Columns: 49\n",
      "Zenodo Wide columns: 49\n",
      "\n",
      "Columns in BOTH: 49\n",
      "Only in Stephen's: None\n",
      "Only in Zenodo: None\n"
     ]
    }
   ],
   "source": [
    "# Stephen's SESAR parquet URL\n",
    "STEPHEN_SESAR_URL = 'https://sesar-parquet.s3.amazonaws.com/sesar_samples.parquet'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"14.1 SCHEMA COMPARISON: Stephen's SESAR vs Zenodo Wide\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get schema for Stephen's file\n",
    "print(\"\\n--- Stephen's SESAR schema ---\")\n",
    "stephen_schema = con.sql(f\"DESCRIBE SELECT * FROM read_parquet('{STEPHEN_SESAR_URL}')\").fetchdf()\n",
    "print(f\"Columns: {len(stephen_schema)}\")\n",
    "\n",
    "# Get schema for Zenodo wide\n",
    "zenodo_schema = con.sql(f\"DESCRIBE SELECT * FROM read_parquet('{PATHS['zenodo_wide']}')\").fetchdf()\n",
    "print(f\"Zenodo Wide columns: {len(zenodo_schema)}\")\n",
    "\n",
    "# Compare column names\n",
    "stephen_cols = set(stephen_schema['column_name'])\n",
    "zenodo_cols = set(zenodo_schema['column_name'])\n",
    "\n",
    "print(f\"\\nColumns in BOTH: {len(stephen_cols & zenodo_cols)}\")\n",
    "print(f\"Only in Stephen's: {stephen_cols - zenodo_cols or 'None'}\")\n",
    "print(f\"Only in Zenodo: {zenodo_cols - stephen_cols or 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "14.2 ENTITY TYPE DISTRIBUTION\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad4698bf6ce4ef2a699289949e663f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "         otype             Stephen's    Zenodo(SESAR)     Diff\n",
      "----------------------------------------------------------------------\n",
      "MaterialSampleRecord       5,273,157      4,688,386     584,771\n",
      "SamplingEvent              5,262,077      4,688,386     573,691\n",
      "GeospatialCoordLocation    4,887,102      4,389,231     497,871\n",
      "SampleRelation             3,780,683              0   3,780,683\n",
      "SamplingSite                 156,857        193,427     -36,570\n",
      "IdentifiedConcept             76,727              0      76,727\n",
      "Agent                            832              0         832\n",
      "MaterialSampleCuration           765              0         765\n"
     ]
    }
   ],
   "source": [
    "# Entity type comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"14.2 ENTITY TYPE DISTRIBUTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Stephen's SESAR otype counts\n",
    "stephen_otypes = con.sql(f\"\"\"\n",
    "    SELECT otype, COUNT(*) as stephen_cnt\n",
    "    FROM read_parquet('{STEPHEN_SESAR_URL}')\n",
    "    GROUP BY otype\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Zenodo SESAR-only otype counts (filter by n='SESAR')\n",
    "zenodo_sesar_otypes = con.sql(f\"\"\"\n",
    "    SELECT otype, COUNT(*) as zenodo_sesar_cnt\n",
    "    FROM read_parquet('{PATHS['zenodo_wide']}')\n",
    "    WHERE n = 'SESAR'\n",
    "    GROUP BY otype\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Merge for comparison\n",
    "otype_compare = stephen_otypes.merge(zenodo_sesar_otypes, on='otype', how='outer').fillna(0)\n",
    "otype_compare['stephen_cnt'] = otype_compare['stephen_cnt'].astype(int)\n",
    "otype_compare['zenodo_sesar_cnt'] = otype_compare['zenodo_sesar_cnt'].astype(int)\n",
    "otype_compare['diff'] = otype_compare['stephen_cnt'] - otype_compare['zenodo_sesar_cnt']\n",
    "otype_compare = otype_compare.sort_values('stephen_cnt', ascending=False)\n",
    "\n",
    "print(\"\\n         otype             Stephen's    Zenodo(SESAR)     Diff\")\n",
    "print(\"-\" * 70)\n",
    "for _, row in otype_compare.iterrows():\n",
    "    print(f\"{row['otype']:<25} {row['stephen_cnt']:>10,}  {row['zenodo_sesar_cnt']:>13,}  {row['diff']:>10,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "14.3 IDENTIFIEDCONCEPT DUPLICATION CHECK\n",
      "======================================================================\n",
      "\n",
      "Wide format spec: one row per unique PID\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48eb53280a4463981d26535d3a0fba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stephen's SESAR IdentifiedConcept:\n",
      "  Total rows: 76,727\n",
      "  Unique PIDs: 51,296\n",
      "  ‚ö†Ô∏è DUPLICATION DETECTED: 25,431 duplicate rows\n",
      "\n",
      "--- Sample duplicated PIDs (same PID, multiple rows) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43462d53d54c4b8c9e479a4b7ad6f762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         pid        label          scheme_name  cnt\n",
      "http://resource.geosciml.org/classifier/ics/ischart/Aalenian Aalenian Age   Geologic Age Older    1\n",
      "http://resource.geosciml.org/classifier/ics/ischart/Aalenian Aalenian Age Geologic Age Younger    1\n",
      "http://resource.geosciml.org/classifier/ics/ischart/Aeronian Aeronian Age   Geologic Age Older    1\n",
      "http://resource.geosciml.org/classifier/ics/ischart/Aeronian Aeronian Age Geologic Age Younger    1\n",
      "  http://resource.geosciml.org/classifier/ics/ischart/Albian   Albian Age   Geologic Age Older    1\n",
      "  http://resource.geosciml.org/classifier/ics/ischart/Albian   Albian Age Geologic Age Younger    1\n",
      " http://resource.geosciml.org/classifier/ics/ischart/Anisian  Anisian Age   Geologic Age Older    1\n",
      " http://resource.geosciml.org/classifier/ics/ischart/Anisian  Anisian Age Geologic Age Younger    1\n",
      "  http://resource.geosciml.org/classifier/ics/ischart/Aptian   Aptian Age   Geologic Age Older    1\n",
      "  http://resource.geosciml.org/classifier/ics/ischart/Aptian   Aptian Age Geologic Age Younger    1\n"
     ]
    }
   ],
   "source": [
    "# IdentifiedConcept duplication check\n",
    "print(\"=\" * 70)\n",
    "print(\"14.3 IDENTIFIEDCONCEPT DUPLICATION CHECK\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nWide format spec: one row per unique PID\")\n",
    "\n",
    "# Stephen's SESAR\n",
    "stephen_ic = con.sql(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_rows,\n",
    "        COUNT(DISTINCT pid) as unique_pids\n",
    "    FROM read_parquet('{STEPHEN_SESAR_URL}')\n",
    "    WHERE otype = 'IdentifiedConcept'\n",
    "\"\"\").fetchdf()\n",
    "print(f\"\\nStephen's SESAR IdentifiedConcept:\")\n",
    "print(f\"  Total rows: {stephen_ic['total_rows'].iloc[0]:,}\")\n",
    "print(f\"  Unique PIDs: {stephen_ic['unique_pids'].iloc[0]:,}\")\n",
    "if stephen_ic['total_rows'].iloc[0] != stephen_ic['unique_pids'].iloc[0]:\n",
    "    print(f\"  ‚ö†Ô∏è DUPLICATION DETECTED: {stephen_ic['total_rows'].iloc[0] - stephen_ic['unique_pids'].iloc[0]:,} duplicate rows\")\n",
    "\n",
    "# Show example duplicates\n",
    "print(\"\\n--- Sample duplicated PIDs (same PID, multiple rows) ---\")\n",
    "dups = con.sql(f\"\"\"\n",
    "    SELECT pid, label, scheme_name, COUNT(*) as cnt\n",
    "    FROM read_parquet('{STEPHEN_SESAR_URL}')\n",
    "    WHERE otype = 'IdentifiedConcept'\n",
    "    GROUP BY pid, label, scheme_name\n",
    "    HAVING COUNT(*) > 1 OR pid IN (\n",
    "        SELECT pid FROM read_parquet('{STEPHEN_SESAR_URL}')\n",
    "        WHERE otype = 'IdentifiedConcept'\n",
    "        GROUP BY pid HAVING COUNT(*) > 1\n",
    "    )\n",
    "    ORDER BY pid, scheme_name\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "print(dups.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "14.4 SAMPLERELATION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Stephen's SESAR has ~3.8M SampleRelation rows (19% of file)\n",
      "This is much higher than Zenodo's 501K (2% of file)\n",
      "\n",
      "--- Relationship types in Stephen's SESAR ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6b77246f8440c0b3fec292301568eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relationship     cnt\n",
      "      parent 3780683\n",
      "\n",
      "--- Sample SampleRelation rows ---\n",
      "                          pid                        label relationship             target\n",
      "relation:16246604443798877231 parent of 10.58052/MGD0000N3       parent 10.58052/MGD0000G2\n",
      " relation:7616191376866397440 parent of 10.58052/MGD0000N4       parent 10.58052/MGD0000G2\n",
      " relation:4141607539259512041 parent of 10.58052/MGD0000N5       parent 10.58052/MGD0000G2\n",
      "relation:17658622658289135018 parent of 10.58052/MGD0000N6       parent 10.58052/MGD0000G2\n",
      "relation:13862767266228668924 parent of 10.58052/MGD0000N7       parent 10.58052/MGD0000G2\n"
     ]
    }
   ],
   "source": [
    "# SampleRelation comparison\n",
    "print(\"=\" * 70)\n",
    "print(\"14.4 SAMPLERELATION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nStephen's SESAR has ~3.8M SampleRelation rows (19% of file)\")\n",
    "print(\"This is much higher than Zenodo's 501K (2% of file)\")\n",
    "\n",
    "# Check relationship types in Stephen's file\n",
    "print(\"\\n--- Relationship types in Stephen's SESAR ---\")\n",
    "rels = con.sql(f\"\"\"\n",
    "    SELECT relationship, COUNT(*) as cnt\n",
    "    FROM read_parquet('{STEPHEN_SESAR_URL}')\n",
    "    WHERE otype = 'SampleRelation'\n",
    "    GROUP BY relationship\n",
    "    ORDER BY cnt DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "print(rels.to_string(index=False))\n",
    "\n",
    "# Sample SampleRelation rows\n",
    "print(\"\\n--- Sample SampleRelation rows ---\")\n",
    "sample_rels = con.sql(f\"\"\"\n",
    "    SELECT pid, label, relationship, target\n",
    "    FROM read_parquet('{STEPHEN_SESAR_URL}')\n",
    "    WHERE otype = 'SampleRelation'\n",
    "    LIMIT 5\n",
    "\"\"\").fetchdf()\n",
    "print(sample_rels.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5 Summary: Stephen's SESAR vs Zenodo\n",
    "\n",
    "**Schema Alignment:** ‚úÖ Both have 49 columns with matching names\n",
    "\n",
    "**Critical Differences:**\n",
    "\n",
    "| Issue | Stephen's SESAR | Zenodo | Impact |\n",
    "|-------|-----------------|--------|--------|\n",
    "| **IdentifiedConcept rows** | ~77K rows, ~51K unique PIDs | 1:1 ratio | Potential schema violation |\n",
    "| **SampleRelation count** | 3.8M (19%) | 501K (2%) | More parent/child data |\n",
    "| **Agent rows** | 832 | 50K+ | Less agent extraction |\n",
    "| **MaterialSampleCuration** | 765 | 720K | Different curation model |\n",
    "| **p__site_location** | 0% populated | 1.7% | Missing relationship |\n",
    "\n",
    "**Discussion Points for Meeting:**\n",
    "1. Should IdentifiedConcept support multiple scheme contexts per PID?\n",
    "2. Why does SESAR have so many more SampleRelation rows?\n",
    "3. How should Agent/Curation data be extracted from SESAR source?\n",
    "4. Performance optimization strategies (partitioning, DuckDB-WASM)\n",
    "\n",
    "**Stephen's Performance Notes:**\n",
    "- S3 direct access times out ‚Üí copies to server\n",
    "- Server: ~40 second responses\n",
    "- Local DuckDB in-memory: <1 second\n",
    "- Render free tier: 15 min idle timeout, 2 min restart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isamples-python-3.12.9",
   "language": "python",
   "name": "isamples-python-3.12.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

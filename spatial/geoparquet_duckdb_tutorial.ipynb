{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86800ff",
   "metadata": {},
   "source": [
    "# Comprehensive Python + GeoParquet + DuckDB Tutorial\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This tutorial explores the powerful combination of Python, GeoParquet, and DuckDB for efficient geospatial data processing and analysis. We'll cover the basics of each technology, their advantages, and how they work together to provide a robust solution for handling geospatial datasets.\n",
    "\n",
    "### 1.1 What is GeoParquet?\n",
    "\n",
    "GeoParquet is an extension of Apache Parquet, a columnar storage file format, designed specifically for geospatial data. It combines the efficiency of Parquet with support for geometric data types, making it an excellent choice for storing and processing geospatial information.\n",
    "\n",
    "### 1.2 Advantages of GeoParquet\n",
    "\n",
    "GeoParquet offers several advantages over alternative formats such as JSON, JSONL (JSON Lines), and CSV, especially when dealing with large geospatial datasets:\n",
    "\n",
    "1. **Efficient Storage**: Uses columnar storage and compression, significantly reducing file size.\n",
    "2. **Fast Query Performance**: Allows for quick data retrieval and filtering.\n",
    "3. **Schema Enforcement**: Ensures data consistency and reduces interpretation errors.\n",
    "4. **Support for Complex Data Types**: Natively stores complex geospatial objects.\n",
    "5. **Partitioning and Chunking**: Supports efficient querying of subsets of large datasets.\n",
    "6. **Interoperability**: Wide support in big data ecosystems and geospatial tools.\n",
    "7. **Metadata Handling**: Better support for metadata compared to CSV.\n",
    "8. **Streaming Capabilities**: Supports streaming reads with compression benefits.\n",
    "9. **Reduced Processing Time**: Faster overall processing for large datasets.\n",
    "\n",
    "### 1.3 Comparison with Alternative Formats\n",
    "\n",
    "- **JSON Blobs**:\n",
    "  - Pros: Human-readable, flexible schema\n",
    "  - Cons: Large file size, slow to parse, must often be read entirely into memory\n",
    "\n",
    "- **JSONL (JSON Lines)**:\n",
    "  - Pros: Supports streaming, one record per line for easier processing\n",
    "  - Cons: Still larger file size than GeoParquet, less efficient querying\n",
    "\n",
    "- **CSV**:\n",
    "  - Pros: Simple, widely supported, human-readable\n",
    "  - Cons: No native support for complex data types, no schema enforcement, less efficient for large datasets\n",
    "\n",
    "## 2. Setting Up the Environment\n",
    "\n",
    "### 2.1 Installation\n",
    "\n",
    "To set up our environment, we need to install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0914d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        from IPython.core import getipython\n",
    "        return 'google.colab' in str(getipython.get_ipython())\n",
    "    except ImportError:\n",
    "        # Not running in an IPython environment\n",
    "        return False\n",
    "\n",
    "\n",
    "if in_colab():\n",
    "  subprocess.run(['pip', 'install', '-r', 'https://raw.githubusercontent.com/rdhyee/isamples-examples/exploratory/requirements.in'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea37995",
   "metadata": {},
   "source": [
    "### 2.2 Importing Necessary Modules\n",
    "\n",
    "In your Python script or Jupyter notebook, start with these imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c31791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import duckdb\n",
    "import shapely\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afecc10a",
   "metadata": {},
   "source": [
    "## 3. Working with GeoParquet and DuckDB\n",
    "\n",
    "Let's create a simple example to demonstrate how to create, save, and read GeoParquet data using Python, GeoPandas, and DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import duckdb\n",
    "\n",
    "# Print version information\n",
    "print(f\"GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"DuckDB version: {duckdb.__version__}\")\n",
    "\n",
    "# Create a simple GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    {'city': ['New York', 'Paris', 'Tokyo'],\n",
    "     'geometry': gpd.points_from_xy([-74.006, 2.3522, 139.6917], \n",
    "                                    [40.7128, 48.8566, 35.6895])},\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Save as GeoParquet\n",
    "gdf.to_parquet(\"cities.geoparquet\")\n",
    "\n",
    "# Read with DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Enable spatial extension\n",
    "con.execute(\"INSTALL spatial;\")\n",
    "con.execute(\"LOAD spatial;\")\n",
    "\n",
    "# Read the GeoParquet file and extract coordinates\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        city, \n",
    "        ST_X(ST_GeomFromWKB(geometry)) as longitude, \n",
    "        ST_Y(ST_GeomFromWKB(geometry)) as latitude\n",
    "    FROM read_parquet('cities.geoparquet')\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"\\nData read from GeoParquet using DuckDB:\")\n",
    "for row in result:\n",
    "    print(f\"City: {row[0]}, Longitude: {row[1]}, Latitude: {row[2]}\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab46c8",
   "metadata": {},
   "source": [
    "### 3.1 Understanding ST_GeomFromWKB\n",
    "\n",
    "In our DuckDB query, we use the `ST_GeomFromWKB` function. Here's why it's necessary:\n",
    "\n",
    "1. **WKB Format**: GeoParquet stores geometry data in Well-Known Binary (WKB) format. This is a standard binary representation of geometry data that's compact and efficient.\n",
    "\n",
    "2. **DuckDB Interpretation**: While DuckDB can read the Parquet file, it doesn't automatically recognize the WKB data as geometry. The `ST_GeomFromWKB` function tells DuckDB to interpret this binary data as geometric information.\n",
    "\n",
    "3. **Enabling Spatial Functions**: By converting the WKB data to a geometry type that DuckDB understands, we can then use spatial functions like `ST_X` and `ST_Y` to extract coordinates.\n",
    "\n",
    "## 4. Processing GeoParquet with Different Tools\n",
    "\n",
    "Now, let's explore how to process our GeoParquet file using different Python libraries and compare their approaches. We'll start with a simple Haversine distance calculation as a reference point, then move on to more native and accurate methods for each platform.\n",
    "\n",
    "### 4.0 Haversine Distance Calculation (Reference)\n",
    "\n",
    "First, let's implement a Haversine distance function that we'll use as a reference point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e809d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "    \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fafd955",
   "metadata": {},
   "source": [
    "This Haversine function provides a good approximation for distances on Earth, assuming a spherical Earth. It's a useful \"back-of-the-envelope\" calculation, but it can have errors up to 0.5% due to the Earth's ellipsoidal shape.\n",
    "\n",
    "Now, let's proceed with more accurate, native calculations for each platform.\n",
    "\n",
    "### 4.1 Using Pandas and GeoPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de66b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Read the GeoParquet file\n",
    "pdf = pd.read_parquet('cities.geoparquet')\n",
    "print(\"Pandas DataFrame:\")\n",
    "print(pdf)\n",
    "\n",
    "# Convert to GeoDataFrame to properly handle the geometry\n",
    "gdf = gpd.read_parquet('cities.geoparquet')\n",
    "print(\"\\nGeoPandas GeoDataFrame:\")\n",
    "print(gdf)\n",
    "\n",
    "# Basic querying\n",
    "print(\"\\nCities with longitude < 0:\")\n",
    "print(gdf[gdf.geometry.x < 0])\n",
    "\n",
    "# Calculate distances using Haversine (reference)\n",
    "tokyo_coords = (139.6917, 35.6895)\n",
    "gdf['haversine_distance_km'] = gdf.apply(\n",
    "    lambda row: haversine_distance(row.geometry.x, row.geometry.y, \n",
    "                                   tokyo_coords[0], tokyo_coords[1]), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate distances using geodesic (more accurate)\n",
    "tokyo_coords_geodesic = (35.6895, 139.6917)  # Note: geodesic uses (lat, lon) order\n",
    "gdf['geodesic_distance_km'] = gdf.apply(\n",
    "    lambda row: geodesic(tokyo_coords_geodesic, (row.geometry.y, row.geometry.x)).kilometers,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"\\nDistances to Tokyo (in kilometers):\")\n",
    "print(gdf[['city', 'haversine_distance_km', 'geodesic_distance_km']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d454b",
   "metadata": {},
   "source": [
    "### 4.2 Using Polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d3ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "\n",
    "# Read the GeoParquet file\n",
    "df = pl.read_parquet('cities.geoparquet')\n",
    "print(\"Polars DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Function to convert WKB to coordinates\n",
    "def wkb_to_coords(wkb_data):\n",
    "    point = wkb.loads(wkb_data)\n",
    "    return (point.x, point.y)\n",
    "\n",
    "# Set up the geodesic distance calculator\n",
    "geod = pyproj.Geod(ellps='WGS84')\n",
    "\n",
    "# Function to calculate geodesic distance\n",
    "def geodesic_distance(lon1, lat1, lon2, lat2):\n",
    "    _, _, distance = geod.inv(lon1, lat1, lon2, lat2)\n",
    "    return distance / 1000  # Convert to kilometers\n",
    "\n",
    "# Extract coordinates from the geometry column\n",
    "df_with_coords = df.with_columns([\n",
    "    pl.col('geometry').map_elements(wkb_to_coords).alias('coords')\n",
    "])\n",
    "df_with_coords = df_with_coords.with_columns([\n",
    "    pl.col('coords').list.get(0).alias('longitude'),\n",
    "    pl.col('coords').list.get(1).alias('latitude')\n",
    "])\n",
    "\n",
    "print(\"\\nPolars DataFrame with extracted coordinates:\")\n",
    "print(df_with_coords)\n",
    "\n",
    "# Basic querying\n",
    "print(\"\\nCities with longitude < 0:\")\n",
    "print(df_with_coords.filter(pl.col('longitude') < 0))\n",
    "\n",
    "# Calculate distances using Haversine (reference)\n",
    "tokyo_coords = (139.6917, 35.6895)\n",
    "df_with_distances = df_with_coords.with_columns([\n",
    "    pl.struct(['longitude', 'latitude'])\n",
    "    .map_elements(lambda x: haversine_distance(x['longitude'], x['latitude'], tokyo_coords[0], tokyo_coords[1]))\n",
    "    .alias('haversine_distance_km')\n",
    "])\n",
    "\n",
    "# Calculate distances using geodesic distance (more accurate)\n",
    "df_with_distances = df_with_distances.with_columns([\n",
    "    pl.struct(['longitude', 'latitude'])\n",
    "    .map_elements(lambda x: geodesic_distance(x['longitude'], x['latitude'], tokyo_coords[0], tokyo_coords[1]))\n",
    "    .alias('geodesic_distance_km')\n",
    "])\n",
    "\n",
    "print(\"\\nDistances to Tokyo (in kilometers):\")\n",
    "print(df_with_distances.select(['city', 'haversine_distance_km', 'geodesic_distance_km']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5b889",
   "metadata": {},
   "source": [
    "### 4.3 Using DuckDB\n",
    "\n",
    "Is there a native DuckDB approach?  **The following code is incorrect** TO DO: must study\n",
    "[Spatial Extension â€“ DuckDB](https://duckdb.org/docs/extensions/spatial.html) to figure out \n",
    "how to use the DuckDB `spatial` extension and understand its current limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL spatial;\")\n",
    "con.execute(\"LOAD spatial;\")\n",
    "\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        city, \n",
    "        ST_X(ST_GeomFromWKB(geometry)) as longitude, \n",
    "        ST_Y(ST_GeomFromWKB(geometry)) as latitude\n",
    "    FROM read_parquet('cities.geoparquet')\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"\\nData read from GeoParquet using DuckDB:\")\n",
    "for row in result:\n",
    "    print(f\"City: {row[0]}, Longitude: {row[1]}, Latitude: {row[2]}\")\n",
    "\n",
    "# Calculate distances using DuckDB\n",
    "result_distances = con.execute(\"\"\"\n",
    "    WITH cities AS (\n",
    "        SELECT \n",
    "            city, \n",
    "            ST_GeomFromWKB(geometry) as geom\n",
    "        FROM read_parquet('cities.geoparquet')\n",
    "    )\n",
    "    SELECT \n",
    "        city, \n",
    "        ST_Distance(geom, ST_Point(139.6917, 35.6895))/1000 as distance_to_tokyo_km\n",
    "    FROM cities\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"\\nDistances to Tokyo calculated by DuckDB (in kilometers):\")\n",
    "for row in result_distances:\n",
    "    print(f\"City: {row[0]}, Distance: {row[1]:.2f} km\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134ea42",
   "metadata": {},
   "source": [
    "Compare that to Haversine:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d608387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "\n",
    "# Define haversine_distance as a UDF\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION haversine_distance(lon1, lat1, lon2, lat2) AS (\n",
    "    6371 * 2 * asin(sqrt(\n",
    "        sin((radians(lat2) - radians(lat1))/2)^2 +\n",
    "        cos(radians(lat1)) * cos(radians(lat2)) * sin((radians(lon2) - radians(lon1))/2)^2\n",
    "    ))\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Use the UDF in the query\n",
    "result_distances = con.execute(\"\"\"\n",
    "    WITH cities AS (\n",
    "        SELECT \n",
    "            city, \n",
    "            ST_GeomFromWKB(geometry) as geom\n",
    "        FROM read_parquet('cities.geoparquet')\n",
    "    )\n",
    "    SELECT \n",
    "        city, \n",
    "        haversine_distance(ST_X(geom), ST_Y(geom), 139.6917, 35.6895) as distance_km\n",
    "    FROM cities\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"\\nDistances to Tokyo:\")\n",
    "for row in result_distances:\n",
    "    print(f\"City: {row[0]}, Distance: {row[1]:.2f} km\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f1af1",
   "metadata": {},
   "source": [
    "## 5. Comparison of Approaches\n",
    "\n",
    "1. **GeoPandas**: \n",
    "   - Pros: Native support for geospatial operations, intuitive for those familiar with pandas.\n",
    "   - Cons: Can be memory-intensive for large datasets.\n",
    "\n",
    "2. **Polars**: \n",
    "   - Pros: Very fast, good for large datasets.\n",
    "   - Cons: Requires manual handling of geometry data, less built-in support for geospatial operations.\n",
    "\n",
    "3. **DuckDB**: \n",
    "   - Pros: SQL interface, efficient for large datasets, built-in geospatial functions.\n",
    "   - Cons: Requires knowledge of SQL and specific DuckDB functions.\n",
    "\n",
    "Each approach has its strengths, and the choice depends on your specific use case, dataset size, and familiarity with the tools.\n",
    "\n",
    "## 6. Best Practices and Tips\n",
    "\n",
    "1. **Choose the Right Tool**: Consider your dataset size, query complexity, and performance requirements when choosing between GeoPandas, Polars, and DuckDB.\n",
    "\n",
    "2. **Leverage GeoParquet's Efficiency**: Use GeoParquet for storing large geospatial datasets to take advantage of its compression and efficient querying capabilities.\n",
    "\n",
    "3. **Understand Geometry Formats**: Be aware of how different tools handle geometry data (e.g., WKB in GeoParquet, native geometry objects in GeoPandas).\n",
    "\n",
    "4. **Use Appropriate Projections**: When calculating distances or areas, make sure to use an appropriate projection for your data's geographic extent.\n",
    "\n",
    "5. **Handle Large Datasets Carefully**: For very large datasets, consider using tools like DuckDB or Polars that are designed for out-of-memory processing.\n",
    "\n",
    "6. **Validate Results**: Cross-check results between different tools, especially when implementing custom geospatial operations.\n",
    "\n",
    "7. **Use Native Geospatial Functions**: When available, use the native geospatial functions provided by each tool. They are often optimized for performance and accuracy.\n",
    "\n",
    "8. **Understand Geodesic Calculations**: Be aware that different methods of calculating geodesic distances may yield slightly different results due to variations in the underlying algorithms and Earth models used.\n",
    "\n",
    "9. **Start Simple, Then Refine**: Begin with simple calculations (like Haversine) for quick estimates, then move to more accurate methods (like geodesic calculations) when precision is crucial.\n",
    "\n",
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "This tutorial has introduced you to working with GeoParquet data using Python, GeoPandas, Polars, and DuckDB. You've learned how to:\n",
    "\n",
    "- Create and save GeoParquet files\n",
    "- Read and process GeoParquet data using different tools\n",
    "- Perform basic spatial operations and queries\n",
    "- Calculate distances using both simple (Haversine) and more accurate (geodesic) methods\n",
    "\n",
    "To further your learning, consider exploring:\n",
    "\n",
    "- More complex geospatial analyses and operations\n",
    "- Handling larger datasets and optimizing performance\n",
    "- Integrating these tools into data processing pipelines\n",
    "- Visualizing geospatial data using libraries like Folium or Geopandas' plotting capabilities\n",
    "\n",
    "Remember, the field of geospatial data processing is vast and constantly evolving. Keep exploring and experimenting with different tools and techniques to find the best solutions for your specific needs.\n",
    "\n",
    "Happy geospatial data processing!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
